2023-12-21 20:31:15,871 -               text  label
category                 
crime          600    600
health         600    600
politics       600    600
science        600    600
social_media   600    600
2023-12-21 20:31:15,877 -        text  category
label                
0      1567      1567
1      1433      1433
2023-12-21 20:31:15,883 - ====================================================
2023-12-21 20:31:25,586 - ====================================================
2023-12-21 20:31:26,340 - Model: bert-base-uncased 2023-12-21_20-31-26 with 1 epochs
2023-12-21 20:32:28,702 - Epoch 1 average train loss: 0.485454
2023-12-21 20:32:33,838 - 2023-12-21_20-31-26 with 1 epochs: Evaluation Results (balanced):
2023-12-21 20:32:33,839 - Training time: 62.03987765312195 seconds
2023-12-21 20:32:33,839 - Inference time: 5.127467393875122 seconds
2023-12-21 20:32:33,839 - Precision: 0.850909090909091
2023-12-21 20:32:33,839 - Recall: 0.8181818181818182
2023-12-21 20:32:33,839 - F-score: 0.8342245989304814
2023-12-21 20:32:33,839 - Accuracy: 0.845
2023-12-21 20:32:33,839 - G-mean: 0.8314827937868807
2023-12-21 20:32:40,708 - bert-base-uncased 2023-12-21_20-31-26 with 1 epochs: Evaluation Results (balanced) (completely new data):
2023-12-21 20:32:40,709 - Training time: 62.03987765312195 seconds
2023-12-21 20:32:40,709 - Inference time: 6.862257719039917 seconds
2023-12-21 20:32:40,709 - Precision: 0.4366576819407008
2023-12-21 20:32:40,709 - Recall: 0.4263157894736842
2023-12-21 20:32:40,709 - F-score: 0.4314247669773635
2023-12-21 20:32:40,709 - Accuracy: 0.46625
2023-12-21 20:32:40,709 - G-mean: 0.4458359976965804
2023-12-21 20:32:41,040 - ====================================================
2023-12-21 20:32:41,931 - Model: bert-base-uncased 2023-12-21_20-32-41 with 2 epochs
2023-12-21 20:33:43,560 - Epoch 1 average train loss: 0.467859
2023-12-21 20:34:44,799 - Epoch 2 average train loss: 0.234170
2023-12-21 20:34:49,894 - 2023-12-21_20-32-41 with 2 epochs: Evaluation Results (balanced):
2023-12-21 20:34:49,894 - Training time: 122.46283221244812 seconds
2023-12-21 20:34:49,894 - Inference time: 5.086483716964722 seconds
2023-12-21 20:34:49,894 - Precision: 0.9084507042253521
2023-12-21 20:34:49,894 - Recall: 0.9020979020979021
2023-12-21 20:34:49,894 - F-score: 0.9052631578947369
2023-12-21 20:34:49,894 - Accuracy: 0.91
2023-12-21 20:34:49,894 - G-mean: 0.9060403362483874
2023-12-21 20:34:54,459 - bert-base-uncased 2023-12-21_20-32-41 with 2 epochs: Evaluation Results (balanced) (completely new data):
2023-12-21 20:34:54,459 - Training time: 122.46283221244812 seconds
2023-12-21 20:34:54,459 - Inference time: 4.557437181472778 seconds
2023-12-21 20:34:54,459 - Precision: 0.5053763440860215
2023-12-21 20:34:54,459 - Recall: 0.618421052631579
2023-12-21 20:34:54,459 - F-score: 0.5562130177514794
2023-12-21 20:34:54,459 - Accuracy: 0.53125
2023-12-21 20:34:54,459 - G-mean: 0.5731807605027635
2023-12-21 20:34:54,774 - ====================================================
2023-12-21 20:34:55,614 - Model: bert-base-uncased 2023-12-21_20-34-55 with 3 epochs
2023-12-21 20:35:27,491 - Epoch 1 average train loss: 0.487105
2023-12-21 20:35:59,203 - Epoch 2 average train loss: 0.225878
2023-12-21 20:36:30,915 - Epoch 3 average train loss: 0.107551
2023-12-21 20:36:33,456 - 2023-12-21_20-34-55 with 3 epochs: Evaluation Results (balanced):
2023-12-21 20:36:33,456 - Training time: 95.16936373710632 seconds
2023-12-21 20:36:33,456 - Inference time: 2.532698392868042 seconds
2023-12-21 20:36:33,456 - Precision: 0.9006849315068494
2023-12-21 20:36:33,456 - Recall: 0.9195804195804196
2023-12-21 20:36:33,456 - F-score: 0.9100346020761246
2023-12-21 20:36:33,456 - Accuracy: 0.9133333333333333
2023-12-21 20:36:33,456 - G-mean: 0.9164515534841162
2023-12-21 20:36:36,838 - bert-base-uncased 2023-12-21_20-34-55 with 3 epochs: Evaluation Results (balanced) (completely new data):
2023-12-21 20:36:36,838 - Training time: 95.16936373710632 seconds
2023-12-21 20:36:36,838 - Inference time: 3.3751442432403564 seconds
2023-12-21 20:36:36,838 - Precision: 0.48091603053435117
2023-12-21 20:36:36,838 - Recall: 0.6631578947368421
2023-12-21 20:36:36,838 - F-score: 0.5575221238938054
2023-12-21 20:36:36,839 - Accuracy: 0.5
2023-12-21 20:36:36,839 - G-mean: 0.5758289219624358
2023-12-21 20:36:37,179 - ====================================================
2023-12-21 20:36:38,020 - Model: bert-base-uncased 2023-12-21_20-36-38 with 4 epochs
2023-12-21 20:37:09,858 - Epoch 1 average train loss: 0.544590
2023-12-21 20:37:41,475 - Epoch 2 average train loss: 0.254005
2023-12-21 20:38:13,026 - Epoch 3 average train loss: 0.110146
2023-12-21 20:38:44,680 - Epoch 4 average train loss: 0.052017
2023-12-21 20:38:47,218 - 2023-12-21_20-36-38 with 4 epochs: Evaluation Results (balanced):
2023-12-21 20:38:47,218 - Training time: 126.5301513671875 seconds
2023-12-21 20:38:47,218 - Inference time: 2.529939889907837 seconds
2023-12-21 20:38:47,218 - Precision: 0.911660777385159
2023-12-21 20:38:47,218 - Recall: 0.9020979020979021
2023-12-21 20:38:47,218 - F-score: 0.9068541300527241
2023-12-21 20:38:47,218 - Accuracy: 0.9116666666666666
2023-12-21 20:38:47,218 - G-mean: 0.9068696639609175
2023-12-21 20:38:50,590 - bert-base-uncased 2023-12-21_20-36-38 with 4 epochs: Evaluation Results (balanced) (completely new data):
2023-12-21 20:38:50,590 - Training time: 126.5301513671875 seconds
2023-12-21 20:38:50,590 - Inference time: 3.364715337753296 seconds
2023-12-21 20:38:50,590 - Precision: 0.48655913978494625
2023-12-21 20:38:50,590 - Recall: 0.4763157894736842
2023-12-21 20:38:50,590 - F-score: 0.48138297872340424
2023-12-21 20:38:50,590 - Accuracy: 0.5125
2023-12-21 20:38:50,590 - G-mean: 0.49407675730119416
2023-12-21 20:38:50,936 - ====================================================
2023-12-21 20:38:51,816 - Model: bert-base-uncased 2023-12-21_20-38-51 with 5 epochs
2023-12-21 20:39:23,673 - Epoch 1 average train loss: 0.468958
2023-12-21 20:39:55,324 - Epoch 2 average train loss: 0.209559
2023-12-21 20:40:27,065 - Epoch 3 average train loss: 0.111845
2023-12-21 20:40:59,006 - Epoch 4 average train loss: 0.072488
2023-12-21 20:41:30,765 - Epoch 5 average train loss: 0.045536
2023-12-21 20:41:33,302 - 2023-12-21_20-38-51 with 5 epochs: Evaluation Results (balanced):
2023-12-21 20:41:33,302 - Training time: 158.80187392234802 seconds
2023-12-21 20:41:33,302 - Inference time: 2.5282957553863525 seconds
2023-12-21 20:41:33,302 - Precision: 0.865625
2023-12-21 20:41:33,302 - Recall: 0.9685314685314685
2023-12-21 20:41:33,302 - F-score: 0.9141914191419143
2023-12-21 20:41:33,302 - Accuracy: 0.9133333333333333
2023-12-21 20:41:33,303 - G-mean: 0.9405275512137189
2023-12-21 20:41:36,676 - bert-base-uncased 2023-12-21_20-38-51 with 5 epochs: Evaluation Results (balanced) (completely new data):
2023-12-21 20:41:36,676 - Training time: 158.80187392234802 seconds
2023-12-21 20:41:36,676 - Inference time: 3.3667001724243164 seconds
2023-12-21 20:41:36,676 - Precision: 0.4876543209876543
2023-12-21 20:41:36,676 - Recall: 0.8315789473684211
2023-12-21 20:41:36,676 - F-score: 0.6147859922178988
2023-12-21 20:41:36,676 - Accuracy: 0.505
2023-12-21 20:41:36,676 - G-mean: 0.6480334624238571
2023-12-21 20:41:37,027 - ====================================================
2023-12-21 20:41:37,829 - Model: bert-base-uncased 2023-12-21_20-41-37 with 6 epochs
2023-12-21 20:42:09,755 - Epoch 1 average train loss: 0.527492
2023-12-21 20:42:41,498 - Epoch 2 average train loss: 0.264127
2023-12-21 20:43:13,346 - Epoch 3 average train loss: 0.151374
2023-12-21 20:43:44,925 - Epoch 4 average train loss: 0.093891
2023-12-21 20:44:16,508 - Epoch 5 average train loss: 0.064233
2023-12-21 20:44:48,092 - Epoch 6 average train loss: 0.032069
2023-12-21 20:44:50,634 - 2023-12-21_20-41-37 with 6 epochs: Evaluation Results (balanced):
2023-12-21 20:44:50,634 - Training time: 190.04876565933228 seconds
2023-12-21 20:44:50,634 - Inference time: 2.533700466156006 seconds
2023-12-21 20:44:50,634 - Precision: 0.8637770897832817
2023-12-21 20:44:50,634 - Recall: 0.9755244755244755
2023-12-21 20:44:50,634 - F-score: 0.9162561576354679
2023-12-21 20:44:50,634 - Accuracy: 0.915
2023-12-21 20:44:50,634 - G-mean: 0.9447776961300977
2023-12-21 20:44:54,013 - bert-base-uncased 2023-12-21_20-41-37 with 6 epochs: Evaluation Results (balanced) (completely new data):
2023-12-21 20:44:54,013 - Training time: 190.04876565933228 seconds
2023-12-21 20:44:54,013 - Inference time: 3.3722641468048096 seconds
2023-12-21 20:44:54,013 - Precision: 0.49756888168557534
2023-12-21 20:44:54,013 - Recall: 0.8078947368421052
2023-12-21 20:44:54,013 - F-score: 0.6158475426278835
2023-12-21 20:44:54,013 - Accuracy: 0.52125
2023-12-21 20:44:54,013 - G-mean: 0.6489338422204126
2023-12-21 20:44:54,366 - ====================================================
2023-12-21 20:44:55,130 - Model: bert-base-uncased 2023-12-21_20-44-55 with 7 epochs
2023-12-21 20:45:26,950 - Epoch 1 average train loss: 0.488724
2023-12-21 20:45:58,597 - Epoch 2 average train loss: 0.247413
2023-12-21 20:46:30,232 - Epoch 3 average train loss: 0.137585
2023-12-21 20:47:01,829 - Epoch 4 average train loss: 0.070286
2023-12-21 20:47:33,474 - Epoch 5 average train loss: 0.037493
2023-12-21 20:48:05,095 - Epoch 6 average train loss: 0.027947
2023-12-21 20:48:36,689 - Epoch 7 average train loss: 0.025056
2023-12-21 20:48:39,226 - 2023-12-21_20-44-55 with 7 epochs: Evaluation Results (balanced):
2023-12-21 20:48:39,226 - Training time: 221.4253330230713 seconds
2023-12-21 20:48:39,226 - Inference time: 2.529506206512451 seconds
2023-12-21 20:48:39,226 - Precision: 0.8986486486486487
2023-12-21 20:48:39,226 - Recall: 0.9300699300699301
2023-12-21 20:48:39,226 - F-score: 0.9140893470790379
2023-12-21 20:48:39,226 - Accuracy: 0.9166666666666666
2023-12-21 20:48:39,226 - G-mean: 0.92334397846312
2023-12-21 20:48:42,601 - bert-base-uncased 2023-12-21_20-44-55 with 7 epochs: Evaluation Results (balanced) (completely new data):
2023-12-21 20:48:42,601 - Training time: 221.4253330230713 seconds
2023-12-21 20:48:42,601 - Inference time: 3.368353843688965 seconds
2023-12-21 20:48:42,601 - Precision: 0.5142276422764228
2023-12-21 20:48:42,601 - Recall: 0.6657894736842105
2023-12-21 20:48:42,601 - F-score: 0.5802752293577981
2023-12-21 20:48:42,601 - Accuracy: 0.5425
2023-12-21 20:48:42,602 - G-mean: 0.6009915053257276
2023-12-21 20:48:42,955 - ====================================================
2023-12-21 20:48:43,830 - Model: bert-base-uncased 2023-12-21_20-48-43 with 8 epochs
2023-12-21 20:49:15,729 - Epoch 1 average train loss: 0.470853
2023-12-21 20:49:47,435 - Epoch 2 average train loss: 0.190344
2023-12-21 20:50:19,137 - Epoch 3 average train loss: 0.087739
2023-12-21 20:50:50,834 - Epoch 4 average train loss: 0.047789
2023-12-21 20:51:22,441 - Epoch 5 average train loss: 0.034338
2023-12-21 20:51:54,075 - Epoch 6 average train loss: 0.023879
2023-12-21 20:52:25,718 - Epoch 7 average train loss: 0.017480
2023-12-21 20:52:57,397 - Epoch 8 average train loss: 0.013327
2023-12-21 20:52:59,940 - 2023-12-21_20-48-43 with 8 epochs: Evaluation Results (balanced):
2023-12-21 20:52:59,941 - Training time: 253.36635065078735 seconds
2023-12-21 20:52:59,941 - Inference time: 2.535207509994507 seconds
2023-12-21 20:52:59,941 - Precision: 0.9100346020761245
2023-12-21 20:52:59,941 - Recall: 0.9195804195804196
2023-12-21 20:52:59,941 - F-score: 0.9147826086956521
2023-12-21 20:52:59,941 - Accuracy: 0.9183333333333333
2023-12-21 20:52:59,941 - G-mean: 0.9189566649093699
2023-12-21 20:53:03,323 - bert-base-uncased 2023-12-21_20-48-43 with 8 epochs: Evaluation Results (balanced) (completely new data):
2023-12-21 20:53:03,324 - Training time: 253.36635065078735 seconds
2023-12-21 20:53:03,324 - Inference time: 3.376068115234375 seconds
2023-12-21 20:53:03,324 - Precision: 0.4161849710982659
2023-12-21 20:53:03,324 - Recall: 0.37894736842105264
2023-12-21 20:53:03,324 - F-score: 0.39669421487603307
2023-12-21 20:53:03,324 - Accuracy: 0.4525
2023-12-21 20:53:03,324 - G-mean: 0.4140938108816966
2023-12-21 20:53:03,713 - Total program time: 1308.7387344837189 seconds
