{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac723a00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:48.304160Z",
     "iopub.status.busy": "2023-12-13T08:27:48.303161Z",
     "iopub.status.idle": "2023-12-13T08:27:53.175784Z",
     "shell.execute_reply": "2023-12-13T08:27:53.175784Z"
    },
    "papermill": {
     "duration": 4.877611,
     "end_time": "2023-12-13T08:27:53.176790",
     "exception": false,
     "start_time": "2023-12-13T08:27:48.299179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (1.26.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\user\\anaconda3\\lib\\site-packages (11.0.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\user\\anaconda3\\lib\\site-packages (0.25.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\user\\anaconda3\\lib\\site-packages (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: datetime in c:\\users\\user\\anaconda3\\lib\\site-packages (5.3)\n",
      "Requirement already satisfied: imblearn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\user\\anaconda3\\lib\\site-packages (0.1.99)\n",
      "Requirement already satisfied: papermill in c:\\users\\user\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.25.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (6.25.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (8.16.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (5.10.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipywidgets) (4.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\user\\anaconda3\\lib\\site-packages (from datetime) (5.4.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from imblearn) (0.11.0)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from papermill) (8.1.7)\n",
      "Requirement already satisfied: nbformat>=5.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from papermill) (5.9.2)\n",
      "Requirement already satisfied: nbclient>=0.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from papermill) (0.8.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\user\\anaconda3\\lib\\site-packages (from papermill) (0.4)\n",
      "Requirement already satisfied: tenacity>=5.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from papermill) (8.2.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (8.3.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.8)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
      "Requirement already satisfied: backcall in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\user\\anaconda3\\lib\\site-packages (from nbformat>=5.1.2->papermill) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nbformat>=5.1.2->papermill) (4.19.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from zope.interface->datetime) (68.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.1.2->papermill) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.1.2->papermill) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.1.2->papermill) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.1.2->papermill) (0.10.6)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (306)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.8)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy transformers pandas torch scikit-learn pyarrow accelerate transformers[torch] transformers[sentencepiece] ipywidgets tqdm datetime imblearn sentencepiece papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc60b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:53.184790Z",
     "iopub.status.busy": "2023-12-13T08:27:53.183790Z",
     "iopub.status.idle": "2023-12-13T08:27:56.025694Z",
     "shell.execute_reply": "2023-12-13T08:27:56.025694Z"
    },
    "papermill": {
     "duration": 2.846937,
     "end_time": "2023-12-13T08:27:56.026727",
     "exception": false,
     "start_time": "2023-12-13T08:27:53.179790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, DistilBertTokenizer, DistilBertForSequenceClassification ,AlbertTokenizer, AlbertForSequenceClassification, RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61d650b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:56.033739Z",
     "iopub.status.busy": "2023-12-13T08:27:56.033739Z",
     "iopub.status.idle": "2023-12-13T08:27:56.037171Z",
     "shell.execute_reply": "2023-12-13T08:27:56.037171Z"
    },
    "papermill": {
     "duration": 0.009345,
     "end_time": "2023-12-13T08:27:56.039108",
     "exception": false,
     "start_time": "2023-12-13T08:27:56.029763",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Default parameters, Papermill will overwrite these\n",
    "categories = 'science'\n",
    "select_model = 0\n",
    "freeze_layers_up_to = 0\n",
    "weight_for_class_0 = 0.45\n",
    "weight_for_class_1 = 0.55\n",
    "learning_rate = 0.00001\n",
    "min_acc = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b0ef84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:56.044671Z",
     "iopub.status.busy": "2023-12-13T08:27:56.044671Z",
     "iopub.status.idle": "2023-12-13T08:27:56.047758Z",
     "shell.execute_reply": "2023-12-13T08:27:56.047758Z"
    },
    "papermill": {
     "duration": 0.007114,
     "end_time": "2023-12-13T08:27:56.048771",
     "exception": false,
     "start_time": "2023-12-13T08:27:56.041657",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "freeze_layers_up_to = 0\n",
    "weight_for_class_0 = 0.45\n",
    "weight_for_class_1 = 0.55\n",
    "learning_rate = 1e-05\n",
    "min_acc = 0.8\n",
    "select_model = 5\n",
    "categories = \"politics\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c83c1403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:56.054771Z",
     "iopub.status.busy": "2023-12-13T08:27:56.054771Z",
     "iopub.status.idle": "2023-12-13T08:27:56.057859Z",
     "shell.execute_reply": "2023-12-13T08:27:56.057859Z"
    },
    "papermill": {
     "duration": 0.007093,
     "end_time": "2023-12-13T08:27:56.058864",
     "exception": false,
     "start_time": "2023-12-13T08:27:56.051771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_random_string(length=10):\n",
    "    letters = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choice(letters) for _ in range(length))\n",
    "\n",
    "run_id = generate_random_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2470f852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:56.064863Z",
     "iopub.status.busy": "2023-12-13T08:27:56.064863Z",
     "iopub.status.idle": "2023-12-13T08:27:56.069053Z",
     "shell.execute_reply": "2023-12-13T08:27:56.069053Z"
    },
    "papermill": {
     "duration": 0.009198,
     "end_time": "2023-12-13T08:27:56.070081",
     "exception": false,
     "start_time": "2023-12-13T08:27:56.060883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_dir_mapping = {\n",
    "  'crime': './results/crime',\n",
    "  'science': './results/science',\n",
    "  'health': './results/health',\n",
    "  'politics': './results/politics',\n",
    "  'social_media': './results/social_media'\n",
    "}\n",
    "\n",
    "log_dir = log_dir_mapping.get(categories, './results')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "log_filename = f'training_log_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\n",
    "log_filepath = os.path.join(log_dir, log_filename)\n",
    "\n",
    "logging.basicConfig(filename=log_filepath, filemode='w', format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "logging.info(f'\\nStarting detection model - {run_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3352bf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:56.077079Z",
     "iopub.status.busy": "2023-12-13T08:27:56.077079Z",
     "iopub.status.idle": "2023-12-13T08:27:56.506709Z",
     "shell.execute_reply": "2023-12-13T08:27:56.506709Z"
    },
    "papermill": {
     "duration": 0.434655,
     "end_time": "2023-12-13T08:27:56.507713",
     "exception": false,
     "start_time": "2023-12-13T08:27:56.073058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  label  \\\n",
      "78534  Breaking: At least 10 dead, 5 injured after tO...      0   \n",
      "78535  France: 10 people dead after shooting at HQ of...      0   \n",
      "78536  Ten killed in shooting at headquarters of Fren...      0   \n",
      "78537  BREAKING: 10 dead in shooting at headquarters ...      0   \n",
      "78538  Reuters: 10 people shot dead at headquarters o...      0   \n",
      "...                                                  ...    ...   \n",
      "84953  Sydney siege ends as police storm Lindt Cafe a...      0   \n",
      "84954  Breaking News: #SydneySiege is over, according...      0   \n",
      "84955  Watch gunfire erupt and hostages flee chocolat...      0   \n",
      "84956  Authorities have confirmed that #sydneysiege i...      0   \n",
      "84957  WATCH: The dramatic moment tactical teams stor...      0   \n",
      "\n",
      "                                                metadata         author  \n",
      "78534  {'account_date': 'Tue Oct 04 09:36:17 +0000 20...     H_E_Samuel  \n",
      "78535  {'account_date': 'Wed Mar 18 12:57:11 +0000 20...       euronews  \n",
      "78536  {'account_date': 'Mon Apr 28 14:29:37 +0000 20...   Channel4News  \n",
      "78537  {'account_date': 'Sat Feb 28 08:31:32 +0000 20...  AlArabiya_Eng  \n",
      "78538  {'account_date': 'Wed Nov 04 11:25:45 +0000 20...   SkyNewsBreak  \n",
      "...                                                  ...            ...  \n",
      "84953  {'account_date': 'Thu Nov 05 23:49:19 +0000 20...       guardian  \n",
      "84954  {'account_date': 'Sat Mar 17 19:01:26 +0000 20...        FoxNews  \n",
      "84955  {'account_date': 'Tue Mar 18 23:19:17 +0000 20...        NBCNews  \n",
      "84956  {'account_date': 'Fri Feb 13 15:44:54 +0000 20...    YahooNewsUK  \n",
      "84957  {'account_date': 'Wed May 04 06:32:13 +0000 20...         PzFeed  \n",
      "\n",
      "[6424 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "root_dir = '../data'\n",
    "\n",
    "def load_data_from_category(category):\n",
    "    files = os.listdir(os.path.join(root_dir, category))\n",
    "    dataframes = []\n",
    "    for file in files:\n",
    "        if file.endswith('.feather'):\n",
    "            df = pd.read_feather(os.path.join(root_dir, category, file))\n",
    "            dataframes.append(df)\n",
    "    return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Use this one when running multiple categories\n",
    "#combined_dataframes = [load_data_from_category(category) for category in categories] \n",
    "# This one is for single category\n",
    "combined_dataframes = [load_data_from_category(categories)]\n",
    "combined_df = pd.concat(combined_dataframes, ignore_index=True)\n",
    "combined_df.dropna(inplace=True)\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fab9777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:56.515714Z",
     "iopub.status.busy": "2023-12-13T08:27:56.515714Z",
     "iopub.status.idle": "2023-12-13T08:27:56.520759Z",
     "shell.execute_reply": "2023-12-13T08:27:56.520759Z"
    },
    "papermill": {
     "duration": 0.011105,
     "end_time": "2023-12-13T08:27:56.521874",
     "exception": false,
     "start_time": "2023-12-13T08:27:56.510769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef load_data_from_category(category, filenames):\\n    dataframes = []\\n    for file_name in filenames:\\n        file_path = os.path.join(root_dir, category, file_name)\\n        if os.path.exists(file_path):\\n            df = pd.read_feather(file_path)\\n            dataframes.append(df)\\n        else:\\n            print(f\"The file \\'{file_name}\\' in the \\'{category}\\' category does not exist.\")\\n    return pd.concat(dataframes, ignore_index=True)\\n\\nroot_dir = \\'../data\\'\\ncategory = \\'health\\'\\n\\n# List of filenames to include in combined_df\\n#included_filenames = [\\'isot_dataset.feather\\', \\'fake_news_dataset.feather\\', \\'pheme.feather\\', \\'liar_dataset.feather\\', \\'politifact_dataset.feather\\']\\nincluded_filenames = [\\'covid_claims.feather\\', \\'covid_fake_news_dataset.feather\\', \\'covid_FNIR.feather\\']\\ncombined_df = load_data_from_category(category, included_filenames)\\n\\n# Drop NaN values\\ncombined_df.dropna(inplace=True)\\n\\n# Print the resulting DataFrame\\nprint(combined_df)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def load_data_from_category(category, filenames):\n",
    "    dataframes = []\n",
    "    for file_name in filenames:\n",
    "        file_path = os.path.join(root_dir, category, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_feather(file_path)\n",
    "            dataframes.append(df)\n",
    "        else:\n",
    "            print(f\"The file '{file_name}' in the '{category}' category does not exist.\")\n",
    "    return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "root_dir = '../data'\n",
    "category = 'health'\n",
    "\n",
    "# List of filenames to include in combined_df\n",
    "#included_filenames = ['isot_dataset.feather', 'fake_news_dataset.feather', 'pheme.feather', 'liar_dataset.feather', 'politifact_dataset.feather']\n",
    "included_filenames = ['covid_claims.feather', 'covid_fake_news_dataset.feather', 'covid_FNIR.feather']\n",
    "combined_df = load_data_from_category(category, included_filenames)\n",
    "\n",
    "# Drop NaN values\n",
    "combined_df.dropna(inplace=True)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(combined_df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c7c1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:56.527986Z",
     "iopub.status.busy": "2023-12-13T08:27:56.527986Z",
     "iopub.status.idle": "2023-12-13T08:27:56.532376Z",
     "shell.execute_reply": "2023-12-13T08:27:56.532376Z"
    },
    "papermill": {
     "duration": 0.008524,
     "end_time": "2023-12-13T08:27:56.533398",
     "exception": false,
     "start_time": "2023-12-13T08:27:56.524874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Breaking: At least 10 dead, 5 injured after tO gunman open fire in offices of Charlie  Hebdo,satirical mag that published Mohammed cartoons'\n",
      " 'France: 10 people dead after shooting at HQ of satirical weekly newspaper #CharlieHebdo, according to witnesses http://t.co/FkYxGmuS58'\n",
      " 'Ten killed in shooting at headquarters of French satirical weekly Charlie Hebdo, says French media citing witnesses #c4news'\n",
      " 'BREAKING: 10 dead in shooting at headquarters of French satirical weekly #CharlieHebdo - French media citing witnesses. #France'\n",
      " 'Reuters: 10 people shot dead at headquarters of French satirical weekly publication Charlie Hebdo in #Paris after gunmen stormed the office']\n",
      "[0 0 0 0 0]\n",
      "Number of unique classes: 2\n",
      "Class 0: 5089 instances\n",
      "Class 1: 1335 instances\n"
     ]
    }
   ],
   "source": [
    "# May need to include more columns to process metadata\n",
    "texts = combined_df['text'].values\n",
    "labels = combined_df['label'].values\n",
    "num_classes = combined_df['label'].nunique()\n",
    "\n",
    "print(texts[:5])\n",
    "print(labels[:5])\n",
    "print(f\"Number of unique classes: {num_classes}\")\n",
    "\n",
    "unique_classes, class_counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "for class_label, count in zip(unique_classes, class_counts):\n",
    "  print(f\"Class {class_label}: {count} instances\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b471a1d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:56.540379Z",
     "iopub.status.busy": "2023-12-13T08:27:56.540379Z",
     "iopub.status.idle": "2023-12-13T08:27:56.543831Z",
     "shell.execute_reply": "2023-12-13T08:27:56.543831Z"
    },
    "papermill": {
     "duration": 0.008488,
     "end_time": "2023-12-13T08:27:56.544869",
     "exception": false,
     "start_time": "2023-12-13T08:27:56.536381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=7623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fca9291d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:56.551845Z",
     "iopub.status.busy": "2023-12-13T08:27:56.551845Z",
     "iopub.status.idle": "2023-12-13T08:27:57.018874Z",
     "shell.execute_reply": "2023-12-13T08:27:57.018874Z"
    },
    "papermill": {
     "duration": 0.472014,
     "end_time": "2023-12-13T08:27:57.019879",
     "exception": false,
     "start_time": "2023-12-13T08:27:56.547865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained BERT (or BERT variation) model and tokenizer\n",
    "model_mapping = {\n",
    "    0: (BertTokenizer, BertForSequenceClassification, 'bert-base-uncased'),\n",
    "    1: (BertTokenizer, BertForSequenceClassification, 'bert-base-cased'),\n",
    "    2: (DistilBertTokenizer, DistilBertForSequenceClassification, 'distilbert-base-uncased-finetuned-sst-2-english'),\n",
    "    3: (DistilBertTokenizer, DistilBertForSequenceClassification, 'distilbert-base-uncased'),\n",
    "    4: (RobertaTokenizer, RobertaForSequenceClassification, 'roberta-base'),\n",
    "    5: (AlbertTokenizer, AlbertForSequenceClassification, 'albert-base-v2')\n",
    "}\n",
    "\n",
    "tokenizer_class, model_class, model_name = model_mapping.get(select_model, (None, None, None))\n",
    "\n",
    "if tokenizer_class and model_class and model_name:\n",
    "    tokenizer = tokenizer_class.from_pretrained(model_name)\n",
    "    model = model_class.from_pretrained(model_name, num_labels=2)\n",
    "else:\n",
    "    logging.error(f\"Invalid model selection: {select_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9561789a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:57.027891Z",
     "iopub.status.busy": "2023-12-13T08:27:57.027891Z",
     "iopub.status.idle": "2023-12-13T08:27:57.032558Z",
     "shell.execute_reply": "2023-12-13T08:27:57.032558Z"
    },
    "papermill": {
     "duration": 0.009683,
     "end_time": "2023-12-13T08:27:57.033563",
     "exception": false,
     "start_time": "2023-12-13T08:27:57.023880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze the layers up to the specified layer\n",
    "if freeze_layers_up_to > 0:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if select_model == 0 or select_model == 1:\n",
    "        print(\"Layers: \"+str(len(model.bert.encoder.layer)))\n",
    "        for param in model.bert.embeddings.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif select_model == 2 or select_model == 3:\n",
    "        print(\"Layers: \"+str(len(model.distilbert.transformer.layer)))\n",
    "        for param in model.distilbert.embeddings.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif select_model == 4:\n",
    "        print(\"Layers: \"+str(len(model.roberta.encoder.layer)))\n",
    "        for param in model.roberta.embeddings.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif select_model == 5:\n",
    "        print(\"Layers: \"+str(len(model.albert.encoder.albert_layer_groups)))\n",
    "        for param in model.albert.embeddings.parameters():\n",
    "            param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eec6007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:57.040564Z",
     "iopub.status.busy": "2023-12-13T08:27:57.040564Z",
     "iopub.status.idle": "2023-12-13T08:27:57.937445Z",
     "shell.execute_reply": "2023-12-13T08:27:57.937445Z"
    },
    "papermill": {
     "duration": 0.901881,
     "end_time": "2023-12-13T08:27:57.938448",
     "exception": false,
     "start_time": "2023-12-13T08:27:57.036567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize the texts\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ae68874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:57.946957Z",
     "iopub.status.busy": "2023-12-13T08:27:57.945967Z",
     "iopub.status.idle": "2023-12-13T08:27:58.021475Z",
     "shell.execute_reply": "2023-12-13T08:27:58.021475Z"
    },
    "papermill": {
     "duration": 0.082039,
     "end_time": "2023-12-13T08:27:58.023488",
     "exception": false,
     "start_time": "2023-12-13T08:27:57.941449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the encodings to PyTorch tensors\n",
    "train_inputs = torch.tensor(train_encodings['input_ids'])\n",
    "train_masks = torch.tensor(train_encodings['attention_mask'])\n",
    "train_labels = torch.tensor(train_labels)\n",
    "\n",
    "test_inputs = torch.tensor(test_encodings['input_ids'])\n",
    "test_masks = torch.tensor(test_encodings['attention_mask'])\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "# Create a DataLoader for training and testing\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=8)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_dataloader = DataLoader(test_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f656743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:58.029515Z",
     "iopub.status.busy": "2023-12-13T08:27:58.029515Z",
     "iopub.status.idle": "2023-12-13T08:27:58.032656Z",
     "shell.execute_reply": "2023-12-13T08:27:58.032656Z"
    },
    "papermill": {
     "duration": 0.008155,
     "end_time": "2023-12-13T08:27:58.033661",
     "exception": false,
     "start_time": "2023-12-13T08:27:58.025506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e9de17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:27:58.040661Z",
     "iopub.status.busy": "2023-12-13T08:27:58.039660Z",
     "iopub.status.idle": "2023-12-13T08:28:34.899150Z",
     "shell.execute_reply": "2023-12-13T08:28:34.899150Z"
    },
    "papermill": {
     "duration": 36.863506,
     "end_time": "2023-12-13T08:28:34.900166",
     "exception": false,
     "start_time": "2023-12-13T08:27:58.036660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Move the model and data to the GPU\n",
    "model.to(device)\n",
    "train_inputs, train_masks, train_labels = train_inputs.to(device), train_masks.to(device), train_labels.to(device)\n",
    "test_inputs, test_masks, test_labels = test_inputs.to(device), test_masks.to(device), test_labels.to(device)\n",
    "\n",
    "# Define class weights based on class imbalance\n",
    "class_weights = [weight_for_class_0, weight_for_class_1]\n",
    "\n",
    "# Define the loss function with class weights\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device))\n",
    "\n",
    "# Define the optimizer with a learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Fine-tune the pre-trained BERT model\n",
    "train_start_time = time.time()\n",
    "model.train()\n",
    "model.to(device)\n",
    "for batch in train_dataloader:\n",
    "    optimizer.zero_grad()\n",
    "    inputs = {'input_ids': batch[0].to(device), 'attention_mask': batch[1].to(device), 'labels': batch[2].to(device)}\n",
    "    outputs = model(**inputs)\n",
    "    loss = loss_fn(outputs.logits, inputs['labels'])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "train_end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bcc40d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:28:34.909165Z",
     "iopub.status.busy": "2023-12-13T08:28:34.909165Z",
     "iopub.status.idle": "2023-12-13T08:28:38.072029Z",
     "shell.execute_reply": "2023-12-13T08:28:38.072029Z"
    },
    "papermill": {
     "duration": 3.168869,
     "end_time": "2023-12-13T08:28:38.074034",
     "exception": false,
     "start_time": "2023-12-13T08:28:34.905165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "eval_start_time = time.time()\n",
    "model.eval()\n",
    "predictions = []\n",
    "for batch in test_dataloader:\n",
    "    inputs = {'input_ids': batch[0].to(device), 'attention_mask': batch[1].to(device), 'labels': None}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions.extend(logits.argmax(dim=1).cpu().tolist())\n",
    "eval_end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4efc851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:28:38.082034Z",
     "iopub.status.busy": "2023-12-13T08:28:38.082034Z",
     "iopub.status.idle": "2023-12-13T08:28:38.099834Z",
     "shell.execute_reply": "2023-12-13T08:28:38.099834Z"
    },
    "papermill": {
     "duration": 0.023804,
     "end_time": "2023-12-13T08:28:38.100838",
     "exception": false,
     "start_time": "2023-12-13T08:28:38.077034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate additional metrics\n",
    "precision = precision_score(test_labels.cpu(), predictions)\n",
    "recall = recall_score(test_labels.cpu(), predictions)\n",
    "f1 = f1_score(test_labels.cpu(), predictions)\n",
    "accuracy = accuracy_score(test_labels.cpu(), predictions)\n",
    "g_mean = (recall*accuracy)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a962d2f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:28:38.109874Z",
     "iopub.status.busy": "2023-12-13T08:28:38.108839Z",
     "iopub.status.idle": "2023-12-13T08:28:38.112752Z",
     "shell.execute_reply": "2023-12-13T08:28:38.112752Z"
    },
    "papermill": {
     "duration": 0.008885,
     "end_time": "2023-12-13T08:28:38.113757",
     "exception": false,
     "start_time": "2023-12-13T08:28:38.104872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dir = './models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "saved_model_name = f\"bert_model_{run_id}.pt\"\n",
    "model_path = os.path.join(save_dir, saved_model_name)\n",
    "\n",
    "# Only save model if accuracy meets minimum threshold\n",
    "if accuracy > min_acc:\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f47be55f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:28:38.121785Z",
     "iopub.status.busy": "2023-12-13T08:28:38.120757Z",
     "iopub.status.idle": "2023-12-13T08:28:38.126379Z",
     "shell.execute_reply": "2023-12-13T08:28:38.126379Z"
    },
    "papermill": {
     "duration": 0.010607,
     "end_time": "2023-12-13T08:28:38.127383",
     "exception": false,
     "start_time": "2023-12-13T08:28:38.116776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Training time: 35.501657485961914 seconds\n",
      "Inference time: 3.1587584018707275 seconds\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F-score: 0.0\n",
      "Accuracy: 0.7782101167315175\n",
      "G-mean: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Log the results\n",
    "logging.info(\"Evaluation Results\")\n",
    "logging.info(f\"Training time: {train_end_time - train_start_time} seconds\")\n",
    "logging.info(f\"Inference time: {eval_end_time - eval_start_time} seconds\")\n",
    "logging.info(f\"Precision: {precision}\")\n",
    "logging.info(f\"Recall: {recall}\")\n",
    "logging.info(f\"F-score: {f1}\")\n",
    "logging.info(f\"Accuracy: {accuracy}\")\n",
    "logging.info(f\"G-mean: {g_mean}\")\n",
    "logging.info(\"Additional Info\")\n",
    "logging.info(f\"Model name: {model_name}\")\n",
    "logging.info(f\"Datasets list: {categories}\")\n",
    "logging.info(f\"Layers frozen: {freeze_layers_up_to}\")\n",
    "logging.info(f\"Learning rate: {learning_rate}\")\n",
    "logging.info(f\"Class weights: {class_weights}\")\n",
    "if accuracy > min_acc:\n",
    "  logging.info(f\"Model saved to: {model_path}\")\n",
    "else:\n",
    "  logging.info(\"Model not saved, didn't meet minimum accuracy threshold\")\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"Training time: {train_end_time - train_start_time} seconds\")\n",
    "print(f\"Inference time: {eval_end_time - eval_start_time} seconds\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F-score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"G-mean: {g_mean}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 52.150072,
   "end_time": "2023-12-13T08:28:39.153039",
   "environment_variables": {},
   "exception": null,
   "input_path": "detection.ipynb",
   "output_path": "output_detection_politics_model_5.ipynb",
   "parameters": {
    "categories": "politics",
    "freeze_layers_up_to": 0,
    "learning_rate": 1e-05,
    "min_acc": 0.8,
    "select_model": 5,
    "weight_for_class_0": 0.45,
    "weight_for_class_1": 0.55
   },
   "start_time": "2023-12-13T08:27:47.002967",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}