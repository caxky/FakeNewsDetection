{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69cfc5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:44.572024Z",
     "iopub.status.busy": "2023-12-20T21:29:44.571025Z",
     "iopub.status.idle": "2023-12-20T21:29:50.395411Z",
     "shell.execute_reply": "2023-12-20T21:29:50.395411Z"
    },
    "papermill": {
     "duration": 5.829907,
     "end_time": "2023-12-20T21:29:50.397418",
     "exception": false,
     "start_time": "2023-12-20T21:29:44.567511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (1.26.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\user\\anaconda3\\lib\\site-packages (11.0.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\user\\anaconda3\\lib\\site-packages (0.25.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\user\\anaconda3\\lib\\site-packages (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: datetime in c:\\users\\user\\anaconda3\\lib\\site-packages (5.3)\n",
      "Requirement already satisfied: imblearn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\user\\anaconda3\\lib\\site-packages (0.1.99)\n",
      "Requirement already satisfied: papermill in c:\\users\\user\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.25.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (6.25.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (8.16.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (5.10.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipywidgets) (4.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\user\\anaconda3\\lib\\site-packages (from datetime) (5.4.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from imblearn) (0.11.0)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from papermill) (8.1.7)\n",
      "Requirement already satisfied: nbformat>=5.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from papermill) (5.9.2)\n",
      "Requirement already satisfied: nbclient>=0.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from papermill) (0.8.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\user\\anaconda3\\lib\\site-packages (from papermill) (0.4)\n",
      "Requirement already satisfied: tenacity>=5.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from papermill) (8.2.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (8.3.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.8)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
      "Requirement already satisfied: backcall in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\user\\anaconda3\\lib\\site-packages (from nbformat>=5.1.2->papermill) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nbformat>=5.1.2->papermill) (4.19.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from zope.interface->datetime) (68.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.1.2->papermill) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.1.2->papermill) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.1.2->papermill) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.1.2->papermill) (0.10.6)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (306)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.8)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy transformers pandas torch scikit-learn pyarrow accelerate transformers[torch] transformers[sentencepiece] ipywidgets tqdm datetime imblearn sentencepiece papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43343f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:50.404950Z",
     "iopub.status.busy": "2023-12-20T21:29:50.404950Z",
     "iopub.status.idle": "2023-12-20T21:29:53.719508Z",
     "shell.execute_reply": "2023-12-20T21:29:53.718940Z"
    },
    "papermill": {
     "duration": 3.319505,
     "end_time": "2023-12-20T21:29:53.720455",
     "exception": false,
     "start_time": "2023-12-20T21:29:50.400950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, DistilBertTokenizer, DistilBertForSequenceClassification ,AlbertTokenizer, AlbertForSequenceClassification, RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e60c78",
   "metadata": {
    "papermill": {
     "duration": 0.003002,
     "end_time": "2023-12-20T21:29:53.727456",
     "exception": false,
     "start_time": "2023-12-20T21:29:53.724454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1720cbee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:53.735008Z",
     "iopub.status.busy": "2023-12-20T21:29:53.734009Z",
     "iopub.status.idle": "2023-12-20T21:29:53.738731Z",
     "shell.execute_reply": "2023-12-20T21:29:53.738731Z"
    },
    "papermill": {
     "duration": 0.010248,
     "end_time": "2023-12-20T21:29:53.740247",
     "exception": false,
     "start_time": "2023-12-20T21:29:53.729999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, epochs, optimizer, loss_fn, train_dataloader):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {'input_ids': batch[0].to(device), 'attention_mask': batch[1].to(device), 'labels': batch[2].to(device)}\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, inputs['labels'])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # total_loss += loss.item()\n",
    "            total_loss += loss\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        print(f\"Epoch {epoch+1} average train loss: {avg_train_loss}\")\n",
    "        logging.info(f\"Epoch {epoch+1} average train loss: {avg_train_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c5941",
   "metadata": {
    "papermill": {
     "duration": 0.001997,
     "end_time": "2023-12-20T21:29:53.745253",
     "exception": false,
     "start_time": "2023-12-20T21:29:53.743256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ee283d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:53.752789Z",
     "iopub.status.busy": "2023-12-20T21:29:53.751789Z",
     "iopub.status.idle": "2023-12-20T21:29:53.755624Z",
     "shell.execute_reply": "2023-12-20T21:29:53.755624Z"
    },
    "papermill": {
     "duration": 0.00937,
     "end_time": "2023-12-20T21:29:53.757641",
     "exception": false,
     "start_time": "2023-12-20T21:29:53.748271",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Default parameters, Papermill will overwrite these\n",
    "categories = 'science'\n",
    "select_model = 0\n",
    "freeze_layers_up_to = 0\n",
    "weight_for_class_0 = 0.45\n",
    "weight_for_class_1 = 0.55\n",
    "learning_rate = 0.00001\n",
    "min_acc = 0.85\n",
    "batch_size = 8\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3e03464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:53.764186Z",
     "iopub.status.busy": "2023-12-20T21:29:53.764186Z",
     "iopub.status.idle": "2023-12-20T21:29:53.767939Z",
     "shell.execute_reply": "2023-12-20T21:29:53.766930Z"
    },
    "papermill": {
     "duration": 0.007762,
     "end_time": "2023-12-20T21:29:53.767939",
     "exception": false,
     "start_time": "2023-12-20T21:29:53.760177",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "freeze_layers_up_to = 0\n",
    "weight_for_class_0 = 0.45\n",
    "weight_for_class_1 = 0.55\n",
    "min_acc = 0.8\n",
    "select_model = 0\n",
    "categories = \"science\"\n",
    "epochs = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b73255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:53.775455Z",
     "iopub.status.busy": "2023-12-20T21:29:53.775455Z",
     "iopub.status.idle": "2023-12-20T21:29:53.779574Z",
     "shell.execute_reply": "2023-12-20T21:29:53.779484Z"
    },
    "papermill": {
     "duration": 0.009036,
     "end_time": "2023-12-20T21:29:53.780491",
     "exception": false,
     "start_time": "2023-12-20T21:29:53.771455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_random_string(length=10):\n",
    "    letters = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choice(letters) for _ in range(length))\n",
    "\n",
    "run_id = generate_random_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71c02ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:53.788492Z",
     "iopub.status.busy": "2023-12-20T21:29:53.788492Z",
     "iopub.status.idle": "2023-12-20T21:29:53.793040Z",
     "shell.execute_reply": "2023-12-20T21:29:53.793040Z"
    },
    "papermill": {
     "duration": 0.009508,
     "end_time": "2023-12-20T21:29:53.794002",
     "exception": false,
     "start_time": "2023-12-20T21:29:53.784494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_dir_mapping = {\n",
    "  'crime': './results/crime',\n",
    "  'science': './results/science',\n",
    "  'health': './results/health',\n",
    "  'politics': './results/politics',\n",
    "  'social_media': './results/social_media'\n",
    "}\n",
    "\n",
    "log_dir = log_dir_mapping.get(categories, './results')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "log_filename = f'training_log_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\n",
    "log_filepath = os.path.join(log_dir, log_filename)\n",
    "\n",
    "logging.basicConfig(filename=log_filepath, filemode='w', format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "logging.info(f'\\nStarting detection model - {run_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e5bbe2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:53.801516Z",
     "iopub.status.busy": "2023-12-20T21:29:53.800517Z",
     "iopub.status.idle": "2023-12-20T21:29:53.833404Z",
     "shell.execute_reply": "2023-12-20T21:29:53.832398Z"
    },
    "papermill": {
     "duration": 0.037406,
     "end_time": "2023-12-20T21:29:53.834408",
     "exception": false,
     "start_time": "2023-12-20T21:29:53.797002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text  label  \\\n",
      "0    Global warming is driving polar bears toward e...      0   \n",
      "1    The sun has gone into ‘lockdown’ which could c...      0   \n",
      "2    They tell us that we are the primary forces co...      0   \n",
      "3    The Great Barrier Reef is experiencing the mos...      0   \n",
      "4    Volcanoes Melting West Antarctic Glaciers, Not...      0   \n",
      "..                                                 ...    ...   \n",
      "902  No warming since at least 1995, no melting gla...      1   \n",
      "903  This was the case last year too, while earlier...      1   \n",
      "904  \"Disasters Cost More Than Ever — But Not Becau...      1   \n",
      "905  CO2 constitutes 80% of the non-condensing gree...      1   \n",
      "906           the Great Barrier Reef is in fine fettle      1   \n",
      "\n",
      "                                              metadata  \n",
      "0    [{'article': 'Extinction risk from global warm...  \n",
      "1    [{'article': 'Famine', 'entropy': 0.0, 'eviden...  \n",
      "2    [{'article': 'Carbon dioxide', 'entropy': 0.0,...  \n",
      "3    [{'article': 'Coral bleaching', 'entropy': 0.0...  \n",
      "4    [{'article': 'Antarctica', 'entropy': 0.693147...  \n",
      "..                                                 ...  \n",
      "902  [{'article': 'Global warming', 'entropy': 0.0,...  \n",
      "903  [{'article': 'Arctic methane emissions', 'entr...  \n",
      "904  [{'article': 'Climate change mitigation', 'ent...  \n",
      "905  [{'article': 'Greenhouse gas', 'entropy': 0.0,...  \n",
      "906  [{'article': 'Great Barrier Reef', 'entropy': ...  \n",
      "\n",
      "[907 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "root_dir = '../data'\n",
    "\n",
    "def load_data_from_category(category):\n",
    "    files = os.listdir(os.path.join(root_dir, category))\n",
    "    dataframes = []\n",
    "    for file in files:\n",
    "        if file.endswith('.feather'):\n",
    "            df = pd.read_feather(os.path.join(root_dir, category, file))\n",
    "            dataframes.append(df)\n",
    "    return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Use this one when running multiple categories\n",
    "#combined_dataframes = [load_data_from_category(category) for category in categories] \n",
    "# This one is for single category\n",
    "combined_dataframes = [load_data_from_category(categories)]\n",
    "combined_df = pd.concat(combined_dataframes, ignore_index=True)\n",
    "combined_df.dropna(inplace=True)\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9abf2e88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:53.848444Z",
     "iopub.status.busy": "2023-12-20T21:29:53.848444Z",
     "iopub.status.idle": "2023-12-20T21:29:53.856176Z",
     "shell.execute_reply": "2023-12-20T21:29:53.856176Z"
    },
    "papermill": {
     "duration": 0.015739,
     "end_time": "2023-12-20T21:29:53.858182",
     "exception": false,
     "start_time": "2023-12-20T21:29:53.842443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef load_data_from_category(category, filenames):\\n    dataframes = []\\n    for file_name in filenames:\\n        file_path = os.path.join(root_dir, category, file_name)\\n        if os.path.exists(file_path):\\n            df = pd.read_feather(file_path)\\n            dataframes.append(df)\\n        else:\\n            print(f\"The file \\'{file_name}\\' in the \\'{category}\\' category does not exist.\")\\n    return pd.concat(dataframes, ignore_index=True)\\n\\nroot_dir = \\'../data\\'\\ncategory = \\'health\\'\\n\\n# List of filenames to include in combined_df\\n#included_filenames = [\\'isot_dataset.feather\\', \\'fake_news_dataset.feather\\', \\'pheme.feather\\', \\'liar_dataset.feather\\', \\'politifact_dataset.feather\\']\\nincluded_filenames = [\\'covid_claims.feather\\', \\'covid_fake_news_dataset.feather\\', \\'covid_FNIR.feather\\']\\ncombined_df = load_data_from_category(category, included_filenames)\\n\\n# Drop NaN values\\ncombined_df.dropna(inplace=True)\\n\\n# Print the resulting DataFrame\\nprint(combined_df)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def load_data_from_category(category, filenames):\n",
    "    dataframes = []\n",
    "    for file_name in filenames:\n",
    "        file_path = os.path.join(root_dir, category, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_feather(file_path)\n",
    "            dataframes.append(df)\n",
    "        else:\n",
    "            print(f\"The file '{file_name}' in the '{category}' category does not exist.\")\n",
    "    return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "root_dir = '../data'\n",
    "category = 'health'\n",
    "\n",
    "# List of filenames to include in combined_df\n",
    "#included_filenames = ['isot_dataset.feather', 'fake_news_dataset.feather', 'pheme.feather', 'liar_dataset.feather', 'politifact_dataset.feather']\n",
    "included_filenames = ['covid_claims.feather', 'covid_fake_news_dataset.feather', 'covid_FNIR.feather']\n",
    "combined_df = load_data_from_category(category, included_filenames)\n",
    "\n",
    "# Drop NaN values\n",
    "combined_df.dropna(inplace=True)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(combined_df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b81b1e4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:53.865695Z",
     "iopub.status.busy": "2023-12-20T21:29:53.864695Z",
     "iopub.status.idle": "2023-12-20T21:29:53.870200Z",
     "shell.execute_reply": "2023-12-20T21:29:53.870200Z"
    },
    "papermill": {
     "duration": 0.011517,
     "end_time": "2023-12-20T21:29:53.872213",
     "exception": false,
     "start_time": "2023-12-20T21:29:53.860696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Global warming is driving polar bears toward extinction'\n",
      " 'The sun has gone into ‘lockdown’ which could cause freezing weather, earthquakes and famine, say scientists'\n",
      " 'They tell us that we are the primary forces controlling earth temperatures by the burning of fossil fuels and releasing their carbon dioxide.'\n",
      " 'The Great Barrier Reef is experiencing the most widespread bleaching ever recorded'\n",
      " 'Volcanoes Melting West Antarctic Glaciers, Not Global Warming']\n",
      "[0 0 0 0 0]\n",
      "Number of unique classes: 2\n",
      "Class 0: 654 instances\n",
      "Class 1: 253 instances\n"
     ]
    }
   ],
   "source": [
    "# May need to include more columns to process metadata\n",
    "texts = combined_df['text'].values\n",
    "labels = combined_df['label'].values\n",
    "num_classes = combined_df['label'].nunique()\n",
    "\n",
    "print(texts[:5])\n",
    "print(labels[:5])\n",
    "print(f\"Number of unique classes: {num_classes}\")\n",
    "\n",
    "unique_classes, class_counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "for class_label, count in zip(unique_classes, class_counts):\n",
    "  print(f\"Class {class_label}: {count} instances\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a55845db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:53.879725Z",
     "iopub.status.busy": "2023-12-20T21:29:53.878724Z",
     "iopub.status.idle": "2023-12-20T21:29:53.883474Z",
     "shell.execute_reply": "2023-12-20T21:29:53.883474Z"
    },
    "papermill": {
     "duration": 0.009268,
     "end_time": "2023-12-20T21:29:53.884480",
     "exception": false,
     "start_time": "2023-12-20T21:29:53.875212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=7623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5b6326c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:53.892001Z",
     "iopub.status.busy": "2023-12-20T21:29:53.892001Z",
     "iopub.status.idle": "2023-12-20T21:29:54.866832Z",
     "shell.execute_reply": "2023-12-20T21:29:54.866832Z"
    },
    "papermill": {
     "duration": 0.980359,
     "end_time": "2023-12-20T21:29:54.868839",
     "exception": false,
     "start_time": "2023-12-20T21:29:53.888480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained BERT (or BERT variation) model and tokenizer\n",
    "model_mapping = {\n",
    "    0: (BertTokenizer, BertForSequenceClassification, 'bert-base-uncased'),\n",
    "    1: (BertTokenizer, BertForSequenceClassification, 'bert-base-cased'),\n",
    "    2: (DistilBertTokenizer, DistilBertForSequenceClassification, 'distilbert-base-uncased-finetuned-sst-2-english'),\n",
    "    3: (DistilBertTokenizer, DistilBertForSequenceClassification, 'distilbert-base-uncased'),\n",
    "    4: (RobertaTokenizer, RobertaForSequenceClassification, 'roberta-base'),\n",
    "    5: (AlbertTokenizer, AlbertForSequenceClassification, 'albert-base-v2')\n",
    "}\n",
    "\n",
    "tokenizer_class, model_class, model_name = model_mapping.get(select_model, (None, None, None))\n",
    "\n",
    "if tokenizer_class and model_class and model_name:\n",
    "    tokenizer = tokenizer_class.from_pretrained(model_name)\n",
    "    model = model_class.from_pretrained(model_name, num_labels=2)\n",
    "else:\n",
    "    logging.error(f\"Invalid model selection: {select_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fde04bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:54.879897Z",
     "iopub.status.busy": "2023-12-20T21:29:54.878896Z",
     "iopub.status.idle": "2023-12-20T21:29:54.884521Z",
     "shell.execute_reply": "2023-12-20T21:29:54.884521Z"
    },
    "papermill": {
     "duration": 0.01318,
     "end_time": "2023-12-20T21:29:54.886528",
     "exception": false,
     "start_time": "2023-12-20T21:29:54.873348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze the layers up to the specified layer\n",
    "if freeze_layers_up_to > 0:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if select_model == 0 or select_model == 1:\n",
    "        print(\"Layers: \"+str(len(model.bert.encoder.layer)))\n",
    "        for param in model.bert.embeddings.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif select_model == 2 or select_model == 3:\n",
    "        print(\"Layers: \"+str(len(model.distilbert.transformer.layer)))\n",
    "        for param in model.distilbert.embeddings.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif select_model == 4:\n",
    "        print(\"Layers: \"+str(len(model.roberta.encoder.layer)))\n",
    "        for param in model.roberta.embeddings.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif select_model == 5:\n",
    "        print(\"Layers: \"+str(len(model.albert.encoder.albert_layer_groups)))\n",
    "        for param in model.albert.embeddings.parameters():\n",
    "            param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2f9cf09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:54.896041Z",
     "iopub.status.busy": "2023-12-20T21:29:54.895042Z",
     "iopub.status.idle": "2023-12-20T21:29:55.172422Z",
     "shell.execute_reply": "2023-12-20T21:29:55.171415Z"
    },
    "papermill": {
     "duration": 0.283392,
     "end_time": "2023-12-20T21:29:55.173422",
     "exception": false,
     "start_time": "2023-12-20T21:29:54.890030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize the texts\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c118f6fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:55.183446Z",
     "iopub.status.busy": "2023-12-20T21:29:55.183446Z",
     "iopub.status.idle": "2023-12-20T21:29:55.202120Z",
     "shell.execute_reply": "2023-12-20T21:29:55.202120Z"
    },
    "papermill": {
     "duration": 0.025216,
     "end_time": "2023-12-20T21:29:55.204151",
     "exception": false,
     "start_time": "2023-12-20T21:29:55.178935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the encodings to PyTorch tensors\n",
    "train_inputs = torch.tensor(train_encodings['input_ids'])\n",
    "train_masks = torch.tensor(train_encodings['attention_mask'])\n",
    "train_labels = torch.tensor(train_labels)\n",
    "\n",
    "test_inputs = torch.tensor(test_encodings['input_ids'])\n",
    "test_masks = torch.tensor(test_encodings['attention_mask'])\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "# Create a DataLoader for training and testing\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df55a763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:55.212637Z",
     "iopub.status.busy": "2023-12-20T21:29:55.212637Z",
     "iopub.status.idle": "2023-12-20T21:29:55.215747Z",
     "shell.execute_reply": "2023-12-20T21:29:55.215747Z"
    },
    "papermill": {
     "duration": 0.008627,
     "end_time": "2023-12-20T21:29:55.216752",
     "exception": false,
     "start_time": "2023-12-20T21:29:55.208125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9786f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:29:55.226272Z",
     "iopub.status.busy": "2023-12-20T21:29:55.225271Z",
     "iopub.status.idle": "2023-12-20T21:34:33.538509Z",
     "shell.execute_reply": "2023-12-20T21:34:33.538509Z"
    },
    "papermill": {
     "duration": 278.322354,
     "end_time": "2023-12-20T21:34:33.543619",
     "exception": false,
     "start_time": "2023-12-20T21:29:55.221265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 average train loss: 0.6214894652366638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 average train loss: 0.5412142276763916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 average train loss: 0.3718872666358948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 average train loss: 0.20714665949344635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 average train loss: 0.1572132408618927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 average train loss: 0.14297057688236237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 average train loss: 0.04648645594716072\n"
     ]
    }
   ],
   "source": [
    "# Move the model and data to the GPU\n",
    "model.to(device)\n",
    "train_inputs, train_masks, train_labels = train_inputs.to(device), train_masks.to(device), train_labels.to(device)\n",
    "test_inputs, test_masks, test_labels = test_inputs.to(device), test_masks.to(device), test_labels.to(device)\n",
    "\n",
    "# Define class weights based on class imbalance\n",
    "class_weights = [weight_for_class_0, weight_for_class_1]\n",
    "\n",
    "# Define the loss function with class weights\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device))\n",
    "\n",
    "# Define the optimizer with a learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Fine-tune the pre-trained BERT model\n",
    "train_start_time = time.time()\n",
    "train_model(model, epochs, optimizer, loss_fn, train_dataloader)\n",
    "train_end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "226b9f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:34:33.557712Z",
     "iopub.status.busy": "2023-12-20T21:34:33.556693Z",
     "iopub.status.idle": "2023-12-20T21:34:39.035453Z",
     "shell.execute_reply": "2023-12-20T21:34:39.035453Z"
    },
    "papermill": {
     "duration": 5.487846,
     "end_time": "2023-12-20T21:34:39.037465",
     "exception": false,
     "start_time": "2023-12-20T21:34:33.549619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "eval_start_time = time.time()\n",
    "model.eval()\n",
    "predictions = []\n",
    "for batch in test_dataloader:\n",
    "    inputs = {'input_ids': batch[0].to(device), 'attention_mask': batch[1].to(device), 'labels': None}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions.extend(logits.argmax(dim=1).cpu().tolist())\n",
    "eval_end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d167bbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:34:39.052088Z",
     "iopub.status.busy": "2023-12-20T21:34:39.052088Z",
     "iopub.status.idle": "2023-12-20T21:34:39.061825Z",
     "shell.execute_reply": "2023-12-20T21:34:39.061825Z"
    },
    "papermill": {
     "duration": 0.018851,
     "end_time": "2023-12-20T21:34:39.063850",
     "exception": false,
     "start_time": "2023-12-20T21:34:39.044999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate additional metrics\n",
    "precision = precision_score(test_labels.cpu(), predictions)\n",
    "recall = recall_score(test_labels.cpu(), predictions)\n",
    "f1 = f1_score(test_labels.cpu(), predictions)\n",
    "accuracy = accuracy_score(test_labels.cpu(), predictions)\n",
    "g_mean = (recall*accuracy)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edde407e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:34:39.076941Z",
     "iopub.status.busy": "2023-12-20T21:34:39.076941Z",
     "iopub.status.idle": "2023-12-20T21:34:40.068600Z",
     "shell.execute_reply": "2023-12-20T21:34:40.068600Z"
    },
    "papermill": {
     "duration": 1.000863,
     "end_time": "2023-12-20T21:34:40.070693",
     "exception": false,
     "start_time": "2023-12-20T21:34:39.069830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dir = './models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "saved_model_name = f\"bert_model_{run_id}.pt\"\n",
    "model_path = os.path.join(save_dir, saved_model_name)\n",
    "\n",
    "# Only save model if accuracy meets minimum threshold\n",
    "if accuracy > min_acc:\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d02b771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T21:34:40.084826Z",
     "iopub.status.busy": "2023-12-20T21:34:40.084826Z",
     "iopub.status.idle": "2023-12-20T21:34:40.092738Z",
     "shell.execute_reply": "2023-12-20T21:34:40.092738Z"
    },
    "papermill": {
     "duration": 0.018049,
     "end_time": "2023-12-20T21:34:40.094743",
     "exception": false,
     "start_time": "2023-12-20T21:34:40.076694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Training time: 276.7071738243103 seconds\n",
      "Inference time: 5.473334550857544 seconds\n",
      "Precision: 0.6136363636363636\n",
      "Recall: 0.6136363636363636\n",
      "F-score: 0.6136363636363636\n",
      "Accuracy: 0.8131868131868132\n",
      "G-mean: 0.706400027605463\n",
      "Epoch: 7\n",
      "Batch size: 8\n"
     ]
    }
   ],
   "source": [
    "# Log the results\n",
    "logging.info(\"Evaluation Results\")\n",
    "logging.info(f\"Training time: {train_end_time - train_start_time} seconds\")\n",
    "logging.info(f\"Inference time: {eval_end_time - eval_start_time} seconds\")\n",
    "logging.info(f\"Precision: {precision}\")\n",
    "logging.info(f\"Recall: {recall}\")\n",
    "logging.info(f\"F-score: {f1}\")\n",
    "logging.info(f\"Accuracy: {accuracy}\")\n",
    "logging.info(f\"G-mean: {g_mean}\")\n",
    "logging.info(\"Additional Info\")\n",
    "logging.info(f\"Model name: {model_name}\")\n",
    "logging.info(f\"Datasets list: {categories}\")\n",
    "logging.info(f\"Layers frozen: {freeze_layers_up_to}\")\n",
    "logging.info(f\"Learning rate: {learning_rate}\")\n",
    "logging.info(f\"Class weights: {class_weights}\")\n",
    "if accuracy > min_acc:\n",
    "  logging.info(f\"Model saved to: {model_path}\")\n",
    "else:\n",
    "  logging.info(\"Model not saved, didn't meet minimum accuracy threshold\")\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"Training time: {train_end_time - train_start_time} seconds\")\n",
    "print(f\"Inference time: {eval_end_time - eval_start_time} seconds\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F-score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"G-mean: {g_mean}\")\n",
    "print(f\"Epoch: {epochs}\")\n",
    "print(f\"Batch size: {batch_size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 298.041021,
   "end_time": "2023-12-20T21:34:41.302470",
   "environment_variables": {},
   "exception": null,
   "input_path": "detection.ipynb",
   "output_path": "output_detection_science_model_0.ipynb",
   "parameters": {
    "categories": "science",
    "epochs": 7,
    "freeze_layers_up_to": 0,
    "min_acc": 0.8,
    "select_model": 0,
    "weight_for_class_0": 0.45,
    "weight_for_class_1": 0.55
   },
   "start_time": "2023-12-20T21:29:43.261449",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}