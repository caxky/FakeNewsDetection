2023-12-22 19:35:13,173 - 
Starting detection model - qin4ZBpCyn
2023-12-22 19:36:10,980 - Epoch 1 average train loss: 0.0
2023-12-22 19:36:43,758 - Epoch 2 average train loss: 0.0
2023-12-22 19:37:16,534 - Epoch 3 average train loss: 0.0
2023-12-22 19:37:49,307 - Epoch 4 average train loss: 0.0
2023-12-22 19:37:52,247 - Evaluation Results
2023-12-22 19:37:52,247 - Training time: 131.3709533214569 seconds
2023-12-22 19:37:52,247 - Inference time: 2.5369327068328857 seconds
2023-12-22 19:37:52,247 - Precision: 0.8213592233009709
2023-12-22 19:37:52,247 - Recall: 0.8376237623762376
2023-12-22 19:37:52,248 - F-score: 0.8294117647058824
2023-12-22 19:37:52,248 - Accuracy: 0.8534119629317607
2023-12-22 19:37:52,248 - G-mean: 0.845481010577879
2023-12-22 19:37:52,248 - Additional Info
2023-12-22 19:37:52,248 - Model name: distilbert-base-uncased
2023-12-22 19:37:52,248 - Datasets list: health
2023-12-22 19:37:52,248 - Dataset size: 5932
2023-12-22 19:37:52,248 - Layers frozen: 0
2023-12-22 19:37:52,248 - Learning rate: 1e-05
2023-12-22 19:37:52,248 - Class weights: Manual weights - [0.45, 0.55]
2023-12-22 19:37:52,248 - Model saved to: ./models/bert_model_qin4ZBpCyn.pt
