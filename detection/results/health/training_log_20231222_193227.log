2023-12-22 19:32:27,498 - 
Starting detection model - OhylhwACg5
2023-12-22 19:33:25,284 - Epoch 1 average train loss: 0.0
2023-12-22 19:33:58,062 - Epoch 2 average train loss: 0.0
2023-12-22 19:34:30,843 - Epoch 3 average train loss: 0.0
2023-12-22 19:35:03,615 - Epoch 4 average train loss: 0.0
2023-12-22 19:35:06,628 - Evaluation Results
2023-12-22 19:35:06,629 - Training time: 131.36621809005737 seconds
2023-12-22 19:35:06,630 - Inference time: 2.5342793464660645 seconds
2023-12-22 19:35:06,630 - Precision: 0.8256704980842912
2023-12-22 19:35:06,630 - Recall: 0.8534653465346534
2023-12-22 19:35:06,630 - F-score: 0.8393378773125608
2023-12-22 19:35:06,630 - Accuracy: 0.8609941027801179
2023-12-22 19:35:06,630 - G-mean: 0.8572214593053106
2023-12-22 19:35:06,630 - Additional Info
2023-12-22 19:35:06,630 - Model name: distilbert-base-uncased
2023-12-22 19:35:06,630 - Datasets list: health
2023-12-22 19:35:06,630 - Dataset size: 5932
2023-12-22 19:35:06,630 - Layers frozen: 0
2023-12-22 19:35:06,631 - Learning rate: 1e-05
2023-12-22 19:35:06,631 - Class weights: Manual weights - [0.45, 0.55]
2023-12-22 19:35:06,631 - Model saved to: ./models/bert_model_OhylhwACg5.pt
