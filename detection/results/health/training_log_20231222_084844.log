2023-12-22 08:48:44,672 - 
Starting detection model - GKNAMmaw3Z
2023-12-22 08:50:12,273 - Epoch 1 average train loss: 0.0
2023-12-22 08:50:15,204 - Evaluation Results
2023-12-22 08:50:15,205 - Training time: 34.04138135910034 seconds
2023-12-22 08:50:15,205 - Inference time: 2.536616563796997 seconds
2023-12-22 08:50:15,205 - Precision: 0.92
2023-12-22 08:50:15,206 - Recall: 0.592079207920792
2023-12-22 08:50:15,206 - F-score: 0.7204819277108434
2023-12-22 08:50:15,206 - Accuracy: 0.8045492839090144
2023-12-22 08:50:15,206 - G-mean: 0.6901861363067863
2023-12-22 08:50:15,206 - Additional Info
2023-12-22 08:50:15,206 - Model name: distilbert-base-uncased-finetuned-sst-2-english
2023-12-22 08:50:15,207 - Datasets list: health
2023-12-22 08:50:15,207 - Dataset size: 5932
2023-12-22 08:50:15,207 - Layers frozen: 0
2023-12-22 08:50:15,207 - Learning rate: 1e-05
2023-12-22 08:50:15,207 - Class weights: Default weights - [0.5536075522589345, 0.4463924477410654]
2023-12-22 08:50:15,207 - Model saved to: ./models/bert_model_GKNAMmaw3Z.pt
