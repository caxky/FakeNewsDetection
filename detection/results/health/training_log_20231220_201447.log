2023-12-20 20:14:47,546 - 
Starting detection model - JHpWJTyBle
2023-12-20 20:17:21,765 - Evaluation Results
2023-12-20 20:17:21,765 - Training time: 114.07061457633972 seconds
2023-12-20 20:17:21,766 - Inference time: 9.205886602401733 seconds
2023-12-20 20:17:21,766 - Precision: 0.9414634146341463
2023-12-20 20:17:21,766 - Recall: 0.724202626641651
2023-12-20 20:17:21,766 - F-score: 0.8186638388123011
2023-12-20 20:17:21,766 - Accuracy: 0.8559393428812131
2023-12-20 20:17:21,766 - G-mean: 0.7873204686533326
2023-12-20 20:17:21,766 - Additional Info
2023-12-20 20:17:21,766 - Model name: distilbert-base-uncased-finetuned-sst-2-english
2023-12-20 20:17:21,766 - Datasets list: health
2023-12-20 20:17:21,766 - Dataset size: 5932
2023-12-20 20:17:21,766 - Layers frozen: 0
2023-12-20 20:17:21,766 - Learning rate: 1e-05
2023-12-20 20:17:21,767 - Class weights: Default weights - [0.5536075522589345, 0.4463924477410654]
2023-12-20 20:17:21,767 - Model saved to: ./models/bert_model_JHpWJTyBle.pt
