2023-12-22 18:32:54,581 - 
Starting detection model - 0lkKX33R7Q
2023-12-22 18:33:23,473 - Epoch 1 average train loss: 0.0
2023-12-22 18:33:47,706 - Epoch 2 average train loss: 0.0
2023-12-22 18:34:11,768 - Epoch 3 average train loss: 0.0
2023-12-22 18:34:35,974 - Epoch 4 average train loss: 0.0
2023-12-22 18:35:00,280 - Epoch 5 average train loss: 0.0
2023-12-22 18:35:01,937 - Evaluation Results
2023-12-22 18:35:01,938 - Training time: 120.75572109222412 seconds
2023-12-22 18:35:01,938 - Inference time: 1.0558195114135742 seconds
2023-12-22 18:35:01,938 - Precision: 0.743421052631579
2023-12-22 18:35:01,938 - Recall: 0.7929824561403509
2023-12-22 18:35:01,938 - F-score: 0.767402376910017
2023-12-22 18:35:01,938 - Accuracy: 0.8933852140077821
2023-12-22 18:35:01,939 - G-mean: 0.841688066496944
2023-12-22 18:35:01,939 - Additional Info
2023-12-22 18:35:01,939 - Model name: bert-base-uncased
2023-12-22 18:35:01,939 - Datasets list: politics
2023-12-22 18:35:01,939 - Dataset size: 6424
2023-12-22 18:35:01,939 - Layers frozen: 0
2023-12-22 18:35:01,939 - Learning rate: 1e-05
2023-12-22 18:35:01,940 - Class weights: Manual weights - [0.45, 0.55]
2023-12-22 18:35:01,940 - Model saved to: ./models/bert_model_0lkKX33R7Q.pt
