2023-12-22 18:55:34,765 - 
Starting detection model - 6TWpfXjCfi
2023-12-22 18:56:03,018 - Epoch 1 average train loss: 0.0
2023-12-22 18:56:26,891 - Epoch 2 average train loss: 0.0
2023-12-22 18:56:50,923 - Epoch 3 average train loss: 0.0
2023-12-22 18:57:14,491 - Epoch 4 average train loss: 0.0
2023-12-22 18:57:38,387 - Epoch 5 average train loss: 0.0
2023-12-22 18:58:02,571 - Epoch 6 average train loss: 0.0
2023-12-22 18:58:25,915 - Epoch 7 average train loss: 0.0
2023-12-22 18:58:27,674 - Evaluation Results
2023-12-22 18:58:27,676 - Training time: 166.25025391578674 seconds
2023-12-22 18:58:27,676 - Inference time: 1.0636539459228516 seconds
2023-12-22 18:58:27,677 - Precision: 0.854251012145749
2023-12-22 18:58:27,677 - Recall: 0.7403508771929824
2023-12-22 18:58:27,677 - F-score: 0.7932330827067668
2023-12-22 18:58:27,677 - Accuracy: 0.914396887159533
2023-12-22 18:58:27,677 - G-mean: 0.8227846240123188
2023-12-22 18:58:27,677 - Additional Info
2023-12-22 18:58:27,677 - Model name: bert-base-uncased
2023-12-22 18:58:27,677 - Datasets list: politics
2023-12-22 18:58:27,677 - Dataset size: 6424
2023-12-22 18:58:27,677 - Layers frozen: 0
2023-12-22 18:58:27,677 - Learning rate: 1e-05
2023-12-22 18:58:27,677 - Class weights: Manual weights - [0.45, 0.55]
2023-12-22 18:58:27,677 - Model saved to: ./models/bert_model_6TWpfXjCfi.pt
