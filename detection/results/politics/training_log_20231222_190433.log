2023-12-22 19:04:33,691 - 
Starting detection model - vwsIq42pvM
2023-12-22 19:05:02,015 - Epoch 1 average train loss: 0.0
2023-12-22 19:05:25,345 - Epoch 2 average train loss: 0.0
2023-12-22 19:05:49,491 - Epoch 3 average train loss: 0.0
2023-12-22 19:06:13,330 - Epoch 4 average train loss: 0.0
2023-12-22 19:06:36,891 - Epoch 5 average train loss: 0.0
2023-12-22 19:07:00,905 - Epoch 6 average train loss: 0.0
2023-12-22 19:07:24,782 - Epoch 7 average train loss: 0.0
2023-12-22 19:07:26,571 - Evaluation Results
2023-12-22 19:07:26,571 - Training time: 166.49288821220398 seconds
2023-12-22 19:07:26,571 - Inference time: 1.0676543712615967 seconds
2023-12-22 19:07:26,572 - Precision: 0.871244635193133
2023-12-22 19:07:26,572 - Recall: 0.712280701754386
2023-12-22 19:07:26,572 - F-score: 0.7837837837837837
2023-12-22 19:07:26,572 - Accuracy: 0.91284046692607
2023-12-22 19:07:26,572 - G-mean: 0.806348961909112
2023-12-22 19:07:26,572 - Additional Info
2023-12-22 19:07:26,573 - Model name: bert-base-uncased
2023-12-22 19:07:26,573 - Datasets list: politics
2023-12-22 19:07:26,573 - Dataset size: 6424
2023-12-22 19:07:26,573 - Layers frozen: 0
2023-12-22 19:07:26,573 - Learning rate: 1e-05
2023-12-22 19:07:26,574 - Class weights: Manual weights - [0.45, 0.55]
2023-12-22 19:07:26,574 - Model saved to: ./models/bert_model_vwsIq42pvM.pt
