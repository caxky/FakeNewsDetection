2023-12-22 18:30:42,508 - 
Starting detection model - jpIZXD8l0F
2023-12-22 18:31:11,447 - Epoch 1 average train loss: 0.0
2023-12-22 18:31:35,102 - Epoch 2 average train loss: 0.0
2023-12-22 18:31:58,544 - Epoch 3 average train loss: 0.0
2023-12-22 18:32:22,212 - Epoch 4 average train loss: 0.0
2023-12-22 18:32:45,977 - Epoch 5 average train loss: 0.0
2023-12-22 18:32:47,733 - Evaluation Results
2023-12-22 18:32:47,733 - Training time: 118.7010486125946 seconds
2023-12-22 18:32:47,734 - Inference time: 1.056952953338623 seconds
2023-12-22 18:32:47,734 - Precision: 0.8385826771653543
2023-12-22 18:32:47,734 - Recall: 0.7473684210526316
2023-12-22 18:32:47,734 - F-score: 0.7903525046382189
2023-12-22 18:32:47,734 - Accuracy: 0.9120622568093385
2023-12-22 18:32:47,734 - G-mean: 0.8256188762215257
2023-12-22 18:32:47,734 - Additional Info
2023-12-22 18:32:47,734 - Model name: bert-base-uncased
2023-12-22 18:32:47,734 - Datasets list: politics
2023-12-22 18:32:47,734 - Dataset size: 6424
2023-12-22 18:32:47,734 - Layers frozen: 0
2023-12-22 18:32:47,734 - Learning rate: 1e-05
2023-12-22 18:32:47,734 - Class weights: Manual weights - [0.45, 0.55]
2023-12-22 18:32:47,734 - Model saved to: ./models/bert_model_jpIZXD8l0F.pt
