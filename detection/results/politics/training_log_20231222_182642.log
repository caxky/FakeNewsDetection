2023-12-22 18:26:42,725 - 
Starting detection model - 8trkQ01eyW
2023-12-22 18:27:11,224 - Epoch 1 average train loss: 0.0
2023-12-22 18:27:35,035 - Epoch 2 average train loss: 0.0
2023-12-22 18:27:58,814 - Epoch 3 average train loss: 0.0
2023-12-22 18:28:22,280 - Epoch 4 average train loss: 0.0
2023-12-22 18:28:24,053 - Evaluation Results
2023-12-22 18:28:24,054 - Training time: 94.6073591709137 seconds
2023-12-22 18:28:24,054 - Inference time: 1.0642967224121094 seconds
2023-12-22 18:28:24,054 - Precision: 0.7178683385579937
2023-12-22 18:28:24,054 - Recall: 0.8035087719298246
2023-12-22 18:28:24,054 - F-score: 0.7582781456953642
2023-12-22 18:28:24,054 - Accuracy: 0.8863813229571984
2023-12-22 18:28:24,054 - G-mean: 0.8439284141862221
2023-12-22 18:28:24,054 - Additional Info
2023-12-22 18:28:24,054 - Model name: bert-base-uncased
2023-12-22 18:28:24,054 - Datasets list: politics
2023-12-22 18:28:24,054 - Dataset size: 6424
2023-12-22 18:28:24,054 - Layers frozen: 0
2023-12-22 18:28:24,054 - Learning rate: 1e-05
2023-12-22 18:28:24,054 - Class weights: Manual weights - [0.45, 0.55]
2023-12-22 18:28:24,054 - Model saved to: ./models/bert_model_8trkQ01eyW.pt
