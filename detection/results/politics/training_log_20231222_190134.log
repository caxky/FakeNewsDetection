2023-12-22 19:01:34,621 - 
Starting detection model - 495yJLm1qv
2023-12-22 19:02:03,553 - Epoch 1 average train loss: 0.0
2023-12-22 19:02:27,174 - Epoch 2 average train loss: 0.0
2023-12-22 19:02:50,796 - Epoch 3 average train loss: 0.0
2023-12-22 19:03:14,845 - Epoch 4 average train loss: 0.0
2023-12-22 19:03:38,155 - Epoch 5 average train loss: 0.0
2023-12-22 19:04:02,093 - Epoch 6 average train loss: 0.0
2023-12-22 19:04:25,658 - Epoch 7 average train loss: 0.0
2023-12-22 19:04:27,466 - Evaluation Results
2023-12-22 19:04:27,466 - Training time: 166.1685254573822 seconds
2023-12-22 19:04:27,466 - Inference time: 1.0713376998901367 seconds
2023-12-22 19:04:27,466 - Precision: 0.7785234899328859
2023-12-22 19:04:27,466 - Recall: 0.8140350877192982
2023-12-22 19:04:27,466 - F-score: 0.7958833619210978
2023-12-22 19:04:27,468 - Accuracy: 0.9073929961089494
2023-12-22 19:04:27,468 - G-mean: 0.8594473440434995
2023-12-22 19:04:27,468 - Additional Info
2023-12-22 19:04:27,468 - Model name: bert-base-uncased
2023-12-22 19:04:27,468 - Datasets list: politics
2023-12-22 19:04:27,468 - Dataset size: 6424
2023-12-22 19:04:27,468 - Layers frozen: 0
2023-12-22 19:04:27,468 - Learning rate: 1e-05
2023-12-22 19:04:27,468 - Class weights: Manual weights - [0.45, 0.55]
2023-12-22 19:04:27,469 - Model saved to: ./models/bert_model_495yJLm1qv.pt
