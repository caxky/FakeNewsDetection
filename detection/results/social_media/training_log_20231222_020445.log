2023-12-22 02:04:45,279 - 
Starting detection model - 6mHx5i8nUC
2023-12-22 02:17:37,933 - Epoch 1 average train loss: 0.0
2023-12-22 02:23:57,485 - Epoch 2 average train loss: 0.0
2023-12-22 02:30:16,968 - Epoch 3 average train loss: 0.0
2023-12-22 02:36:36,433 - Epoch 4 average train loss: 0.0
2023-12-22 02:42:55,837 - Epoch 5 average train loss: 0.0
2023-12-22 02:49:15,630 - Epoch 6 average train loss: 0.0
2023-12-22 02:55:35,399 - Epoch 7 average train loss: 0.0
2023-12-22 02:56:04,484 - Evaluation Results
2023-12-22 02:56:04,484 - Training time: 2657.3291203975677 seconds
2023-12-22 02:56:04,484 - Inference time: 28.609919786453247 seconds
2023-12-22 02:56:04,484 - Precision: 0.9710972017673049
2023-12-22 02:56:04,484 - Recall: 0.9129456559363102
2023-12-22 02:56:04,484 - F-score: 0.9411239964317574
2023-12-22 02:56:04,485 - Accuracy: 0.9507756563245824
2023-12-22 02:56:04,485 - G-mean: 0.9316686670761885
2023-12-22 02:56:04,486 - Additional Info
2023-12-22 02:56:04,486 - Model name: distilbert-base-uncased-finetuned-sst-2-english
2023-12-22 02:56:04,486 - Datasets list: social_media
2023-12-22 02:56:04,486 - Dataset size: 67038
2023-12-22 02:56:04,486 - Layers frozen: 0
2023-12-22 02:56:04,486 - Learning rate: 1e-05
2023-12-22 02:56:04,487 - Class weights: Auto weights - [0.4296667561681434, 0.5703332438318566]
2023-12-22 02:56:04,487 - Model saved to: ./models/bert_model_6mHx5i8nUC.pt
