2023-12-16 15:14:46,669 - 
Starting detection model - lmbWpnbTuy
2023-12-16 15:15:31,719 - Epoch 1 average train loss: 0.6332566738128662
2023-12-16 15:16:12,559 - Epoch 2 average train loss: 0.5298703908920288
2023-12-16 15:16:53,781 - Epoch 3 average train loss: 0.31856009364128113
2023-12-16 15:17:36,421 - Epoch 4 average train loss: 0.2146192193031311
2023-12-16 15:17:37,680 - Evaluation Results
2023-12-16 15:17:37,680 - Training time: 166.9711892604828 seconds
2023-12-16 15:17:37,680 - Inference time: 0.4472637176513672 seconds
2023-12-16 15:17:37,680 - Precision: 0.7222222222222222
2023-12-16 15:17:37,680 - Recall: 0.29545454545454547
2023-12-16 15:17:37,680 - F-score: 0.41935483870967744
2023-12-16 15:17:37,680 - Accuracy: 0.8021978021978022
2023-12-16 15:17:37,680 - G-mean: 0.4868397960448458
2023-12-16 15:17:37,680 - Additional Info
2023-12-16 15:17:37,680 - Model name: bert-base-uncased
2023-12-16 15:17:37,680 - Datasets list: science
2023-12-16 15:17:37,680 - Layers frozen: 0
2023-12-16 15:17:37,680 - Learning rate: 0.0001
2023-12-16 15:17:37,680 - Batch size: 16
2023-12-16 15:17:37,680 - Class weights: [0.45, 0.55]
2023-12-16 15:17:37,681 - Model saved to: ./models\bert_model_lmbWpnbTuy.pt
