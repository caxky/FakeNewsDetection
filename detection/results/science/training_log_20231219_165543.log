2023-12-19 16:55:43,067 - 
Starting detection model - gbOpcwZml5
2023-12-19 16:55:52,326 - Epoch 1 average train loss: 0.6130734086036682
2023-12-19 16:55:57,959 - Epoch 2 average train loss: 0.4615931808948517
2023-12-19 16:56:03,618 - Epoch 3 average train loss: 0.24805989861488342
2023-12-19 16:56:09,267 - Epoch 4 average train loss: 0.19195204973220825
2023-12-19 16:56:14,920 - Epoch 5 average train loss: 0.05562271550297737
2023-12-19 16:56:15,412 - Evaluation Results
2023-12-19 16:56:15,412 - Training time: 29.279541730880737 seconds
2023-12-19 16:56:15,412 - Inference time: 0.4167807102203369 seconds
2023-12-19 16:56:15,412 - Precision: 0.47058823529411764
2023-12-19 16:56:15,412 - Recall: 0.5454545454545454
2023-12-19 16:56:15,412 - F-score: 0.5052631578947367
2023-12-19 16:56:15,412 - Accuracy: 0.7417582417582418
2023-12-19 16:56:15,412 - G-mean: 0.6360781434661975
2023-12-19 16:56:15,412 - Additional Info
2023-12-19 16:56:15,412 - Model name: bert-base-uncased
2023-12-19 16:56:15,412 - Datasets list: science
2023-12-19 16:56:15,412 - Layers frozen: 0
2023-12-19 16:56:15,412 - Learning rate: 3e-05
2023-12-19 16:56:15,412 - Class weights: [0.45, 0.55]
2023-12-19 16:56:15,412 - Model not saved, didn't meet minimum accuracy threshold
