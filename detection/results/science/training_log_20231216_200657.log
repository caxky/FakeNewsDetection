2023-12-16 20:06:57,268 - 
Starting detection model - UABaPlPtEy
2023-12-16 20:11:52,155 - Epoch 1 average train loss: 0.6243125200271606
2023-12-16 20:18:14,195 - Epoch 2 average train loss: 0.5118539333343506
2023-12-16 20:27:39,954 - Epoch 3 average train loss: 0.3812190294265747
2023-12-16 20:39:58,650 - Epoch 4 average train loss: 0.19922664761543274
2023-12-16 20:40:36,770 - Evaluation Results
2023-12-16 20:40:36,770 - Training time: 1978.5718858242035 seconds
2023-12-16 20:40:36,770 - Inference time: 38.05619025230408 seconds
2023-12-16 20:40:36,770 - Precision: 0.5116279069767442
2023-12-16 20:40:36,770 - Recall: 0.5
2023-12-16 20:40:36,770 - F-score: 0.5057471264367817
2023-12-16 20:40:36,770 - Accuracy: 0.7637362637362637
2023-12-16 20:40:36,770 - G-mean: 0.6179547975929404
2023-12-16 20:40:36,770 - Additional Info
2023-12-16 20:40:36,770 - Model name: bert-base-uncased
2023-12-16 20:40:36,770 - Datasets list: science
2023-12-16 20:40:36,771 - Layers frozen: 0
2023-12-16 20:40:36,771 - Learning rate: 5e-05
2023-12-16 20:40:36,771 - Batch size: 64
2023-12-16 20:40:36,771 - Class weights: [0.45, 0.55]
2023-12-16 20:40:36,771 - Model not saved, didn't meet minimum accuracy threshold
