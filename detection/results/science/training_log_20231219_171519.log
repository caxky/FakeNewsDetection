2023-12-19 17:15:19,509 - 
Starting detection model - k5C7Ydnwax
2023-12-19 17:16:01,404 - Epoch 1 average train loss: 0.6530568599700928
2023-12-19 17:16:41,801 - Epoch 2 average train loss: 0.6128817796707153
2023-12-19 17:17:22,119 - Epoch 3 average train loss: 0.5755202174186707
2023-12-19 17:18:02,480 - Epoch 4 average train loss: 0.5357417464256287
2023-12-19 17:18:42,945 - Epoch 5 average train loss: 0.46010804176330566
2023-12-19 17:18:46,084 - Evaluation Results
2023-12-19 17:18:46,084 - Training time: 200.77965712547302 seconds
2023-12-19 17:18:46,084 - Inference time: 3.0762557983398438 seconds
2023-12-19 17:18:46,084 - Precision: 0.4166666666666667
2023-12-19 17:18:46,085 - Recall: 0.3409090909090909
2023-12-19 17:18:46,085 - F-score: 0.37499999999999994
2023-12-19 17:18:46,085 - Accuracy: 0.7252747252747253
2023-12-19 17:18:46,085 - G-mean: 0.4972451580988469
2023-12-19 17:18:46,085 - Additional Info
2023-12-19 17:18:46,085 - Model name: bert-base-uncased
2023-12-19 17:18:46,085 - Datasets list: science
2023-12-19 17:18:46,085 - Layers frozen: 0
2023-12-19 17:18:46,085 - Learning rate: 1e-05
2023-12-19 17:18:46,085 - Class weights: [0.45, 0.55]
2023-12-19 17:18:46,085 - Model not saved, didn't meet minimum accuracy threshold
