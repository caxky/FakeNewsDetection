2023-12-19 16:55:00,241 - 
Starting detection model - bCkC7QoVUR
2023-12-19 16:55:09,624 - Epoch 1 average train loss: 0.6222485303878784
2023-12-19 16:55:15,267 - Epoch 2 average train loss: 0.5176292061805725
2023-12-19 16:55:20,911 - Epoch 3 average train loss: 0.39689359068870544
2023-12-19 16:55:26,561 - Epoch 4 average train loss: 0.19614526629447937
2023-12-19 16:55:32,209 - Epoch 5 average train loss: 0.11364547163248062
2023-12-19 16:55:33,044 - Evaluation Results
2023-12-19 16:55:33,045 - Training time: 29.306105375289917 seconds
2023-12-19 16:55:33,045 - Inference time: 0.41235923767089844 seconds
2023-12-19 16:55:33,045 - Precision: 0.6818181818181818
2023-12-19 16:55:33,045 - Recall: 0.3409090909090909
2023-12-19 16:55:33,045 - F-score: 0.45454545454545453
2023-12-19 16:55:33,045 - Accuracy: 0.8021978021978022
2023-12-19 16:55:33,045 - G-mean: 0.5229498288330569
2023-12-19 16:55:33,045 - Additional Info
2023-12-19 16:55:33,045 - Model name: bert-base-uncased
2023-12-19 16:55:33,045 - Datasets list: science
2023-12-19 16:55:33,045 - Layers frozen: 0
2023-12-19 16:55:33,045 - Learning rate: 3e-05
2023-12-19 16:55:33,045 - Class weights: [0.45, 0.55]
2023-12-19 16:55:33,045 - Model saved to: ./models\bert_model_bCkC7QoVUR.pt
