2023-12-18 18:29:13,094 - 
Starting detection model - usMzBvk5IH
2023-12-18 18:29:22,346 - Epoch 1 average train loss: 0.6271975636482239
2023-12-18 18:29:27,293 - Epoch 2 average train loss: 0.41451701521873474
2023-12-18 18:29:32,178 - Epoch 3 average train loss: 0.29506075382232666
2023-12-18 18:29:37,046 - Epoch 4 average train loss: 0.10974328219890594
2023-12-18 18:29:41,924 - Epoch 5 average train loss: 0.04592746123671532
2023-12-18 18:29:46,831 - Epoch 6 average train loss: 0.018786923959851265
2023-12-18 18:29:47,760 - Evaluation Results
2023-12-18 18:29:47,760 - Training time: 30.84786367416382 seconds
2023-12-18 18:29:47,760 - Inference time: 0.41613173484802246 seconds
2023-12-18 18:29:47,760 - Precision: 0.6923076923076923
2023-12-18 18:29:47,760 - Recall: 0.4090909090909091
2023-12-18 18:29:47,760 - F-score: 0.5142857142857142
2023-12-18 18:29:47,760 - Accuracy: 0.8131868131868132
2023-12-18 18:29:47,760 - G-mean: 0.5767732073071119
2023-12-18 18:29:47,760 - Additional Info
2023-12-18 18:29:47,760 - Model name: bert-base-uncased
2023-12-18 18:29:47,761 - Datasets list: science
2023-12-18 18:29:47,761 - Layers frozen: 0
2023-12-18 18:29:47,761 - Learning rate: 0.0001
2023-12-18 18:29:47,761 - Class weights: [0.45, 0.55]
2023-12-18 18:29:47,761 - Model saved to: ./models\bert_model_usMzBvk5IH.pt
