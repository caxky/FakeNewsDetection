2023-12-16 19:45:32,907 - 
Starting detection model - cnFWfk7t1C
2023-12-16 19:47:23,626 - Epoch 1 average train loss: 0.6441436409950256
2023-12-16 19:49:59,261 - Epoch 2 average train loss: 0.6117568612098694
2023-12-16 19:52:21,463 - Epoch 3 average train loss: 0.5368658304214478
2023-12-16 19:54:48,736 - Epoch 4 average train loss: 0.3547392785549164
2023-12-16 19:55:05,531 - Evaluation Results
2023-12-16 19:55:05,531 - Training time: 552.9268274307251 seconds
2023-12-16 19:55:05,531 - Inference time: 16.72550892829895 seconds
2023-12-16 19:55:05,532 - Precision: 0.3541666666666667
2023-12-16 19:55:05,532 - Recall: 0.7727272727272727
2023-12-16 19:55:05,532 - F-score: 0.4857142857142857
2023-12-16 19:55:05,532 - Accuracy: 0.6043956043956044
2023-12-16 19:55:05,532 - G-mean: 0.6833981028894995
2023-12-16 19:55:05,532 - Additional Info
2023-12-16 19:55:05,532 - Model name: bert-base-uncased
2023-12-16 19:55:05,532 - Datasets list: science
2023-12-16 19:55:05,532 - Layers frozen: 0
2023-12-16 19:55:05,532 - Learning rate: 5e-05
2023-12-16 19:55:05,532 - Batch size: 64
2023-12-16 19:55:05,532 - Class weights: [0.45, 0.55]
2023-12-16 19:55:05,532 - Model not saved, didn't meet minimum accuracy threshold
