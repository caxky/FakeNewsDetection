2023-12-19 18:31:58,474 - 
Starting detection model - W10K2Ve1bz
2023-12-19 18:32:37,027 - Epoch 1 average train loss: 0.6558377146720886
2023-12-19 18:33:13,918 - Epoch 2 average train loss: 0.6292330026626587
2023-12-19 18:33:50,726 - Epoch 3 average train loss: 0.6059941649436951
2023-12-19 18:34:27,476 - Epoch 4 average train loss: 0.5396982431411743
2023-12-19 18:35:04,270 - Epoch 5 average train loss: 0.42772552371025085
2023-12-19 18:35:07,387 - Evaluation Results
2023-12-19 18:35:07,387 - Training time: 183.1731734275818 seconds
2023-12-19 18:35:07,387 - Inference time: 3.0551528930664062 seconds
2023-12-19 18:35:07,387 - Precision: 0.5652173913043478
2023-12-19 18:35:07,387 - Recall: 0.29545454545454547
2023-12-19 18:35:07,387 - F-score: 0.3880597014925373
2023-12-19 18:35:07,387 - Accuracy: 0.7747252747252747
2023-12-19 18:35:07,387 - G-mean: 0.4784308768214107
2023-12-19 18:35:07,387 - Additional Info
2023-12-19 18:35:07,387 - Model name: bert-base-uncased
2023-12-19 18:35:07,387 - Datasets list: science
2023-12-19 18:35:07,387 - Layers frozen: 0
2023-12-19 18:35:07,387 - Learning rate: 3e-05
2023-12-19 18:35:07,387 - Class weights: [0.45, 0.55]
2023-12-19 18:35:07,387 - Model not saved, didn't meet minimum accuracy threshold
