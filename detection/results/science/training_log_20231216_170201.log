2023-12-16 17:02:01,541 - 
Starting detection model - WZZMvuRJ7w
2023-12-16 17:03:20,628 - Epoch 1 average train loss: 0.6341596245765686
2023-12-16 17:04:38,077 - Epoch 2 average train loss: 0.5472666621208191
2023-12-16 17:05:55,467 - Epoch 3 average train loss: 0.3307991623878479
2023-12-16 17:07:12,979 - Epoch 4 average train loss: 0.17354370653629303
2023-12-16 17:07:20,029 - Evaluation Results
2023-12-16 17:07:20,029 - Training time: 308.69965744018555 seconds
2023-12-16 17:07:20,029 - Inference time: 6.980999231338501 seconds
2023-12-16 17:07:20,029 - Precision: 0.6470588235294118
2023-12-16 17:07:20,029 - Recall: 0.25
2023-12-16 17:07:20,029 - F-score: 0.36065573770491804
2023-12-16 17:07:20,029 - Accuracy: 0.7857142857142857
2023-12-16 17:07:20,030 - G-mean: 0.44320263021395917
2023-12-16 17:07:20,030 - Additional Info
2023-12-16 17:07:20,030 - Model name: bert-base-uncased
2023-12-16 17:07:20,030 - Datasets list: science
2023-12-16 17:07:20,030 - Layers frozen: 0
2023-12-16 17:07:20,030 - Learning rate: 5e-05
2023-12-16 17:07:20,030 - Batch size: 32
2023-12-16 17:07:20,030 - Class weights: [0.45, 0.55]
2023-12-16 17:07:20,030 - Model not saved, didn't meet minimum accuracy threshold
