2023-12-19 17:07:58,572 - 
Starting detection model - CgXg8nYV5Z
2023-12-19 17:08:06,713 - Epoch 1 average train loss: 0.6526946425437927
2023-12-19 17:08:11,137 - Epoch 2 average train loss: 0.6072822213172913
2023-12-19 17:08:15,576 - Epoch 3 average train loss: 0.4914577603340149
2023-12-19 17:08:20,014 - Epoch 4 average train loss: 0.27692002058029175
2023-12-19 17:08:24,458 - Epoch 5 average train loss: 0.1404593139886856
2023-12-19 17:08:25,252 - Evaluation Results
2023-12-19 17:08:25,253 - Training time: 23.253080368041992 seconds
2023-12-19 17:08:25,253 - Inference time: 0.37256407737731934 seconds
2023-12-19 17:08:25,253 - Precision: 0.8333333333333334
2023-12-19 17:08:25,253 - Recall: 0.22727272727272727
2023-12-19 17:08:25,253 - F-score: 0.35714285714285715
2023-12-19 17:08:25,253 - Accuracy: 0.8021978021978022
2023-12-19 17:08:25,253 - G-mean: 0.4269867472389305
2023-12-19 17:08:25,253 - Additional Info
2023-12-19 17:08:25,253 - Model name: bert-base-uncased
2023-12-19 17:08:25,253 - Datasets list: science
2023-12-19 17:08:25,253 - Layers frozen: 0
2023-12-19 17:08:25,253 - Learning rate: 5e-05
2023-12-19 17:08:25,253 - Class weights: [0.45, 0.55]
2023-12-19 17:08:25,253 - Model saved to: ./models\bert_model_CgXg8nYV5Z.pt
