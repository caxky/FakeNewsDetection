2023-12-13 23:13:30,683 - ====================================================
2023-12-13 23:13:30,957 - Model: distilbert-base-uncased 2023-12-13_23-13-30 with 9 epochs
2023-12-13 23:17:39,700 - Epoch 1 average train loss: 0.5887749592346304
2023-12-13 23:21:41,993 - Epoch 2 average train loss: 0.1148989168817506
2023-12-13 23:25:56,369 - Epoch 3 average train loss: 0.05465347181129105
2023-12-13 23:30:47,402 - Epoch 4 average train loss: 0.030175476994036752
2023-12-13 23:35:37,671 - Epoch 5 average train loss: 0.021278589286238832
2023-12-13 23:39:52,172 - Epoch 6 average train loss: 0.012230478677528855
2023-12-13 23:44:39,972 - Epoch 7 average train loss: 0.00820348261622712
2023-12-13 23:49:25,273 - Epoch 8 average train loss: 0.007301043005341746
2023-12-13 23:53:49,491 - Epoch 9 average train loss: 0.008918561846238683
2023-12-13 23:54:21,160 - 2023-12-13_23-13-30 with 9 epochs: Evaluation Results:
2023-12-13 23:54:21,160 - Training time: 2418.4489483833313 seconds
2023-12-13 23:54:21,160 - Inference time: 31.656043529510498 seconds
2023-12-13 23:54:21,160 - Precision: 0.971284880696816
2023-12-13 23:54:21,160 - Recall: 0.9707571841452867
2023-12-13 23:54:21,160 - F-score: 0.9709400760914979
2023-12-13 23:54:21,160 - Accuracy: 0.9705882352941176
2023-12-13 23:54:21,160 - G-mean: 0.9706727060439376
2023-12-13 23:54:58,163 - distilbert-base-uncased 2023-12-13_23-13-30 with 9 epochs: Evaluation Results (completely new data):
2023-12-13 23:54:58,163 - Training time: 2418.4489483833313 seconds
2023-12-13 23:54:58,163 - Inference time: 32.39599943161011 seconds
2023-12-13 23:54:58,163 - Precision: 0.9680828932997432
2023-12-13 23:54:58,164 - Recall: 0.9690441282935514
2023-12-13 23:54:58,164 - F-score: 0.968500274266917
2023-12-13 23:54:58,164 - Accuracy: 0.9682352941176471
2023-12-13 23:54:58,164 - G-mean: 0.9686396267814391
2023-12-13 23:55:00,456 - ====================================================
2023-12-13 23:55:00,923 - Model: distilbert-base-uncased 2023-12-13_23-55-00 with 9 epochs
2023-12-13 23:59:08,861 - Epoch 1 average train loss: 0.5978581992931226
2023-12-14 00:03:54,316 - Epoch 2 average train loss: 0.10694512945325936
2023-12-14 00:08:28,088 - Epoch 3 average train loss: 0.05745986219495535
2023-12-14 00:13:22,874 - Epoch 4 average train loss: 0.034680166759473434
2023-12-14 00:18:20,439 - Epoch 5 average train loss: 0.019360596335712164
2023-12-14 00:23:12,276 - Epoch 6 average train loss: 0.010426732272882124
2023-12-14 00:28:05,146 - Epoch 7 average train loss: 0.006662859403295442
2023-12-14 00:32:57,242 - Epoch 8 average train loss: 0.007448723278049489
2023-12-14 00:37:46,958 - Epoch 9 average train loss: 0.007081630599354599
2023-12-14 00:38:17,610 - 2023-12-13_23-55-00 with 9 epochs: Evaluation Results:
2023-12-14 00:38:17,610 - Training time: 2565.9347746372223 seconds
2023-12-14 00:38:17,610 - Inference time: 30.64098882675171 seconds
2023-12-14 00:38:17,610 - Precision: 0.9709725281216508
2023-12-14 00:38:17,610 - Recall: 0.9705997089968335
2023-12-14 00:38:17,610 - F-score: 0.9707293745619431
2023-12-14 00:38:17,610 - Accuracy: 0.9705882352941176
2023-12-14 00:38:17,610 - G-mean: 0.9705939721285213
2023-12-14 00:38:47,752 - distilbert-base-uncased 2023-12-13_23-55-00 with 9 epochs: Evaluation Results (completely new data):
2023-12-14 00:38:47,752 - Training time: 2565.9347746372223 seconds
2023-12-14 00:38:47,752 - Inference time: 26.512000799179077 seconds
2023-12-14 00:38:47,752 - Precision: 0.96789769070488
2023-12-14 00:38:47,752 - Recall: 0.9689165964105806
2023-12-14 00:38:47,752 - F-score: 0.968305932563094
2023-12-14 00:38:47,752 - Accuracy: 0.9682352941176471
2023-12-14 00:38:47,752 - G-mean: 0.9685758853600828
2023-12-14 00:38:47,795 - Model distilbert-base-uncased 2023-12-13_23-55-00 not saved
2023-12-14 00:38:47,795 - ====================================================
2023-12-14 00:38:48,080 - Model: distilbert-base-uncased 2023-12-14_00-38-48 with 10 epochs
2023-12-14 00:43:20,605 - Epoch 1 average train loss: 0.5786707005956594
2023-12-14 00:48:02,924 - Epoch 2 average train loss: 0.11746693436056375
2023-12-14 00:52:20,483 - Epoch 3 average train loss: 0.057350472840754424
2023-12-14 00:56:40,503 - Epoch 4 average train loss: 0.030576783990597024
2023-12-14 01:00:46,751 - Epoch 5 average train loss: 0.01780021995141664
2023-12-14 01:04:48,811 - Epoch 6 average train loss: 0.009404597143396079
2023-12-14 01:08:47,027 - Epoch 7 average train loss: 0.003898239005391267
2023-12-14 01:12:47,721 - Epoch 8 average train loss: 0.004619720167333178
2023-12-14 01:16:47,936 - Epoch 9 average train loss: 0.004189745006682215
2023-12-14 01:20:50,986 - Epoch 10 average train loss: 0.002384138086768764
2023-12-14 01:21:19,801 - 2023-12-14_00-38-48 with 10 epochs: Evaluation Results:
2023-12-14 01:21:19,801 - Training time: 2522.8339054584503 seconds
2023-12-14 01:21:19,802 - Inference time: 28.795660495758057 seconds
2023-12-14 01:21:19,802 - Precision: 0.966256210330128
2023-12-14 01:21:19,802 - Recall: 0.9656292792728381
2023-12-14 01:21:19,802 - F-score: 0.9658763478931507
2023-12-14 01:21:19,802 - Accuracy: 0.9658823529411765
2023-12-14 01:21:19,802 - G-mean: 0.9657558078173495
2023-12-14 01:21:53,642 - distilbert-base-uncased 2023-12-14_00-38-48 with 10 epochs: Evaluation Results (completely new data):
2023-12-14 01:21:53,642 - Training time: 2522.8339054584503 seconds
2023-12-14 01:21:53,642 - Inference time: 29.422990083694458 seconds
2023-12-14 01:21:53,643 - Precision: 0.971486525236472
2023-12-14 01:21:53,643 - Recall: 0.9722808788052829
2023-12-14 01:21:53,643 - F-score: 0.9717497286428612
2023-12-14 01:21:53,643 - Accuracy: 0.971764705882353
2023-12-14 01:21:53,643 - G-mean: 0.9720227580809265
2023-12-14 01:21:56,005 - ====================================================
2023-12-14 01:21:56,331 - Model: distilbert-base-uncased 2023-12-14_01-21-56 with 10 epochs
2023-12-14 01:26:47,942 - Epoch 1 average train loss: 0.5873081925949629
2023-12-14 01:31:23,709 - Epoch 2 average train loss: 0.11853107330115402
2023-12-14 01:35:58,684 - Epoch 3 average train loss: 0.05922883459750344
2023-12-14 01:40:53,734 - Epoch 4 average train loss: 0.03544579908306546
2023-12-14 01:45:44,713 - Epoch 5 average train loss: 0.018085584418629022
2023-12-14 01:49:53,998 - Epoch 6 average train loss: 0.009734018557869336
2023-12-14 01:54:40,511 - Epoch 7 average train loss: 0.008612472654785961
2023-12-14 01:58:46,586 - Epoch 8 average train loss: 0.005432100633607821
2023-12-14 02:02:42,796 - Epoch 9 average train loss: 0.005425197116059923
2023-12-14 02:06:46,741 - Epoch 10 average train loss: 0.000848450202264597
2023-12-14 02:07:14,119 - 2023-12-14_01-21-56 with 10 epochs: Evaluation Results:
2023-12-14 02:07:14,119 - Training time: 2690.3354465961456 seconds
2023-12-14 02:07:14,119 - Inference time: 27.366999626159668 seconds
2023-12-14 02:07:14,119 - Precision: 0.9709952745250264
2023-12-14 02:07:14,119 - Recall: 0.9707914440471604
2023-12-14 02:07:14,119 - F-score: 0.970748213477771
2023-12-14 02:07:14,119 - Accuracy: 0.9705882352941176
2023-12-14 02:07:14,119 - G-mean: 0.9706898343530551
2023-12-14 02:07:44,860 - distilbert-base-uncased 2023-12-14_01-21-56 with 10 epochs: Evaluation Results (completely new data):
2023-12-14 02:07:44,860 - Training time: 2690.3354465961456 seconds
2023-12-14 02:07:44,861 - Inference time: 26.745009660720825 seconds
2023-12-14 02:07:44,861 - Precision: 0.9700727960635088
2023-12-14 02:07:44,861 - Recall: 0.9713106976096771
2023-12-14 02:07:44,861 - F-score: 0.9705371635041413
2023-12-14 02:07:44,861 - Accuracy: 0.9705882352941176
2023-12-14 02:07:44,861 - G-mean: 0.9709493992558391
2023-12-14 02:07:45,178 - Model distilbert-base-uncased 2023-12-14_01-21-56 not saved
2023-12-14 02:07:45,178 - ====================================================
2023-12-14 02:07:45,534 - Model: distilbert-base-uncased 2023-12-14_02-07-45 with 11 epochs
