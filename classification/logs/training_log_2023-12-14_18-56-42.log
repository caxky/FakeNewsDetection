2023-12-14 18:57:06,273 - ====================================================
2023-12-14 18:57:06,974 - Model: distilbert-base-uncased 2023-12-14_18-57-06 with 1 epochs
2023-12-14 19:01:31,489 - Epoch 1 average train loss: 0.5790952553380938
2023-12-14 19:02:02,101 - 2023-12-14_18-57-06 with 1 epochs: Evaluation Results:
2023-12-14 19:02:02,101 - Training time: 264.3962333202362 seconds
2023-12-14 19:02:02,101 - Inference time: 30.599568367004395 seconds
2023-12-14 19:02:02,101 - Precision: 0.9602974350544542
2023-12-14 19:02:02,101 - Recall: 0.9603927169744638
2023-12-14 19:02:02,102 - F-score: 0.9603100298817034
2023-12-14 19:02:02,102 - Accuracy: 0.96
2023-12-14 19:02:02,102 - G-mean: 0.9601963384097469
2023-12-14 19:02:36,276 - distilbert-base-uncased 2023-12-14_18-57-06 with 1 epochs: Evaluation Results (completely new data):
2023-12-14 19:02:36,276 - Training time: 264.3962333202362 seconds
2023-12-14 19:02:36,276 - Inference time: 30.3539981842041 seconds
2023-12-14 19:02:36,276 - Precision: 0.9584431674478516
2023-12-14 19:02:36,276 - Recall: 0.9595149333082134
2023-12-14 19:02:36,276 - F-score: 0.9588542950115497
2023-12-14 19:02:36,277 - Accuracy: 0.9588235294117647
2023-12-14 19:02:36,277 - G-mean: 0.9591691690613681
2023-12-14 19:02:38,329 - ====================================================
2023-12-14 19:02:38,600 - Model: distilbert-base-uncased 2023-12-14_19-02-38 with 1 epochs
2023-12-14 19:07:10,796 - Epoch 1 average train loss: 0.592890573187786
2023-12-14 19:07:41,512 - 2023-12-14_19-02-38 with 1 epochs: Evaluation Results:
2023-12-14 19:07:41,512 - Training time: 272.1221287250519 seconds
2023-12-14 19:07:41,512 - Inference time: 30.70596933364868 seconds
2023-12-14 19:07:41,512 - Precision: 0.9548093726848931
2023-12-14 19:07:41,512 - Recall: 0.9546444968988274
2023-12-14 19:07:41,512 - F-score: 0.9547084082533266
2023-12-14 19:07:41,512 - Accuracy: 0.9541176470588235
2023-12-14 19:07:41,512 - G-mean: 0.954381035624013
2023-12-14 19:08:15,807 - distilbert-base-uncased 2023-12-14_19-02-38 with 1 epochs: Evaluation Results (completely new data):
2023-12-14 19:08:15,807 - Training time: 272.1221287250519 seconds
2023-12-14 19:08:15,807 - Inference time: 30.466001272201538 seconds
2023-12-14 19:08:15,808 - Precision: 0.9622946008243505
2023-12-14 19:08:15,808 - Recall: 0.9629100334201398
2023-12-14 19:08:15,808 - F-score: 0.9625292989885453
2023-12-14 19:08:15,808 - Accuracy: 0.9623529411764706
2023-12-14 19:08:15,808 - G-mean: 0.9626314469983853
2023-12-14 19:08:17,921 - ====================================================
2023-12-14 19:08:18,235 - Model: distilbert-base-uncased 2023-12-14_19-08-18 with 1 epochs
2023-12-14 19:12:20,435 - Epoch 1 average train loss: 0.5907367510830654
2023-12-14 19:12:45,872 - 2023-12-14_19-08-18 with 1 epochs: Evaluation Results:
2023-12-14 19:12:45,872 - Training time: 242.12301802635193 seconds
2023-12-14 19:12:45,872 - Inference time: 25.43098020553589 seconds
2023-12-14 19:12:45,872 - Precision: 0.9571435990486
2023-12-14 19:12:45,872 - Recall: 0.9567700916649574
2023-12-14 19:12:45,873 - F-score: 0.9568289347528134
2023-12-14 19:12:45,873 - Accuracy: 0.9564705882352941
2023-12-14 19:12:45,873 - G-mean: 0.9566203282288738
2023-12-14 19:13:14,439 - distilbert-base-uncased 2023-12-14_19-08-18 with 1 epochs: Evaluation Results (completely new data):
2023-12-14 19:13:14,439 - Training time: 242.12301802635193 seconds
2023-12-14 19:13:14,439 - Inference time: 25.229971408843994 seconds
2023-12-14 19:13:14,439 - Precision: 0.9621135550659302
2023-12-14 19:13:14,439 - Recall: 0.9627525582716865
2023-12-14 19:13:14,439 - F-score: 0.9623753202620984
2023-12-14 19:13:14,440 - Accuracy: 0.9623529411764706
2023-12-14 19:13:14,440 - G-mean: 0.9625527289857574
2023-12-14 19:13:14,476 - Model distilbert-base-uncased 2023-12-14_19-08-18 not saved
2023-12-14 19:13:14,477 - ====================================================
2023-12-14 19:13:14,758 - Model: distilbert-base-uncased 2023-12-14_19-13-14 with 2 epochs
2023-12-14 19:17:05,290 - Epoch 1 average train loss: 0.597900257636519
2023-12-14 19:21:10,623 - Epoch 2 average train loss: 0.11272063578972046
2023-12-14 19:21:39,166 - 2023-12-14_19-13-14 with 2 epochs: Evaluation Results:
2023-12-14 19:21:39,166 - Training time: 475.80288910865784 seconds
2023-12-14 19:21:39,166 - Inference time: 28.535999059677124 seconds
2023-12-14 19:21:39,166 - Precision: 0.9683594237348014
2023-12-14 19:21:39,166 - Recall: 0.9686239935939025
2023-12-14 19:21:39,166 - F-score: 0.9684667487303991
2023-12-14 19:21:39,167 - Accuracy: 0.9682352941176471
2023-12-14 19:21:39,167 - G-mean: 0.9684296243541923
2023-12-14 19:22:10,567 - distilbert-base-uncased 2023-12-14_19-13-14 with 2 epochs: Evaluation Results (completely new data):
2023-12-14 19:22:10,568 - Training time: 475.80288910865784 seconds
2023-12-14 19:22:10,568 - Inference time: 27.672999620437622 seconds
2023-12-14 19:22:10,568 - Precision: 0.9641615545177056
2023-12-14 19:22:10,568 - Recall: 0.9652707491691043
2023-12-14 19:22:10,568 - F-score: 0.9646073359734105
2023-12-14 19:22:10,568 - Accuracy: 0.9647058823529412
2023-12-14 19:22:10,568 - G-mean: 0.964988274429625
2023-12-14 19:22:12,552 - ====================================================
2023-12-14 19:22:12,874 - Model: distilbert-base-uncased 2023-12-14_19-22-12 with 2 epochs
2023-12-14 19:26:53,787 - Epoch 1 average train loss: 0.5861802076329203
2023-12-14 19:31:51,969 - Epoch 2 average train loss: 0.10675021018175518
2023-12-14 19:32:18,087 - 2023-12-14_19-22-12 with 2 epochs: Evaluation Results:
2023-12-14 19:32:18,088 - Training time: 579.0360078811646 seconds
2023-12-14 19:32:18,088 - Inference time: 26.110034704208374 seconds
2023-12-14 19:32:18,088 - Precision: 0.9651182575803887
2023-12-14 19:32:18,088 - Recall: 0.9649447609022939
2023-12-14 19:32:18,088 - F-score: 0.9650133262917446
2023-12-14 19:32:18,088 - Accuracy: 0.9647058823529412
2023-12-14 19:32:18,088 - G-mean: 0.964825314234704
2023-12-14 19:32:47,358 - distilbert-base-uncased 2023-12-14_19-22-12 with 2 epochs: Evaluation Results (completely new data):
2023-12-14 19:32:47,358 - Training time: 579.0360078811646 seconds
2023-12-14 19:32:47,359 - Inference time: 25.766998052597046 seconds
2023-12-14 19:32:47,359 - Precision: 0.9717498782527685
2023-12-14 19:32:47,359 - Recall: 0.9723758996898633
2023-12-14 19:32:47,359 - F-score: 0.9719723266396464
2023-12-14 19:32:47,359 - Accuracy: 0.971764705882353
2023-12-14 19:32:47,359 - G-mean: 0.9720702547497317
2023-12-14 19:32:49,276 - ====================================================
2023-12-14 19:32:49,537 - Model: distilbert-base-uncased 2023-12-14_19-32-49 with 2 epochs
2023-12-14 19:37:39,759 - Epoch 1 average train loss: 0.6070277118507553
2023-12-14 19:42:34,562 - Epoch 2 average train loss: 0.11537323197021204
2023-12-14 19:43:04,172 - 2023-12-14_19-32-49 with 2 epochs: Evaluation Results:
2023-12-14 19:43:04,172 - Training time: 584.9691982269287 seconds
2023-12-14 19:43:04,172 - Inference time: 29.601999759674072 seconds
2023-12-14 19:43:04,172 - Precision: 0.9621694568482837
2023-12-14 19:43:04,172 - Recall: 0.9612928481209424
2023-12-14 19:43:04,172 - F-score: 0.9616362418593816
2023-12-14 19:43:04,172 - Accuracy: 0.9611764705882353
2023-12-14 19:43:04,172 - G-mean: 0.9612346575933475
2023-12-14 19:43:37,146 - distilbert-base-uncased 2023-12-14_19-32-49 with 2 epochs: Evaluation Results (completely new data):
2023-12-14 19:43:37,146 - Training time: 584.9691982269287 seconds
2023-12-14 19:43:37,146 - Inference time: 29.258013010025024 seconds
2023-12-14 19:43:37,146 - Precision: 0.9612080089082531
2023-12-14 19:43:37,147 - Recall: 0.9616255577212653
2023-12-14 19:43:37,147 - F-score: 0.9612644637982427
2023-12-14 19:43:37,147 - Accuracy: 0.9611764705882353
2023-12-14 19:43:37,147 - G-mean: 0.9614009879326987
2023-12-14 19:43:37,185 - Model distilbert-base-uncased 2023-12-14_19-32-49 not saved
2023-12-14 19:43:37,186 - ====================================================
2023-12-14 19:43:37,537 - Model: distilbert-base-uncased 2023-12-14_19-43-37 with 3 epochs
2023-12-14 19:47:40,114 - Epoch 1 average train loss: 0.5970199364336098
2023-12-14 19:51:31,767 - Epoch 2 average train loss: 0.10951031685752027
2023-12-14 19:55:22,358 - Epoch 3 average train loss: 0.060488237523857284
2023-12-14 19:55:48,064 - 2023-12-14_19-43-37 with 3 epochs: Evaluation Results:
2023-12-14 19:55:48,064 - Training time: 704.762814283371 seconds
2023-12-14 19:55:48,064 - Inference time: 25.69899559020996 seconds
2023-12-14 19:55:48,064 - Precision: 0.9678352059864925
2023-12-14 19:55:48,064 - Recall: 0.9671195884827022
2023-12-14 19:55:48,064 - F-score: 0.967430933029082
2023-12-14 19:55:48,064 - Accuracy: 0.9670588235294117
2023-12-14 19:55:48,064 - G-mean: 0.9670892055288027
2023-12-14 19:56:16,895 - distilbert-base-uncased 2023-12-14_19-43-37 with 3 epochs: Evaluation Results (completely new data):
2023-12-14 19:56:16,895 - Training time: 704.762814283371 seconds
2023-12-14 19:56:16,895 - Inference time: 25.398000717163086 seconds
2023-12-14 19:56:16,895 - Precision: 0.9639928854372981
2023-12-14 19:56:16,895 - Recall: 0.9639511391166142
2023-12-14 19:56:16,895 - F-score: 0.9637617783401982
2023-12-14 19:56:16,895 - Accuracy: 0.9635294117647059
2023-12-14 19:56:16,895 - G-mean: 0.9637402523724686
2023-12-14 19:56:18,837 - ====================================================
2023-12-14 19:56:19,086 - Model: distilbert-base-uncased 2023-12-14_19-56-19 with 3 epochs
2023-12-14 20:00:08,493 - Epoch 1 average train loss: 0.611072009135695
2023-12-14 20:03:57,837 - Epoch 2 average train loss: 0.11728141180951805
2023-12-14 20:07:47,471 - Epoch 3 average train loss: 0.05516709851758445
2023-12-14 20:08:13,243 - 2023-12-14_19-56-19 with 3 epochs: Evaluation Results:
2023-12-14 20:08:13,243 - Training time: 688.3279628753662 seconds
2023-12-14 20:08:13,243 - Inference time: 25.7660231590271 seconds
2023-12-14 20:08:13,244 - Precision: 0.96888588405306
2023-12-14 20:08:13,244 - Recall: 0.9680539795310545
2023-12-14 20:08:13,244 - F-score: 0.9683998413595726
2023-12-14 20:08:13,244 - Accuracy: 0.9682352941176471
2023-12-14 20:08:13,244 - G-mean: 0.9681446325797656
2023-12-14 20:08:41,944 - distilbert-base-uncased 2023-12-14_19-56-19 with 3 epochs: Evaluation Results (completely new data):
2023-12-14 20:08:41,944 - Training time: 688.3279628753662 seconds
2023-12-14 20:08:41,944 - Inference time: 25.349032640457153 seconds
2023-12-14 20:08:41,944 - Precision: 0.9669014169525987
2023-12-14 20:08:41,944 - Recall: 0.9673104490812874
2023-12-14 20:08:41,944 - F-score: 0.9670018921137542
2023-12-14 20:08:41,944 - Accuracy: 0.9670588235294117
2023-12-14 20:08:41,944 - G-mean: 0.9671846281223956
2023-12-14 20:08:43,777 - ====================================================
2023-12-14 20:08:44,056 - Model: distilbert-base-uncased 2023-12-14_20-08-44 with 3 epochs
2023-12-14 20:12:32,730 - Epoch 1 average train loss: 0.569038092292407
2023-12-14 20:16:21,949 - Epoch 2 average train loss: 0.10796895679086446
2023-12-14 20:20:11,189 - Epoch 3 average train loss: 0.05459911483942586
2023-12-14 20:20:36,831 - 2023-12-14_20-08-44 with 3 epochs: Evaluation Results:
2023-12-14 20:20:36,831 - Training time: 687.0773568153381 seconds
2023-12-14 20:20:36,831 - Inference time: 25.63300132751465 seconds
2023-12-14 20:20:36,831 - Precision: 0.9655564760415404
2023-12-14 20:20:36,831 - Recall: 0.9645322219878993
2023-12-14 20:20:36,831 - F-score: 0.964989911284017
2023-12-14 20:20:36,831 - Accuracy: 0.9647058823529412
2023-12-14 20:20:36,831 - G-mean: 0.9646190482624108
2023-12-14 20:21:05,610 - distilbert-base-uncased 2023-12-14_20-08-44 with 3 epochs: Evaluation Results (completely new data):
2023-12-14 20:21:05,610 - Training time: 687.0773568153381 seconds
2023-12-14 20:21:05,610 - Inference time: 25.382964611053467 seconds
2023-12-14 20:21:05,610 - Precision: 0.9725802440106597
2023-12-14 20:21:05,610 - Recall: 0.9732237400906314
2023-12-14 20:21:05,610 - F-score: 0.9728558608214162
2023-12-14 20:21:05,610 - Accuracy: 0.9729411764705882
2023-12-14 20:21:05,610 - G-mean: 0.973082448024259
2023-12-14 20:21:07,452 - ====================================================
2023-12-14 20:21:07,706 - Model: distilbert-base-uncased 2023-12-14_20-21-07 with 4 epochs
2023-12-14 20:24:56,156 - Epoch 1 average train loss: 0.6037078993723674
2023-12-14 20:28:44,964 - Epoch 2 average train loss: 0.11606305873350185
2023-12-14 20:32:33,711 - Epoch 3 average train loss: 0.0538860081826501
2023-12-14 20:36:22,659 - Epoch 4 average train loss: 0.029682639598408167
2023-12-14 20:36:48,335 - 2023-12-14_20-21-07 with 4 epochs: Evaluation Results:
2023-12-14 20:36:48,335 - Training time: 914.899496793747 seconds
2023-12-14 20:36:48,335 - Inference time: 25.667996406555176 seconds
2023-12-14 20:36:48,335 - Precision: 0.9653087538392165
2023-12-14 20:36:48,335 - Recall: 0.9630777029252883
2023-12-14 20:36:48,335 - F-score: 0.9640090112811212
2023-12-14 20:36:48,335 - Accuracy: 0.9635294117647059
2023-12-14 20:36:48,335 - G-mean: 0.9633035308682861
2023-12-14 20:37:17,022 - distilbert-base-uncased 2023-12-14_20-21-07 with 4 epochs: Evaluation Results (completely new data):
2023-12-14 20:37:17,022 - Training time: 914.899496793747 seconds
2023-12-14 20:37:17,022 - Inference time: 25.329999923706055 seconds
2023-12-14 20:37:17,022 - Precision: 0.9736301530780057
2023-12-14 20:37:17,022 - Recall: 0.9732827521698544
2023-12-14 20:37:17,022 - F-score: 0.9733149391070226
2023-12-14 20:37:17,022 - Accuracy: 0.9729411764705882
2023-12-14 20:37:17,022 - G-mean: 0.9731119493329994
2023-12-14 20:37:18,872 - ====================================================
2023-12-14 20:37:19,128 - Model: distilbert-base-uncased 2023-12-14_20-37-19 with 4 epochs
2023-12-14 20:41:07,221 - Epoch 1 average train loss: 0.580915650777957
2023-12-14 20:44:55,899 - Epoch 2 average train loss: 0.11051968620761353
2023-12-14 20:48:44,293 - Epoch 3 average train loss: 0.055749639801900175
2023-12-14 20:52:32,812 - Epoch 4 average train loss: 0.034664329703458965
2023-12-14 20:52:58,389 - 2023-12-14_20-37-19 with 4 epochs: Evaluation Results:
2023-12-14 20:52:58,389 - Training time: 913.6294226646423 seconds
2023-12-14 20:52:58,389 - Inference time: 25.570000886917114 seconds
2023-12-14 20:52:58,389 - Precision: 0.9622953826799281
2023-12-14 20:52:58,389 - Recall: 0.9608820581100315
2023-12-14 20:52:58,389 - F-score: 0.9614183149897864
2023-12-14 20:52:58,389 - Accuracy: 0.9611764705882353
2023-12-14 20:52:58,389 - G-mean: 0.9610292530749309
2023-12-14 20:53:27,183 - distilbert-base-uncased 2023-12-14_20-37-19 with 4 epochs: Evaluation Results (completely new data):
2023-12-14 20:53:27,183 - Training time: 913.6294226646423 seconds
2023-12-14 20:53:27,183 - Inference time: 25.432000637054443 seconds
2023-12-14 20:53:27,183 - Precision: 0.9697606549065434
2023-12-14 20:53:27,183 - Recall: 0.969986115127158
2023-12-14 20:53:27,183 - F-score: 0.9697595955522675
2023-12-14 20:53:27,183 - Accuracy: 0.9694117647058823
2023-12-14 20:53:27,183 - G-mean: 0.9696988973932174
2023-12-14 20:53:27,218 - Model distilbert-base-uncased 2023-12-14_20-37-19 not saved
2023-12-14 20:53:27,219 - ====================================================
2023-12-14 20:53:27,454 - Model: distilbert-base-uncased 2023-12-14_20-53-27 with 4 epochs
2023-12-14 20:57:15,654 - Epoch 1 average train loss: 0.603094772380941
2023-12-14 21:01:04,147 - Epoch 2 average train loss: 0.11315592094598448
2023-12-14 21:04:53,230 - Epoch 3 average train loss: 0.05625724329448798
2023-12-14 21:08:41,623 - Epoch 4 average train loss: 0.029290003418812858
2023-12-14 21:09:06,887 - 2023-12-14_20-53-27 with 4 epochs: Evaluation Results:
2023-12-14 21:09:06,887 - Training time: 914.1072647571564 seconds
2023-12-14 21:09:06,887 - Inference time: 25.255999088287354 seconds
2023-12-14 21:09:06,887 - Precision: 0.9709589223000566
2023-12-14 21:09:06,887 - Recall: 0.9707339622133168
2023-12-14 21:09:06,887 - F-score: 0.9707784108695152
2023-12-14 21:09:06,887 - Accuracy: 0.9705882352941176
2023-12-14 21:09:06,887 - G-mean: 0.9706610960189399
2023-12-14 21:09:35,342 - distilbert-base-uncased 2023-12-14_20-53-27 with 4 epochs: Evaluation Results (completely new data):
2023-12-14 21:09:35,342 - Training time: 914.1072647571564 seconds
2023-12-14 21:09:35,342 - Inference time: 25.072967052459717 seconds
2023-12-14 21:09:35,342 - Precision: 0.9729926108374384
2023-12-14 21:09:35,342 - Recall: 0.9735078726703135
2023-12-14 21:09:35,342 - F-score: 0.9731368605954742
2023-12-14 21:09:35,342 - Accuracy: 0.9729411764705882
2023-12-14 21:09:35,342 - G-mean: 0.9732244833229559
2023-12-14 21:09:37,241 - ====================================================
2023-12-14 21:09:37,478 - Model: distilbert-base-uncased 2023-12-14_21-09-37 with 5 epochs
2023-12-14 21:13:25,870 - Epoch 1 average train loss: 0.5973194311120931
2023-12-14 21:17:15,374 - Epoch 2 average train loss: 0.10756480186301119
2023-12-14 21:21:04,914 - Epoch 3 average train loss: 0.05070683294797645
2023-12-14 21:24:54,523 - Epoch 4 average train loss: 0.03382714370649089
2023-12-14 21:28:45,362 - Epoch 5 average train loss: 0.017864577403045534
2023-12-14 21:29:11,331 - 2023-12-14_21-09-37 with 5 epochs: Evaluation Results:
2023-12-14 21:29:11,331 - Training time: 1147.8289721012115 seconds
2023-12-14 21:29:11,331 - Inference time: 25.960527896881104 seconds
2023-12-14 21:29:11,331 - Precision: 0.9650183196207237
2023-12-14 21:29:11,332 - Recall: 0.9645940204581344
2023-12-14 21:29:11,332 - F-score: 0.964701830084719
2023-12-14 21:29:11,332 - Accuracy: 0.9647058823529412
2023-12-14 21:29:11,332 - G-mean: 0.9646499497840839
2023-12-14 21:29:40,041 - distilbert-base-uncased 2023-12-14_21-09-37 with 5 epochs: Evaluation Results (completely new data):
2023-12-14 21:29:40,041 - Training time: 1147.8289721012115 seconds
2023-12-14 21:29:40,042 - Inference time: 25.24596643447876 seconds
2023-12-14 21:29:40,042 - Precision: 0.9643219950846937
2023-12-14 21:29:40,042 - Recall: 0.9652416803553635
2023-12-14 21:29:40,042 - F-score: 0.9646737939732759
2023-12-14 21:29:40,042 - Accuracy: 0.9647058823529412
2023-12-14 21:29:40,042 - G-mean: 0.9649737441666776
2023-12-14 21:29:41,956 - ====================================================
2023-12-14 21:29:42,204 - Model: distilbert-base-uncased 2023-12-14_21-29-42 with 5 epochs
2023-12-14 21:33:33,602 - Epoch 1 average train loss: 0.5968875217174783
2023-12-14 21:37:25,388 - Epoch 2 average train loss: 0.11026587320820373
2023-12-14 21:41:16,842 - Epoch 3 average train loss: 0.05226736457580153
2023-12-14 21:45:08,466 - Epoch 4 average train loss: 0.03379685971885919
2023-12-14 21:49:00,302 - Epoch 5 average train loss: 0.017169597958324147
2023-12-14 21:49:25,867 - 2023-12-14_21-29-42 with 5 epochs: Evaluation Results:
2023-12-14 21:49:25,867 - Training time: 1158.0414247512817 seconds
2023-12-14 21:49:25,867 - Inference time: 25.55799889564514 seconds
2023-12-14 21:49:25,867 - Precision: 0.9652550378051583
2023-12-14 21:49:25,867 - Recall: 0.9645940204581344
2023-12-14 21:49:25,867 - F-score: 0.9648261057757603
2023-12-14 21:49:25,867 - Accuracy: 0.9647058823529412
2023-12-14 21:49:25,867 - G-mean: 0.9646499497840839
2023-12-14 21:49:54,514 - distilbert-base-uncased 2023-12-14_21-29-42 with 5 epochs: Evaluation Results (completely new data):
2023-12-14 21:49:54,514 - Training time: 1158.0414247512817 seconds
2023-12-14 21:49:54,514 - Inference time: 25.23099970817566 seconds
2023-12-14 21:49:54,514 - Precision: 0.9730212337324481
2023-12-14 21:49:54,514 - Recall: 0.9732879432579876
2023-12-14 21:49:54,514 - F-score: 0.9731476549760327
2023-12-14 21:49:54,514 - Accuracy: 0.9729411764705882
2023-12-14 21:49:54,514 - G-mean: 0.9731145444181099
2023-12-14 21:49:56,432 - ====================================================
2023-12-14 21:49:56,727 - Model: distilbert-base-uncased 2023-12-14_21-49-56 with 5 epochs
2023-12-14 21:53:58,039 - Epoch 1 average train loss: 0.5855118096050094
2023-12-14 21:57:57,070 - Epoch 2 average train loss: 0.11448012090781155
2023-12-14 22:02:23,030 - Epoch 3 average train loss: 0.05871988807092695
2023-12-14 22:06:25,740 - Epoch 4 average train loss: 0.03586131304447703
2023-12-14 22:10:35,921 - Epoch 5 average train loss: 0.0239331672735074
2023-12-14 22:11:02,936 - 2023-12-14_21-49-56 with 5 epochs: Evaluation Results:
2023-12-14 22:11:02,936 - Training time: 1239.1227014064789 seconds
2023-12-14 22:11:02,936 - Inference time: 27.00599503517151 seconds
2023-12-14 22:11:02,937 - Precision: 0.9612288327069314
2023-12-14 22:11:02,937 - Recall: 0.9611713817778467
2023-12-14 22:11:02,937 - F-score: 0.9611869779777387
2023-12-14 22:11:02,937 - Accuracy: 0.9611764705882353
2023-12-14 22:11:02,937 - G-mean: 0.9611739261796732
2023-12-14 22:11:33,854 - distilbert-base-uncased 2023-12-14_21-49-56 with 5 epochs: Evaluation Results (completely new data):
2023-12-14 22:11:33,854 - Training time: 1239.1227014064789 seconds
2023-12-14 22:11:33,854 - Inference time: 26.71200132369995 seconds
2023-12-14 22:11:33,854 - Precision: 0.9740686637252987
2023-12-14 22:11:33,854 - Recall: 0.9747348665353442
2023-12-14 22:11:33,855 - F-score: 0.9743292487549885
2023-12-14 22:11:33,855 - Accuracy: 0.9741176470588235
2023-12-14 22:11:33,855 - G-mean: 0.9744262079273145
2023-12-14 22:11:35,898 - ====================================================
2023-12-14 22:11:36,150 - Model: distilbert-base-uncased 2023-12-14_22-11-36 with 6 epochs
2023-12-14 22:15:35,594 - Epoch 1 average train loss: 0.5852009324203519
2023-12-14 22:19:41,271 - Epoch 2 average train loss: 0.10936961406732307
2023-12-14 22:23:50,257 - Epoch 3 average train loss: 0.05351589271908297
2023-12-14 22:27:59,820 - Epoch 4 average train loss: 0.02984788457808249
2023-12-14 22:31:59,252 - Epoch 5 average train loss: 0.017860433667870785
2023-12-14 22:35:40,878 - Epoch 6 average train loss: 0.009350674392395269
2023-12-14 22:36:05,411 - 2023-12-14_22-11-36 with 6 epochs: Evaluation Results:
2023-12-14 22:36:05,411 - Training time: 1444.6668899059296 seconds
2023-12-14 22:36:05,411 - Inference time: 24.525999784469604 seconds
2023-12-14 22:36:05,411 - Precision: 0.9714677257596056
2023-12-14 22:36:05,411 - Recall: 0.9705997089968335
2023-12-14 22:36:05,411 - F-score: 0.9709437933079889
2023-12-14 22:36:05,412 - Accuracy: 0.9705882352941176
2023-12-14 22:36:05,412 - G-mean: 0.9705939721285213
2023-12-14 22:36:33,203 - distilbert-base-uncased 2023-12-14_22-11-36 with 6 epochs: Evaluation Results (completely new data):
2023-12-14 22:36:33,203 - Training time: 1444.6668899059296 seconds
2023-12-14 22:36:33,204 - Inference time: 24.339003562927246 seconds
2023-12-14 22:36:33,204 - Precision: 0.9726571630657505
2023-12-14 22:36:33,204 - Recall: 0.9737004821723823
2023-12-14 22:36:33,204 - F-score: 0.9730918429299515
2023-12-14 22:36:33,204 - Accuracy: 0.9729411764705882
2023-12-14 22:36:33,204 - G-mean: 0.973320755277918
2023-12-14 22:36:35,148 - ====================================================
2023-12-14 22:36:35,398 - Model: distilbert-base-uncased 2023-12-14_22-36-35 with 6 epochs
2023-12-14 22:40:15,828 - Epoch 1 average train loss: 0.606796806104043
2023-12-14 22:43:56,587 - Epoch 2 average train loss: 0.11277464938295238
2023-12-14 22:47:43,411 - Epoch 3 average train loss: 0.05612215624793487
2023-12-14 22:51:32,757 - Epoch 4 average train loss: 0.03513523597105899
2023-12-14 22:55:22,519 - Epoch 5 average train loss: 0.02249574183486402
2023-12-14 22:59:12,186 - Epoch 6 average train loss: 0.014741621822913123
2023-12-14 22:59:37,981 - 2023-12-14_22-36-35 with 6 epochs: Evaluation Results:
2023-12-14 22:59:37,981 - Training time: 1356.7344944477081 seconds
2023-12-14 22:59:37,981 - Inference time: 25.78647756576538 seconds
2023-12-14 22:59:37,981 - Precision: 0.9684523734320483
2023-12-14 22:59:37,981 - Recall: 0.9683083875033585
2023-12-14 22:59:37,981 - F-score: 0.9681615326370856
2023-12-14 22:59:37,981 - Accuracy: 0.9682352941176471
2023-12-14 22:59:37,981 - G-mean: 0.968271840120789
2023-12-14 23:00:06,253 - distilbert-base-uncased 2023-12-14_22-36-35 with 6 epochs: Evaluation Results (completely new data):
2023-12-14 23:00:06,253 - Training time: 1356.7344944477081 seconds
2023-12-14 23:00:06,253 - Inference time: 24.629000663757324 seconds
2023-12-14 23:00:06,253 - Precision: 0.9726904878664827
2023-12-14 23:00:06,253 - Recall: 0.9736072101912854
2023-12-14 23:00:06,253 - F-score: 0.9730010135242197
2023-12-14 23:00:06,253 - Accuracy: 0.9729411764705882
2023-12-14 23:00:06,253 - G-mean: 0.9732741363581776
