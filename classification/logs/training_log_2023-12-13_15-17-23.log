2023-12-13 15:17:37,412 - ====================================================
2023-12-13 15:17:37,620 - Model: distilbert-base-uncased 2023-12-13_15-17-37 with 1 epochs
2023-12-13 15:21:16,987 - Epoch 1 average train loss: 0.5945944090713473
2023-12-13 15:21:41,797 - 2023-12-13_15-17-37 with 1 epochs: Evaluation Results:
2023-12-13 15:21:41,797 - Training time: 219.29998922348022 seconds
2023-12-13 15:21:41,797 - Inference time: 24.802034854888916 seconds
2023-12-13 15:21:41,797 - Precision: 0.9523838609830474
2023-12-13 15:21:41,797 - Recall: 0.9520504090705121
2023-12-13 15:21:41,797 - F-score: 0.9520913767693528
2023-12-13 15:21:41,797 - Accuracy: 0.951764705882353
2023-12-13 15:21:41,802 - G-mean: 0.9519075467576511
2023-12-13 15:22:09,805 - distilbert-base-uncased 2023-12-13_15-17-37 with 1 epochs: Evaluation Results (completely new data):
2023-12-13 15:22:09,805 - Training time: 219.29998922348022 seconds
2023-12-13 15:22:09,805 - Inference time: 24.647034883499146 seconds
2023-12-13 15:22:09,805 - Precision: 0.9579789809472153
2023-12-13 15:22:09,805 - Recall: 0.957464610517877
2023-12-13 15:22:09,805 - F-score: 0.9576022901467093
2023-12-13 15:22:09,805 - Accuracy: 0.9576470588235294
2023-12-13 15:22:09,805 - G-mean: 0.9575558303253451
2023-12-13 15:22:11,635 - ====================================================
2023-12-13 15:22:11,891 - Model: distilbert-base-uncased 2023-12-13_15-22-11 with 1 epochs
2023-12-13 15:25:53,460 - Epoch 1 average train loss: 0.5813377861327985
2023-12-13 15:26:18,284 - 2023-12-13_15-22-11 with 1 epochs: Evaluation Results:
2023-12-13 15:26:18,284 - Training time: 221.51384115219116 seconds
2023-12-13 15:26:18,284 - Inference time: 24.81500005722046 seconds
2023-12-13 15:26:18,284 - Precision: 0.9544484457916275
2023-12-13 15:26:18,284 - Recall: 0.9549295039302512
2023-12-13 15:26:18,284 - F-score: 0.9546575197417158
2023-12-13 15:26:18,284 - Accuracy: 0.9541176470588235
2023-12-13 15:26:18,284 - G-mean: 0.9545234891803244
2023-12-13 15:26:46,651 - distilbert-base-uncased 2023-12-13_15-22-11 with 1 epochs: Evaluation Results (completely new data):
2023-12-13 15:26:46,651 - Training time: 221.51384115219116 seconds
2023-12-13 15:26:46,652 - Inference time: 24.945534467697144 seconds
2023-12-13 15:26:46,652 - Precision: 0.9582740829233665
2023-12-13 15:26:46,652 - Recall: 0.9595149333082134
2023-12-13 15:26:46,652 - F-score: 0.9587263756858118
2023-12-13 15:26:46,652 - Accuracy: 0.9588235294117647
2023-12-13 15:26:46,652 - G-mean: 0.9591691690613681
2023-12-13 15:26:48,501 - ====================================================
2023-12-13 15:26:48,741 - Model: distilbert-base-uncased 2023-12-13_15-26-48 with 1 epochs
2023-12-13 15:30:30,913 - Epoch 1 average train loss: 0.5902689207476728
2023-12-13 15:30:55,744 - 2023-12-13_15-26-48 with 1 epochs: Evaluation Results:
2023-12-13 15:30:55,744 - Training time: 222.11674094200134 seconds
2023-12-13 15:30:55,744 - Inference time: 24.822998762130737 seconds
2023-12-13 15:30:55,744 - Precision: 0.9516004861692865
2023-12-13 15:30:55,744 - Recall: 0.951401680847221
2023-12-13 15:30:55,744 - F-score: 0.9513487402532324
2023-12-13 15:30:55,744 - Accuracy: 0.9505882352941176
2023-12-13 15:30:55,744 - G-mean: 0.9509948710967988
2023-12-13 15:31:23,889 - distilbert-base-uncased 2023-12-13_15-26-48 with 1 epochs: Evaluation Results (completely new data):
2023-12-13 15:31:23,889 - Training time: 222.11674094200134 seconds
2023-12-13 15:31:23,889 - Inference time: 24.734966039657593 seconds
2023-12-13 15:31:23,889 - Precision: 0.965462966787048
2023-12-13 15:31:23,890 - Recall: 0.9655796339261353
2023-12-13 15:31:23,890 - F-score: 0.965239225215738
2023-12-13 15:31:23,890 - Accuracy: 0.9647058823529412
2023-12-13 15:31:23,890 - G-mean: 0.9651426592627342
2023-12-13 15:31:25,757 - ====================================================
2023-12-13 15:31:25,984 - Model: distilbert-base-uncased 2023-12-13_15-31-25 with 2 epochs
2023-12-13 15:35:08,491 - Epoch 1 average train loss: 0.5695270165976356
2023-12-13 15:38:57,873 - Epoch 2 average train loss: 0.10620126445065527
2023-12-13 15:39:23,182 - 2023-12-13_15-31-25 with 2 epochs: Evaluation Results:
2023-12-13 15:39:23,182 - Training time: 451.83327889442444 seconds
2023-12-13 15:39:23,182 - Inference time: 25.299999952316284 seconds
2023-12-13 15:39:23,182 - Precision: 0.9604060192141196
2023-12-13 15:39:23,182 - Recall: 0.9586171820750717
2023-12-13 15:39:23,182 - F-score: 0.9591630918430901
2023-12-13 15:39:23,182 - Accuracy: 0.9588235294117647
2023-12-13 15:39:23,182 - G-mean: 0.9587203501918485
2023-12-13 15:39:52,017 - distilbert-base-uncased 2023-12-13_15-31-25 with 2 epochs: Evaluation Results (completely new data):
2023-12-13 15:39:52,017 - Training time: 451.83327889442444 seconds
2023-12-13 15:39:52,017 - Inference time: 25.070080041885376 seconds
2023-12-13 15:39:52,017 - Precision: 0.9598100112978718
2023-12-13 15:39:52,017 - Recall: 0.9591939174714321
2023-12-13 15:39:52,017 - F-score: 0.9591863658358258
2023-12-13 15:39:52,017 - Accuracy: 0.9588235294117647
2023-12-13 15:39:52,017 - G-mean: 0.9590087055602027
2023-12-13 15:39:52,061 - Model distilbert-base-uncased 2023-12-13_15-31-25 not saved
2023-12-13 15:39:52,061 - ====================================================
2023-12-13 15:39:52,340 - Model: distilbert-base-uncased 2023-12-13_15-39-52 with 2 epochs
2023-12-13 15:43:36,523 - Epoch 1 average train loss: 0.578440645994509
2023-12-13 15:47:25,493 - Epoch 2 average train loss: 0.1115401767698281
2023-12-13 15:47:51,198 - 2023-12-13_15-39-52 with 2 epochs: Evaluation Results:
2023-12-13 15:47:51,198 - Training time: 453.0948588848114 seconds
2023-12-13 15:47:51,198 - Inference time: 25.697996616363525 seconds
2023-12-13 15:47:51,198 - Precision: 0.9673437381332117
2023-12-13 15:47:51,199 - Recall: 0.9668621200196397
2023-12-13 15:47:51,199 - F-score: 0.9670625529863293
2023-12-13 15:47:51,199 - Accuracy: 0.9670588235294117
2023-12-13 15:47:51,199 - G-mean: 0.9669604667727351
2023-12-13 15:48:20,869 - distilbert-base-uncased 2023-12-13_15-39-52 with 2 epochs: Evaluation Results (completely new data):
2023-12-13 15:48:20,869 - Training time: 453.0948588848114 seconds
2023-12-13 15:48:20,869 - Inference time: 25.814314603805542 seconds
2023-12-13 15:48:20,869 - Precision: 0.9658054728474316
2023-12-13 15:48:20,870 - Recall: 0.9663051335320662
2023-12-13 15:48:20,870 - F-score: 0.9659860544898876
2023-12-13 15:48:20,870 - Accuracy: 0.9658823529411765
2023-12-13 15:48:20,870 - G-mean: 0.9660937201095399
2023-12-13 15:48:22,774 - ====================================================
2023-12-13 15:48:23,015 - Model: distilbert-base-uncased 2023-12-13_15-48-23 with 2 epochs
2023-12-13 15:52:24,275 - Epoch 1 average train loss: 0.6037710657978759
2023-12-13 15:56:34,174 - Epoch 2 average train loss: 0.11140014305929927
2023-12-13 15:57:00,801 - 2023-12-13_15-48-23 with 2 epochs: Evaluation Results:
2023-12-13 15:57:00,802 - Training time: 491.1000442504883 seconds
2023-12-13 15:57:00,802 - Inference time: 26.62000060081482 seconds
2023-12-13 15:57:00,802 - Precision: 0.9611317765338624
2023-12-13 15:57:00,802 - Recall: 0.9585512856265493
2023-12-13 15:57:00,802 - F-score: 0.9594142525967886
2023-12-13 15:57:00,804 - Accuracy: 0.9588235294117647
2023-12-13 15:57:00,804 - G-mean: 0.9586873978553346
2023-12-13 15:57:30,444 - distilbert-base-uncased 2023-12-13_15-48-23 with 2 epochs: Evaluation Results (completely new data):
2023-12-13 15:57:30,444 - Training time: 491.1000442504883 seconds
2023-12-13 15:57:30,444 - Inference time: 25.881001234054565 seconds
2023-12-13 15:57:30,444 - Precision: 0.9691493033210824
2023-12-13 15:57:30,445 - Recall: 0.9685964550255411
2023-12-13 15:57:30,445 - F-score: 0.9686451024681372
2023-12-13 15:57:30,445 - Accuracy: 0.9682352941176471
2023-12-13 15:57:30,445 - G-mean: 0.9684158577351805
2023-12-13 15:57:32,734 - ====================================================
2023-12-13 15:57:33,073 - Model: distilbert-base-uncased 2023-12-13_15-57-33 with 3 epochs
2023-12-13 16:01:28,403 - Epoch 1 average train loss: 0.6151698484403245
2023-12-13 16:05:14,595 - Epoch 2 average train loss: 0.1127567264788291
2023-12-13 16:09:00,987 - Epoch 3 average train loss: 0.05701561054543537
2023-12-13 16:09:25,845 - 2023-12-13_15-57-33 with 3 epochs: Evaluation Results:
2023-12-13 16:09:25,845 - Training time: 687.8593258857727 seconds
2023-12-13 16:09:25,845 - Inference time: 24.85100030899048 seconds
2023-12-13 16:09:25,845 - Precision: 0.9606706024832448
2023-12-13 16:09:25,845 - Recall: 0.9589937678064263
2023-12-13 16:09:25,845 - F-score: 0.9595164491138828
2023-12-13 16:09:25,845 - Accuracy: 0.9588235294117647
2023-12-13 16:09:25,845 - G-mean: 0.9589086448312185
2023-12-13 16:09:53,920 - distilbert-base-uncased 2023-12-13_15-57-33 with 3 epochs: Evaluation Results (completely new data):
2023-12-13 16:09:53,920 - Training time: 687.8593258857727 seconds
2023-12-13 16:09:53,920 - Inference time: 24.728999853134155 seconds
2023-12-13 16:09:53,920 - Precision: 0.9679439768517162
2023-12-13 16:09:53,920 - Recall: 0.9673694611605104
2023-12-13 16:09:53,920 - F-score: 0.9673652640322524
2023-12-13 16:09:53,920 - Accuracy: 0.9670588235294117
2023-12-13 16:09:53,920 - G-mean: 0.9672141298741267
2023-12-13 16:09:53,956 - Model distilbert-base-uncased 2023-12-13_15-57-33 not saved
2023-12-13 16:09:53,956 - ====================================================
2023-12-13 16:09:54,403 - Model: distilbert-base-uncased 2023-12-13_16-09-54 with 3 epochs
2023-12-13 16:13:38,418 - Epoch 1 average train loss: 0.6005127335295958
2023-12-13 16:17:22,199 - Epoch 2 average train loss: 0.1246729758491411
2023-12-13 16:21:06,379 - Epoch 3 average train loss: 0.05862277395475437
2023-12-13 16:21:31,317 - 2023-12-13_16-09-54 with 3 epochs: Evaluation Results:
2023-12-13 16:21:31,317 - Training time: 671.9187970161438 seconds
2023-12-13 16:21:31,317 - Inference time: 24.929964065551758 seconds
2023-12-13 16:21:31,317 - Precision: 0.9639550742920644
2023-12-13 16:21:31,317 - Recall: 0.9634336344575811
2023-12-13 16:21:31,317 - F-score: 0.9636446922017614
2023-12-13 16:21:31,317 - Accuracy: 0.9635294117647059
2023-12-13 16:21:31,317 - G-mean: 0.9634815219210204
2023-12-13 16:21:59,407 - distilbert-base-uncased 2023-12-13_16-09-54 with 3 epochs: Evaluation Results (completely new data):
2023-12-13 16:21:59,407 - Training time: 671.9187970161438 seconds
2023-12-13 16:21:59,407 - Inference time: 24.692999124526978 seconds
2023-12-13 16:21:59,407 - Precision: 0.9680554916490565
2023-12-13 16:21:59,407 - Recall: 0.9688532676949662
2023-12-13 16:21:59,407 - F-score: 0.968376800762651
2023-12-13 16:21:59,407 - Accuracy: 0.9682352941176471
2023-12-13 16:21:59,407 - G-mean: 0.9685442316195368
2023-12-13 16:22:01,308 - ====================================================
2023-12-13 16:22:01,535 - Model: distilbert-base-uncased 2023-12-13_16-22-01 with 3 epochs
2023-12-13 16:25:45,680 - Epoch 1 average train loss: 0.6043079636202139
2023-12-13 16:29:29,811 - Epoch 2 average train loss: 0.11381408543709447
2023-12-13 16:33:14,200 - Epoch 3 average train loss: 0.05452654453542303
2023-12-13 16:33:38,988 - 2023-12-13_16-22-01 with 3 epochs: Evaluation Results:
2023-12-13 16:33:38,988 - Training time: 672.6087913513184 seconds
2023-12-13 16:33:38,988 - Inference time: 24.779998779296875 seconds
2023-12-13 16:33:38,988 - Precision: 0.9666983575283042
2023-12-13 16:33:38,988 - Recall: 0.9656641949683495
2023-12-13 16:33:38,988 - F-score: 0.9660703645621032
2023-12-13 16:33:38,988 - Accuracy: 0.9658823529411765
2023-12-13 16:33:38,988 - G-mean: 0.9657732677948155
2023-12-13 16:34:06,923 - distilbert-base-uncased 2023-12-13_16-22-01 with 3 epochs: Evaluation Results (completely new data):
2023-12-13 16:34:06,923 - Training time: 672.6087913513184 seconds
2023-12-13 16:34:06,923 - Inference time: 24.57696270942688 seconds
2023-12-13 16:34:06,923 - Precision: 0.965585018455198
2023-12-13 16:34:06,923 - Recall: 0.9648855301649668
2023-12-13 16:34:06,923 - F-score: 0.965002383269057
2023-12-13 16:34:06,923 - Accuracy: 0.9647058823529412
2023-12-13 16:34:06,923 - G-mean: 0.9647957020775848
2023-12-13 16:34:06,958 - Model distilbert-base-uncased 2023-12-13_16-22-01 not saved
2023-12-13 16:34:06,958 - ====================================================
2023-12-13 16:34:07,224 - Model: distilbert-base-uncased 2023-12-13_16-34-07 with 4 epochs
2023-12-13 16:37:50,668 - Epoch 1 average train loss: 0.595634676919264
2023-12-13 16:41:34,938 - Epoch 2 average train loss: 0.11085676872774082
2023-12-13 16:45:20,029 - Epoch 3 average train loss: 0.05796572829432347
2023-12-13 16:49:04,536 - Epoch 4 average train loss: 0.03025785679161987
2023-12-13 16:49:29,387 - 2023-12-13_16-34-07 with 4 epochs: Evaluation Results:
2023-12-13 16:49:29,387 - Training time: 897.2552645206451 seconds
2023-12-13 16:49:29,387 - Inference time: 24.84299921989441 seconds
2023-12-13 16:49:29,387 - Precision: 0.9661769244125358
2023-12-13 16:49:29,387 - Recall: 0.9644612974870304
2023-12-13 16:49:29,387 - F-score: 0.9651754785546313
2023-12-13 16:49:29,387 - Accuracy: 0.9647058823529412
2023-12-13 16:49:29,387 - G-mean: 0.9645835821677083
2023-12-13 16:49:57,361 - distilbert-base-uncased 2023-12-13_16-34-07 with 4 epochs: Evaluation Results (completely new data):
2023-12-13 16:49:57,361 - Training time: 897.2552645206451 seconds
2023-12-13 16:49:57,361 - Inference time: 24.5889675617218 seconds
2023-12-13 16:49:57,362 - Precision: 0.9726357384215369
2023-12-13 16:49:57,362 - Recall: 0.9720557583048237
2023-12-13 16:49:57,362 - F-score: 0.972177141752011
2023-12-13 16:49:57,362 - Accuracy: 0.971764705882353
2023-12-13 16:49:57,362 - G-mean: 0.9719102211986118
2023-12-13 16:49:59,207 - ====================================================
2023-12-13 16:49:59,475 - Model: distilbert-base-uncased 2023-12-13_16-49-59 with 4 epochs
2023-12-13 16:53:44,181 - Epoch 1 average train loss: 0.5996465985827586
2023-12-13 16:57:32,004 - Epoch 2 average train loss: 0.11566282437785583
2023-12-13 17:01:17,827 - Epoch 3 average train loss: 0.05866117383956033
2023-12-13 17:05:03,985 - Epoch 4 average train loss: 0.030207751841448686
2023-12-13 17:05:28,992 - 2023-12-13_16-49-59 with 4 epochs: Evaluation Results:
2023-12-13 17:05:28,992 - Training time: 904.4520599842072 seconds
2023-12-13 17:05:28,992 - Inference time: 24.99903416633606 seconds
2023-12-13 17:05:28,992 - Precision: 0.9638625644795095
2023-12-13 17:05:28,992 - Recall: 0.963566357428685
2023-12-13 17:05:28,992 - F-score: 0.9634726297124494
2023-12-13 17:05:28,992 - Accuracy: 0.9635294117647059
2023-12-13 17:05:28,992 - G-mean: 0.9635478844196178
2023-12-13 17:05:57,205 - distilbert-base-uncased 2023-12-13_16-49-59 with 4 epochs: Evaluation Results (completely new data):
2023-12-13 17:05:57,205 - Training time: 904.4520599842072 seconds
2023-12-13 17:05:57,205 - Inference time: 24.73799967765808 seconds
2023-12-13 17:05:57,205 - Precision: 0.9676142009019554
2023-12-13 17:05:57,205 - Recall: 0.9687651868020026
2023-12-13 17:05:57,205 - F-score: 0.9679275288299969
2023-12-13 17:05:57,205 - Accuracy: 0.9682352941176471
2023-12-13 17:05:57,205 - G-mean: 0.9685002042199963
2023-12-13 17:05:57,241 - Model distilbert-base-uncased 2023-12-13_16-49-59 not saved
2023-12-13 17:05:57,241 - ====================================================
2023-12-13 17:05:57,660 - Model: distilbert-base-uncased 2023-12-13_17-05-57 with 4 epochs
2023-12-13 17:09:43,173 - Epoch 1 average train loss: 0.5959038959355916
2023-12-13 17:13:29,314 - Epoch 2 average train loss: 0.10740296867183026
2023-12-13 17:17:15,076 - Epoch 3 average train loss: 0.0542081804485882
2023-12-13 17:21:01,039 - Epoch 4 average train loss: 0.031306359366349436
2023-12-13 17:21:26,168 - 2023-12-13_17-05-57 with 4 epochs: Evaluation Results:
2023-12-13 17:21:26,168 - Training time: 903.3216795921326 seconds
2023-12-13 17:21:26,168 - Inference time: 25.12100076675415 seconds
2023-12-13 17:21:26,168 - Precision: 0.9675390904805911
2023-12-13 17:21:26,168 - Recall: 0.9668862164033512
2023-12-13 17:21:26,168 - F-score: 0.9671786522820295
2023-12-13 17:21:26,168 - Accuracy: 0.9670588235294117
2023-12-13 17:21:26,168 - G-mean: 0.9669725161150284
2023-12-13 17:21:54,539 - distilbert-base-uncased 2023-12-13_17-05-57 with 4 epochs: Evaluation Results (completely new data):
2023-12-13 17:21:54,539 - Training time: 903.3216795921326 seconds
2023-12-13 17:21:54,539 - Inference time: 24.765984296798706 seconds
2023-12-13 17:21:54,539 - Precision: 0.9742720817612629
2023-12-13 17:21:54,539 - Recall: 0.974386530788306
2023-12-13 17:21:54,539 - F-score: 0.974313868337528
2023-12-13 17:21:54,540 - Accuracy: 0.9741176470588235
2023-12-13 17:21:54,540 - G-mean: 0.9742520796474158
2023-12-13 17:21:56,460 - Total program time: 7473.060677051544 seconds
