2023-12-14 02:11:29,568 - ====================================================
2023-12-14 02:11:29,857 - Model: distilbert-base-uncased 2023-12-14_02-11-29 with 5 epochs
2023-12-14 02:15:12,685 - Epoch 1 average train loss: 0.6121949562430382
2023-12-14 02:18:57,686 - Epoch 2 average train loss: 0.11754601351259386
2023-12-14 02:22:43,122 - Epoch 3 average train loss: 0.05422820888678817
2023-12-14 02:26:28,203 - Epoch 4 average train loss: 0.032599443769191994
2023-12-14 02:30:13,284 - Epoch 5 average train loss: 0.019342995799584862
2023-12-14 02:30:38,335 - 2023-12-14_02-11-29 with 5 epochs: Evaluation Results:
2023-12-14 02:30:38,335 - Training time: 1123.3629693984985 seconds
2023-12-14 02:30:38,340 - Inference time: 25.04199981689453 seconds
2023-12-14 02:30:38,340 - Precision: 0.9675891295675445
2023-12-14 02:30:38,340 - Recall: 0.9669846794725812
2023-12-14 02:30:38,340 - F-score: 0.9670871452323858
2023-12-14 02:30:38,340 - Accuracy: 0.9670588235294117
2023-12-14 02:30:38,340 - G-mean: 0.9670217507903944
2023-12-14 02:31:06,787 - distilbert-base-uncased 2023-12-14_02-11-29 with 5 epochs: Evaluation Results (completely new data):
2023-12-14 02:31:06,787 - Training time: 1123.3629693984985 seconds
2023-12-14 02:31:06,787 - Inference time: 24.89700222015381 seconds
2023-12-14 02:31:06,787 - Precision: 0.9682141061000369
2023-12-14 02:31:06,787 - Recall: 0.9685092485843192
2023-12-14 02:31:06,787 - F-score: 0.9682529839356594
2023-12-14 02:31:06,787 - Accuracy: 0.9682352941176471
2023-12-14 02:31:06,787 - G-mean: 0.9683722616631993
2023-12-14 02:31:08,851 - ====================================================
2023-12-14 02:31:09,318 - Model: distilbert-base-uncased 2023-12-14_02-31-09 with 5 epochs
2023-12-14 02:34:53,398 - Epoch 1 average train loss: 0.5834587297983029
2023-12-14 02:38:37,122 - Epoch 2 average train loss: 0.11264654239530072
2023-12-14 02:42:20,557 - Epoch 3 average train loss: 0.05922103942645823
2023-12-14 02:46:04,029 - Epoch 4 average train loss: 0.03431784995448063
2023-12-14 02:49:47,391 - Epoch 5 average train loss: 0.02010619407533394
2023-12-14 02:50:12,322 - 2023-12-14_02-31-09 with 5 epochs: Evaluation Results:
2023-12-14 02:50:12,322 - Training time: 1118.017415046692 seconds
2023-12-14 02:50:12,322 - Inference time: 24.922999143600464 seconds
2023-12-14 02:50:12,322 - Precision: 0.9666776579044299
2023-12-14 02:50:12,322 - Recall: 0.9658910643722921
2023-12-14 02:50:12,322 - F-score: 0.9661518869436654
2023-12-14 02:50:12,322 - Accuracy: 0.9658823529411765
2023-12-14 02:50:12,322 - G-mean: 0.9658867086469132
2023-12-14 02:50:40,585 - distilbert-base-uncased 2023-12-14_02-31-09 with 5 epochs: Evaluation Results (completely new data):
2023-12-14 02:50:40,585 - Training time: 1118.017415046692 seconds
2023-12-14 02:50:40,585 - Inference time: 24.868999242782593 seconds
2023-12-14 02:50:40,586 - Precision: 0.9660678380449813
2023-12-14 02:50:40,586 - Recall: 0.9660253175887755
2023-12-14 02:50:40,586 - F-score: 0.9659492487497217
2023-12-14 02:50:40,586 - Accuracy: 0.9658823529411765
2023-12-14 02:50:40,586 - G-mean: 0.9659538326200656
2023-12-14 02:50:40,622 - Model distilbert-base-uncased 2023-12-14_02-31-09 not saved
2023-12-14 02:50:40,623 - ====================================================
2023-12-14 02:50:40,862 - Model: distilbert-base-uncased 2023-12-14_02-50-40 with 6 epochs
2023-12-14 02:54:22,995 - Epoch 1 average train loss: 0.6175214218918015
2023-12-14 02:58:05,144 - Epoch 2 average train loss: 0.10975827974431655
2023-12-14 03:01:47,560 - Epoch 3 average train loss: 0.052126952877596895
2023-12-14 03:05:29,892 - Epoch 4 average train loss: 0.02616421942955212
2023-12-14 03:09:11,856 - Epoch 5 average train loss: 0.014687321101698805
2023-12-14 03:12:53,690 - Epoch 6 average train loss: 0.009441282028291266
2023-12-14 03:13:18,498 - 2023-12-14_02-50-40 with 6 epochs: Evaluation Results:
2023-12-14 03:13:18,498 - Training time: 1332.7637343406677 seconds
2023-12-14 03:13:18,498 - Inference time: 24.801997900009155 seconds
2023-12-14 03:13:18,498 - Precision: 0.9710203080050022
2023-12-14 03:13:18,498 - Recall: 0.9705697657313511
2023-12-14 03:13:18,498 - F-score: 0.9706602687855336
2023-12-14 03:13:18,498 - Accuracy: 0.9705882352941176
2023-12-14 03:13:18,498 - G-mean: 0.9705790004688012
2023-12-14 03:13:46,721 - distilbert-base-uncased 2023-12-14_02-50-40 with 6 epochs: Evaluation Results (completely new data):
2023-12-14 03:13:46,721 - Training time: 1332.7637343406677 seconds
2023-12-14 03:13:46,721 - Inference time: 24.763000011444092 seconds
2023-12-14 03:13:46,721 - Precision: 0.9702580343600264
2023-12-14 03:13:46,721 - Recall: 0.9710265650299951
2023-12-14 03:13:46,721 - F-score: 0.9705312405872508
2023-12-14 03:13:46,721 - Accuracy: 0.9705882352941176
2023-12-14 03:13:46,722 - G-mean: 0.9708073754232462
2023-12-14 03:13:48,575 - ====================================================
2023-12-14 03:13:48,927 - Model: distilbert-base-uncased 2023-12-14_03-13-48 with 6 epochs
2023-12-14 03:17:30,957 - Epoch 1 average train loss: 0.5848173864273464
2023-12-14 03:21:13,156 - Epoch 2 average train loss: 0.1121474278849714
2023-12-14 03:24:55,419 - Epoch 3 average train loss: 0.05664900939144633
2023-12-14 03:28:37,631 - Epoch 4 average train loss: 0.036353666975217705
2023-12-14 03:32:19,780 - Epoch 5 average train loss: 0.019490167489823174
2023-12-14 03:36:01,927 - Epoch 6 average train loss: 0.010244842004852699
2023-12-14 03:36:26,798 - 2023-12-14_03-13-48 with 6 epochs: Evaluation Results:
2023-12-14 03:36:26,798 - Training time: 1332.9447901248932 seconds
2023-12-14 03:36:26,798 - Inference time: 24.862998723983765 seconds
2023-12-14 03:36:26,798 - Precision: 0.9625711473694736
2023-12-14 03:36:26,798 - Recall: 0.9605321921176136
2023-12-14 03:36:26,798 - F-score: 0.9613220534648172
2023-12-14 03:36:26,798 - Accuracy: 0.9611764705882353
2023-12-14 03:36:26,798 - G-mean: 0.9608542773521844
2023-12-14 03:36:54,890 - distilbert-base-uncased 2023-12-14_03-13-48 with 6 epochs: Evaluation Results (completely new data):
2023-12-14 03:36:54,890 - Training time: 1332.9447901248932 seconds
2023-12-14 03:36:54,890 - Inference time: 24.717001914978027 seconds
2023-12-14 03:36:54,890 - Precision: 0.9630180857549279
2023-12-14 03:36:54,890 - Recall: 0.962151782113932
2023-12-14 03:36:54,890 - F-score: 0.9623446800330996
2023-12-14 03:36:54,890 - Accuracy: 0.9623529411764706
2023-12-14 03:36:54,890 - G-mean: 0.9622523563886582
2023-12-14 03:36:54,928 - Model distilbert-base-uncased 2023-12-14_03-13-48 not saved
2023-12-14 03:36:54,928 - ====================================================
2023-12-14 03:36:55,214 - Model: distilbert-base-uncased 2023-12-14_03-36-55 with 7 epochs
2023-12-14 03:40:37,219 - Epoch 1 average train loss: 0.5950174306771334
2023-12-14 03:44:19,433 - Epoch 2 average train loss: 0.11102785246118027
2023-12-14 03:48:01,651 - Epoch 3 average train loss: 0.054466175508192355
2023-12-14 03:51:43,795 - Epoch 4 average train loss: 0.033038730629007605
2023-12-14 03:55:25,958 - Epoch 5 average train loss: 0.02023591207833413
2023-12-14 03:59:08,138 - Epoch 6 average train loss: 0.010888119341175565
2023-12-14 04:02:50,329 - Epoch 7 average train loss: 0.0064322337282903715
2023-12-14 04:03:15,085 - 2023-12-14_03-36-55 with 7 epochs: Evaluation Results:
2023-12-14 04:03:15,085 - Training time: 1555.053677558899 seconds
2023-12-14 04:03:15,085 - Inference time: 24.749000072479248 seconds
2023-12-14 04:03:15,085 - Precision: 0.9661217753340002
2023-12-14 04:03:15,085 - Recall: 0.964020564210637
2023-12-14 04:03:15,085 - F-score: 0.9648620924977663
2023-12-14 04:03:15,085 - Accuracy: 0.9647058823529412
2023-12-14 04:03:15,085 - G-mean: 0.9643631624047047
2023-12-14 04:03:43,085 - distilbert-base-uncased 2023-12-14_03-36-55 with 7 epochs: Evaluation Results (completely new data):
2023-12-14 04:03:43,085 - Training time: 1555.053677558899 seconds
2023-12-14 04:03:43,085 - Inference time: 24.633963584899902 seconds
2023-12-14 04:03:43,085 - Precision: 0.9621309366491311
2023-12-14 04:03:43,085 - Recall: 0.9605798946865127
2023-12-14 04:03:43,085 - F-score: 0.9612150872174847
2023-12-14 04:03:43,085 - Accuracy: 0.9611764705882353
2023-12-14 04:03:43,085 - G-mean: 0.9608781363382148
2023-12-14 04:03:43,122 - Model distilbert-base-uncased 2023-12-14_03-36-55 not saved
2023-12-14 04:03:43,122 - ====================================================
2023-12-14 04:03:43,424 - Model: distilbert-base-uncased 2023-12-14_04-03-43 with 7 epochs
2023-12-14 04:07:25,262 - Epoch 1 average train loss: 0.5842536512981443
2023-12-14 04:11:07,257 - Epoch 2 average train loss: 0.10904834252289113
2023-12-14 04:14:49,355 - Epoch 3 average train loss: 0.05734526398317779
2023-12-14 04:18:31,370 - Epoch 4 average train loss: 0.03568571699235369
2023-12-14 04:22:13,461 - Epoch 5 average train loss: 0.018925056960981557
2023-12-14 04:25:55,475 - Epoch 6 average train loss: 0.010651778657167384
2023-12-14 04:29:37,578 - Epoch 7 average train loss: 0.006141341485850074
2023-12-14 04:30:02,331 - 2023-12-14_04-03-43 with 7 epochs: Evaluation Results:
2023-12-14 04:30:02,331 - Training time: 1554.0931618213654 seconds
2023-12-14 04:30:02,331 - Inference time: 24.74608874320984 seconds
2023-12-14 04:30:02,331 - Precision: 0.9676795995407421
2023-12-14 04:30:02,331 - Recall: 0.9670137482863218
2023-12-14 04:30:02,331 - F-score: 0.967288619375989
2023-12-14 04:30:02,331 - Accuracy: 0.9670588235294117
2023-12-14 04:30:02,331 - G-mean: 0.9670362856452374
2023-12-14 04:30:30,473 - distilbert-base-uncased 2023-12-14_04-03-43 with 7 epochs: Evaluation Results (completely new data):
2023-12-14 04:30:30,473 - Training time: 1554.0931618213654 seconds
2023-12-14 04:30:30,474 - Inference time: 24.622000217437744 seconds
2023-12-14 04:30:30,474 - Precision: 0.9703765938189237
2023-12-14 04:30:30,474 - Recall: 0.9710265650299951
2023-12-14 04:30:30,474 - F-score: 0.9705409601048597
2023-12-14 04:30:30,474 - Accuracy: 0.9705882352941176
2023-12-14 04:30:30,474 - G-mean: 0.9708073754232462
2023-12-14 04:30:32,337 - ====================================================
2023-12-14 04:30:32,680 - Model: distilbert-base-uncased 2023-12-14_04-30-32 with 10 epochs
2023-12-14 04:34:14,523 - Epoch 1 average train loss: 0.5736147681667524
2023-12-14 04:37:56,420 - Epoch 2 average train loss: 0.10571132790954674
2023-12-14 04:41:38,272 - Epoch 3 average train loss: 0.048639510408701264
2023-12-14 04:45:20,785 - Epoch 4 average train loss: 0.02709353500045836
2023-12-14 04:49:03,080 - Epoch 5 average train loss: 0.01941554320647436
2023-12-14 04:52:45,429 - Epoch 6 average train loss: 0.013120657640906488
2023-12-14 04:56:27,807 - Epoch 7 average train loss: 0.002313163344618207
2023-12-14 05:00:09,666 - Epoch 8 average train loss: 0.006876974967633621
2023-12-14 05:03:51,559 - Epoch 9 average train loss: 0.0045851856804673685
2023-12-14 05:07:33,416 - Epoch 10 average train loss: 0.00007585873539937893
2023-12-14 05:07:58,217 - 2023-12-14_04-30-32 with 10 epochs: Evaluation Results:
2023-12-14 05:07:58,217 - Training time: 2220.681970357895 seconds
2023-12-14 05:07:58,217 - Inference time: 24.793001174926758 seconds
2023-12-14 05:07:58,217 - Precision: 0.9666375729886976
2023-12-14 05:07:58,217 - Recall: 0.965914286304262
2023-12-14 05:07:58,217 - F-score: 0.966159132774081
2023-12-14 05:07:58,217 - Accuracy: 0.9658823529411765
2023-12-14 05:07:58,217 - G-mean: 0.9658983194907514
2023-12-14 05:08:26,407 - distilbert-base-uncased 2023-12-14_04-30-32 with 10 epochs: Evaluation Results (completely new data):
2023-12-14 05:08:26,408 - Training time: 2220.681970357895 seconds
2023-12-14 05:08:26,408 - Inference time: 24.71299934387207 seconds
2023-12-14 05:08:26,408 - Precision: 0.9726544291098111
2023-12-14 05:08:26,408 - Recall: 0.973258874444247
2023-12-14 05:08:26,408 - F-score: 0.9728897953660118
2023-12-14 05:08:26,408 - Accuracy: 0.9729411764705882
2023-12-14 05:08:26,408 - G-mean: 0.9731000124921518
2023-12-14 05:08:28,517 - ====================================================
2023-12-14 05:08:28,794 - Model: distilbert-base-uncased 2023-12-14_05-08-28 with 10 epochs
2023-12-14 05:12:10,297 - Epoch 1 average train loss: 0.5982805894665858
2023-12-14 05:15:51,602 - Epoch 2 average train loss: 0.10763798094409353
2023-12-14 05:19:32,973 - Epoch 3 average train loss: 0.04378427545704386
2023-12-14 05:23:14,369 - Epoch 4 average train loss: 0.028258748686708073
2023-12-14 05:26:55,760 - Epoch 5 average train loss: 0.014069562443559442
2023-12-14 05:30:37,144 - Epoch 6 average train loss: 0.014133272401043487
2023-12-14 05:34:18,610 - Epoch 7 average train loss: 0.00442905752455665
2023-12-14 05:38:00,004 - Epoch 8 average train loss: 0.014942596222236341
2023-12-14 05:41:41,390 - Epoch 9 average train loss: 0.010499957853659425
2023-12-14 05:45:22,792 - Epoch 10 average train loss: 0.003840723038674161
2023-12-14 05:45:47,592 - 2023-12-14_05-08-28 with 10 epochs: Evaluation Results:
2023-12-14 05:45:47,592 - Training time: 2213.9430775642395 seconds
2023-12-14 05:45:47,592 - Inference time: 24.792997121810913 seconds
2023-12-14 05:45:47,592 - Precision: 0.9742741526631686
2023-12-14 05:45:47,592 - Recall: 0.973867277225789
2023-12-14 05:45:47,592 - F-score: 0.9740475224210335
2023-12-14 05:45:47,592 - Accuracy: 0.9741176470588235
2023-12-14 05:45:47,592 - G-mean: 0.9739924540974476
2023-12-14 05:46:15,605 - distilbert-base-uncased 2023-12-14_05-08-28 with 10 epochs: Evaluation Results (completely new data):
2023-12-14 05:46:15,606 - Training time: 2213.9430775642395 seconds
2023-12-14 05:46:15,606 - Inference time: 24.632964849472046 seconds
2023-12-14 05:46:15,606 - Precision: 0.9705627501953822
2023-12-14 05:46:15,606 - Recall: 0.9711489058248326
2023-12-14 05:46:15,606 - F-score: 0.9708216231210345
2023-12-14 05:46:15,606 - Accuracy: 0.9705882352941176
2023-12-14 05:46:15,606 - G-mean: 0.9708685300865084
2023-12-14 05:46:15,642 - Model distilbert-base-uncased 2023-12-14_05-08-28 not saved
2023-12-14 05:46:15,642 - Total program time: 12902.060737371445 seconds
