2023-12-13 13:02:19,733 - ====================================================
2023-12-13 13:02:20,264 - Model: distilbert-base-uncased 2023-12-13_13-02-20 with 4 epochs
2023-12-13 13:03:38,722 - Epoch 1 average train loss: 0.5882958752618116
2023-12-13 13:04:56,263 - Epoch 2 average train loss: 0.11782094495261417
2023-12-13 13:06:13,914 - Epoch 3 average train loss: 0.0581863202877781
2023-12-13 13:07:31,605 - Epoch 4 average train loss: 0.03261896597741939
2023-12-13 13:07:38,028 - 2023-12-13_13-02-20 with 4 epochs: Evaluation Results:
2023-12-13 13:07:38,028 - Training time: 311.293869972229 seconds
2023-12-13 13:07:38,028 - Inference time: 6.404501914978027 seconds
2023-12-13 13:07:38,028 - Precision: 0.9666578716843617
2023-12-13 13:07:38,028 - Recall: 0.965530816203608
2023-12-13 13:07:38,029 - F-score: 0.9660184704064516
2023-12-13 13:07:38,029 - Accuracy: 0.9658823529411765
2023-12-13 13:07:38,029 - G-mean: 0.9657065685765814
2023-12-13 13:07:46,656 - distilbert-base-uncased 2023-12-13_13-02-20 with 4 epochs: Evaluation Results (completely new data):
2023-12-13 13:07:46,656 - Training time: 311.293869972229 seconds
2023-12-13 13:07:46,656 - Inference time: 6.4522154331207275 seconds
2023-12-13 13:07:46,656 - Precision: 0.9678086728538453
2023-12-13 13:07:46,656 - Recall: 0.967432789876125
2023-12-13 13:07:46,656 - F-score: 0.9674391605375809
2023-12-13 13:07:46,656 - Accuracy: 0.9670588235294117
2023-12-13 13:07:46,656 - G-mean: 0.9672457886294372
2023-12-13 13:07:46,912 - ====================================================
2023-12-13 13:07:47,480 - Model: distilbert-base-uncased 2023-12-13_13-07-47 with 4 epochs
2023-12-13 13:09:05,177 - Epoch 1 average train loss: 0.5922057350681108
2023-12-13 13:10:23,001 - Epoch 2 average train loss: 0.11097861111164092
2023-12-13 13:11:40,945 - Epoch 3 average train loss: 0.05378273804398144
2023-12-13 13:12:58,803 - Epoch 4 average train loss: 0.030293564291342216
2023-12-13 13:13:05,220 - 2023-12-13_13-07-47 with 4 epochs: Evaluation Results:
2023-12-13 13:13:05,221 - Training time: 311.29091334342957 seconds
2023-12-13 13:13:05,221 - Inference time: 6.412391185760498 seconds
2023-12-13 13:13:05,221 - Precision: 0.9691231436651915
2023-12-13 13:13:05,221 - Recall: 0.9697995711649643
2023-12-13 13:13:05,221 - F-score: 0.9694047473681296
2023-12-13 13:13:05,221 - Accuracy: 0.9694117647058823
2023-12-13 13:13:05,221 - G-mean: 0.9696056485468904
2023-12-13 13:13:13,725 - distilbert-base-uncased 2023-12-13_13-07-47 with 4 epochs: Evaluation Results (completely new data):
2023-12-13 13:13:13,725 - Training time: 311.29091334342957 seconds
2023-12-13 13:13:13,725 - Inference time: 6.4643714427948 seconds
2023-12-13 13:13:13,725 - Precision: 0.9691231436651915
2023-12-13 13:13:13,725 - Recall: 0.9697995711649643
2023-12-13 13:13:13,725 - F-score: 0.9694047473681296
2023-12-13 13:13:13,725 - Accuracy: 0.9694117647058823
2023-12-13 13:13:13,725 - G-mean: 0.9696056485468904
2023-12-13 13:13:13,968 - ====================================================
2023-12-13 13:13:14,587 - Model: distilbert-base-uncased 2023-12-13_13-13-14 with 4 epochs
2023-12-13 13:14:32,334 - Epoch 1 average train loss: 0.5656734558063395
2023-12-13 13:15:50,193 - Epoch 2 average train loss: 0.10888640448231908
2023-12-13 13:17:08,055 - Epoch 3 average train loss: 0.05664970108800951
2023-12-13 13:18:25,928 - Epoch 4 average train loss: 0.03095929237356519
2023-12-13 13:18:32,352 - 2023-12-13_13-13-14 with 4 epochs: Evaluation Results:
2023-12-13 13:18:32,352 - Training time: 311.303750038147 seconds
2023-12-13 13:18:32,352 - Inference time: 6.420140743255615 seconds
2023-12-13 13:18:32,352 - Precision: 0.9731108129782597
2023-12-13 13:18:32,352 - Recall: 0.9732536833561138
2023-12-13 13:18:32,352 - F-score: 0.9731254282684452
2023-12-13 13:18:32,352 - Accuracy: 0.9729411764705882
2023-12-13 13:18:32,352 - G-mean: 0.9730974173682874
2023-12-13 13:18:40,837 - distilbert-base-uncased 2023-12-13_13-13-14 with 4 epochs: Evaluation Results (completely new data):
2023-12-13 13:18:40,837 - Training time: 311.303750038147 seconds
2023-12-13 13:18:40,837 - Inference time: 6.452873706817627 seconds
2023-12-13 13:18:40,837 - Precision: 0.9731108129782597
2023-12-13 13:18:40,838 - Recall: 0.9732536833561138
2023-12-13 13:18:40,838 - F-score: 0.9731254282684452
2023-12-13 13:18:40,838 - Accuracy: 0.9729411764705882
2023-12-13 13:18:40,838 - G-mean: 0.9730974173682874
2023-12-13 13:18:41,089 - ====================================================
2023-12-13 13:18:41,723 - Model: distilbert-base-uncased 2023-12-13_13-18-41 with 4 epochs
2023-12-13 13:19:59,507 - Epoch 1 average train loss: 0.60012002048247
2023-12-13 13:21:17,366 - Epoch 2 average train loss: 0.11132402943775935
2023-12-13 13:22:35,210 - Epoch 3 average train loss: 0.05556095249841318
2023-12-13 13:23:53,102 - Epoch 4 average train loss: 0.03194540741332971
2023-12-13 13:23:59,502 - 2023-12-13_13-18-41 with 4 epochs: Evaluation Results:
2023-12-13 13:23:59,502 - Training time: 311.3497221469879 seconds
2023-12-13 13:23:59,502 - Inference time: 6.394185543060303 seconds
2023-12-13 13:23:59,502 - Precision: 0.9633827088271069
2023-12-13 13:23:59,502 - Recall: 0.9606328412258607
2023-12-13 13:23:59,502 - F-score: 0.9614282665664813
2023-12-13 13:23:59,502 - Accuracy: 0.9611764705882353
2023-12-13 13:23:59,502 - G-mean: 0.9609046174624313
2023-12-13 13:24:08,052 - distilbert-base-uncased 2023-12-13_13-18-41 with 4 epochs: Evaluation Results (completely new data):
2023-12-13 13:24:08,052 - Training time: 311.3497221469879 seconds
2023-12-13 13:24:08,052 - Inference time: 6.50583028793335 seconds
2023-12-13 13:24:08,052 - Precision: 0.9633827088271069
2023-12-13 13:24:08,052 - Recall: 0.9606328412258607
2023-12-13 13:24:08,052 - F-score: 0.9614282665664813
2023-12-13 13:24:08,052 - Accuracy: 0.9611764705882353
2023-12-13 13:24:08,052 - G-mean: 0.9609046174624313
2023-12-13 13:24:08,082 - Model distilbert-base-uncased 2023-12-13_13-18-41 not saved
2023-12-13 13:24:08,083 - ====================================================
2023-12-13 13:24:08,621 - Model: distilbert-base-uncased 2023-12-13_13-24-08 with 4 epochs
2023-12-13 13:25:26,378 - Epoch 1 average train loss: 0.5899682081008659
2023-12-13 13:26:44,249 - Epoch 2 average train loss: 0.10927869001732153
2023-12-13 13:28:02,182 - Epoch 3 average train loss: 0.05266539716545273
2023-12-13 13:29:20,070 - Epoch 4 average train loss: 0.028396655347417383
2023-12-13 13:29:26,485 - 2023-12-13_13-24-08 with 4 epochs: Evaluation Results:
2023-12-13 13:29:26,485 - Training time: 311.4135160446167 seconds
2023-12-13 13:29:26,485 - Inference time: 6.410160064697266 seconds
2023-12-13 13:29:26,485 - Precision: 0.9668024118891172
2023-12-13 13:29:26,485 - Recall: 0.9677229879956821
2023-12-13 13:29:26,485 - F-score: 0.9671213520540747
2023-12-13 13:29:26,485 - Accuracy: 0.9670588235294117
2023-12-13 13:29:26,485 - G-mean: 0.9673908487645887
2023-12-13 13:29:35,013 - distilbert-base-uncased 2023-12-13_13-24-08 with 4 epochs: Evaluation Results (completely new data):
2023-12-13 13:29:35,014 - Training time: 311.4135160446167 seconds
2023-12-13 13:29:35,014 - Inference time: 6.489091634750366 seconds
2023-12-13 13:29:35,014 - Precision: 0.9668024118891172
2023-12-13 13:29:35,014 - Recall: 0.9677229879956821
2023-12-13 13:29:35,014 - F-score: 0.9671213520540747
2023-12-13 13:29:35,014 - Accuracy: 0.9670588235294117
2023-12-13 13:29:35,014 - G-mean: 0.9673908487645887
2023-12-13 13:29:35,044 - Model distilbert-base-uncased 2023-12-13_13-24-08 not saved
2023-12-13 13:29:35,044 - ====================================================
2023-12-13 13:29:35,603 - Model: distilbert-base-uncased 2023-12-13_13-29-35 with 5 epochs
2023-12-13 13:30:53,403 - Epoch 1 average train loss: 0.6049564270587529
2023-12-13 13:32:11,282 - Epoch 2 average train loss: 0.10886911586803548
2023-12-13 13:33:29,185 - Epoch 3 average train loss: 0.04659021742422791
2023-12-13 13:34:47,099 - Epoch 4 average train loss: 0.022020693703225867
2023-12-13 13:36:05,119 - Epoch 5 average train loss: 0.01497147842310369
2023-12-13 13:36:11,524 - 2023-12-13_13-29-35 with 5 epochs: Evaluation Results:
2023-12-13 13:36:11,524 - Training time: 389.4816403388977 seconds
2023-12-13 13:36:11,524 - Inference time: 6.401149272918701 seconds
2023-12-13 13:36:11,524 - Precision: 0.9648737537872358
2023-12-13 13:36:11,524 - Recall: 0.9650781396670354
2023-12-13 13:36:11,524 - F-score: 0.9649173562906697
2023-12-13 13:36:11,524 - Accuracy: 0.9647058823529412
2023-12-13 13:36:11,524 - G-mean: 0.9648919930577838
2023-12-13 13:36:20,058 - distilbert-base-uncased 2023-12-13_13-29-35 with 5 epochs: Evaluation Results (completely new data):
2023-12-13 13:36:20,058 - Training time: 389.4816403388977 seconds
2023-12-13 13:36:20,058 - Inference time: 6.499000549316406 seconds
2023-12-13 13:36:20,058 - Precision: 0.9648737537872358
2023-12-13 13:36:20,058 - Recall: 0.9650781396670354
2023-12-13 13:36:20,058 - F-score: 0.9649173562906697
2023-12-13 13:36:20,058 - Accuracy: 0.9647058823529412
2023-12-13 13:36:20,058 - G-mean: 0.9648919930577838
2023-12-13 13:36:20,087 - Model distilbert-base-uncased 2023-12-13_13-29-35 not saved
2023-12-13 13:36:20,087 - ====================================================
2023-12-13 13:36:20,634 - Model: distilbert-base-uncased 2023-12-13_13-36-20 with 5 epochs
2023-12-13 13:37:38,438 - Epoch 1 average train loss: 0.6022622231788495
2023-12-13 13:38:56,328 - Epoch 2 average train loss: 0.11765245495692772
2023-12-13 13:40:14,204 - Epoch 3 average train loss: 0.05930311310378944
2023-12-13 13:41:32,070 - Epoch 4 average train loss: 0.04016071491546052
2023-12-13 13:42:49,963 - Epoch 5 average train loss: 0.02330045925288954
2023-12-13 13:42:56,371 - 2023-12-13_13-36-20 with 5 epochs: Evaluation Results:
2023-12-13 13:42:56,371 - Training time: 389.289737701416 seconds
2023-12-13 13:42:56,371 - Inference time: 6.403888463973999 seconds
2023-12-13 13:42:56,371 - Precision: 0.9654605475803709
2023-12-13 13:42:56,371 - Recall: 0.9667484901636849
2023-12-13 13:42:56,371 - F-score: 0.9658909060949445
2023-12-13 13:42:56,371 - Accuracy: 0.9658823529411765
2023-12-13 13:42:56,371 - G-mean: 0.9663153245093601
2023-12-13 13:43:04,902 - distilbert-base-uncased 2023-12-13_13-36-20 with 5 epochs: Evaluation Results (completely new data):
2023-12-13 13:43:04,903 - Training time: 389.289737701416 seconds
2023-12-13 13:43:04,903 - Inference time: 6.49517297744751 seconds
2023-12-13 13:43:04,903 - Precision: 0.9654605475803709
2023-12-13 13:43:04,903 - Recall: 0.9667484901636849
2023-12-13 13:43:04,903 - F-score: 0.9658909060949445
2023-12-13 13:43:04,903 - Accuracy: 0.9658823529411765
2023-12-13 13:43:04,903 - G-mean: 0.9663153245093601
2023-12-13 13:43:04,932 - Model distilbert-base-uncased 2023-12-13_13-36-20 not saved
2023-12-13 13:43:04,932 - ====================================================
2023-12-13 13:43:05,465 - Model: distilbert-base-uncased 2023-12-13_13-43-05 with 5 epochs
2023-12-13 13:44:23,245 - Epoch 1 average train loss: 0.5865232480624143
2023-12-13 13:45:41,108 - Epoch 2 average train loss: 0.10765040213132605
2023-12-13 13:46:59,110 - Epoch 3 average train loss: 0.05157027112867902
2023-12-13 13:48:16,990 - Epoch 4 average train loss: 0.03260302767732783
2023-12-13 13:49:34,857 - Epoch 5 average train loss: 0.01814806013053064
2023-12-13 13:49:41,263 - 2023-12-13_13-43-05 with 5 epochs: Evaluation Results:
2023-12-13 13:49:41,263 - Training time: 389.3557426929474 seconds
2023-12-13 13:49:41,263 - Inference time: 6.403263330459595 seconds
2023-12-13 13:49:41,263 - Precision: 0.9716481952884669
2023-12-13 13:49:41,263 - Recall: 0.9723758996898633
2023-12-13 13:49:41,263 - F-score: 0.9719311884938658
2023-12-13 13:49:41,263 - Accuracy: 0.971764705882353
2023-12-13 13:49:41,263 - G-mean: 0.9720702547497317
2023-12-13 13:49:49,778 - distilbert-base-uncased 2023-12-13_13-43-05 with 5 epochs: Evaluation Results (completely new data):
2023-12-13 13:49:49,778 - Training time: 389.3557426929474 seconds
2023-12-13 13:49:49,778 - Inference time: 6.50230598449707 seconds
2023-12-13 13:49:49,778 - Precision: 0.9716481952884669
2023-12-13 13:49:49,778 - Recall: 0.9723758996898633
2023-12-13 13:49:49,778 - F-score: 0.9719311884938658
2023-12-13 13:49:49,778 - Accuracy: 0.971764705882353
2023-12-13 13:49:49,778 - G-mean: 0.9720702547497317
2023-12-13 13:49:49,805 - Model distilbert-base-uncased 2023-12-13_13-43-05 not saved
2023-12-13 13:56:37,274 - ====================================================
2023-12-13 13:56:37,820 - Model: distilbert-base-uncased 2023-12-13_13-56-37 with 5 epochs
2023-12-13 13:57:55,682 - Epoch 1 average train loss: 0.5761346210889956
2023-12-13 13:59:13,565 - Epoch 2 average train loss: 0.1167727926242001
2023-12-13 14:00:31,478 - Epoch 3 average train loss: 0.05778840345933157
2023-12-13 14:01:49,381 - Epoch 4 average train loss: 0.032818737387766736
2023-12-13 14:03:07,282 - Epoch 5 average train loss: 0.01869099159067606
2023-12-13 14:03:13,695 - 2023-12-13_13-56-37 with 5 epochs: Evaluation Results:
2023-12-13 14:03:13,695 - Training time: 389.42279839515686 seconds
2023-12-13 14:03:13,695 - Inference time: 6.407614469528198 seconds
2023-12-13 14:03:13,695 - Precision: 0.9751751460763088
2023-12-13 14:03:13,695 - Recall: 0.9758043852519217
2023-12-13 14:03:13,695 - F-score: 0.9754259315744687
2023-12-13 14:03:13,695 - Accuracy: 0.9752941176470589
2023-12-13 14:03:13,695 - G-mean: 0.9755492180871264
2023-12-13 14:03:22,274 - distilbert-base-uncased 2023-12-13_13-56-37 with 5 epochs: Evaluation Results (completely new data):
2023-12-13 14:03:22,274 - Training time: 389.42279839515686 seconds
2023-12-13 14:03:22,275 - Inference time: 6.51789116859436 seconds
2023-12-13 14:03:22,275 - Precision: 0.9751751460763088
2023-12-13 14:03:22,275 - Recall: 0.9758043852519217
2023-12-13 14:03:22,275 - F-score: 0.9754259315744687
2023-12-13 14:03:22,275 - Accuracy: 0.9752941176470589
2023-12-13 14:03:22,275 - G-mean: 0.9755492180871264
2023-12-13 14:03:22,521 - ====================================================
2023-12-13 14:03:23,061 - Model: distilbert-base-uncased 2023-12-13_14-03-23 with 6 epochs
2023-12-13 14:04:40,926 - Epoch 1 average train loss: 0.5703500159347759
2023-12-13 14:05:58,800 - Epoch 2 average train loss: 0.11388108150266549
2023-12-13 14:07:16,728 - Epoch 3 average train loss: 0.057655084173688115
2023-12-13 14:08:34,628 - Epoch 4 average train loss: 0.028939775236717917
2023-12-13 14:09:52,563 - Epoch 5 average train loss: 0.023607214468476526
2023-12-13 14:11:10,485 - Epoch 6 average train loss: 0.016874358427628657
2023-12-13 14:11:16,890 - 2023-12-13_14-03-23 with 6 epochs: Evaluation Results:
2023-12-13 14:11:16,890 - Training time: 467.39026522636414 seconds
2023-12-13 14:11:16,890 - Inference time: 6.40061616897583 seconds
2023-12-13 14:11:16,890 - Precision: 0.9641032793212565
2023-12-13 14:11:16,890 - Recall: 0.9653991555038168
2023-12-13 14:11:16,890 - F-score: 0.9644911987277591
2023-12-13 14:11:16,890 - Accuracy: 0.9647058823529412
2023-12-13 14:11:16,890 - G-mean: 0.965052456674296
2023-12-13 14:11:25,420 - distilbert-base-uncased 2023-12-13_14-03-23 with 6 epochs: Evaluation Results (completely new data):
2023-12-13 14:11:25,421 - Training time: 467.39026522636414 seconds
2023-12-13 14:11:25,421 - Inference time: 6.502705097198486 seconds
2023-12-13 14:11:25,421 - Precision: 0.9641032793212565
2023-12-13 14:11:25,421 - Recall: 0.9653991555038168
2023-12-13 14:11:25,421 - F-score: 0.9644911987277591
2023-12-13 14:11:25,421 - Accuracy: 0.9647058823529412
2023-12-13 14:11:25,421 - G-mean: 0.965052456674296
2023-12-13 14:11:25,449 - Model distilbert-base-uncased 2023-12-13_14-03-23 not saved
2023-12-13 14:11:25,450 - ====================================================
2023-12-13 14:11:26,998 - Model: distilbert-base-uncased 2023-12-13_14-11-26 with 6 epochs
2023-12-13 14:12:44,776 - Epoch 1 average train loss: 0.5763136462779606
2023-12-13 14:14:02,714 - Epoch 2 average train loss: 0.10744744940934813
2023-12-13 14:15:20,633 - Epoch 3 average train loss: 0.05859337711706757
2023-12-13 14:16:38,589 - Epoch 4 average train loss: 0.03872441804858253
2023-12-13 14:17:56,468 - Epoch 5 average train loss: 0.021647819543859977
2023-12-13 14:19:14,383 - Epoch 6 average train loss: 0.01643238418174031
2023-12-13 14:19:20,791 - 2023-12-13_14-11-26 with 6 epochs: Evaluation Results:
2023-12-13 14:19:20,791 - Training time: 467.3488202095032 seconds
2023-12-13 14:19:20,791 - Inference time: 6.404600381851196 seconds
2023-12-13 14:19:20,791 - Precision: 0.9693521078401173
2023-12-13 14:19:20,791 - Recall: 0.9699219119598019
2023-12-13 14:19:20,791 - F-score: 0.9695815409205355
2023-12-13 14:19:20,791 - Accuracy: 0.9694117647058823
2023-12-13 14:19:20,791 - G-mean: 0.9696668047839191
2023-12-13 14:19:29,341 - distilbert-base-uncased 2023-12-13_14-11-26 with 6 epochs: Evaluation Results (completely new data):
2023-12-13 14:19:29,342 - Training time: 467.3488202095032 seconds
2023-12-13 14:19:29,342 - Inference time: 6.4994895458221436 seconds
2023-12-13 14:19:29,342 - Precision: 0.9693521078401173
2023-12-13 14:19:29,342 - Recall: 0.9699219119598019
2023-12-13 14:19:29,342 - F-score: 0.9695815409205355
2023-12-13 14:19:29,342 - Accuracy: 0.9694117647058823
2023-12-13 14:19:29,342 - G-mean: 0.9696668047839191
2023-12-13 14:19:29,371 - Model distilbert-base-uncased 2023-12-13_14-11-26 not saved
2023-12-13 14:19:29,371 - ====================================================
2023-12-13 14:19:29,948 - Model: distilbert-base-uncased 2023-12-13_14-19-29 with 6 epochs
2023-12-13 14:20:47,750 - Epoch 1 average train loss: 0.5823487578770694
2023-12-13 14:22:05,644 - Epoch 2 average train loss: 0.10800731711089612
2023-12-13 14:23:23,488 - Epoch 3 average train loss: 0.05963229154181831
2023-12-13 14:24:41,345 - Epoch 4 average train loss: 0.03370798368061728
2023-12-13 14:25:59,215 - Epoch 5 average train loss: 0.01984985034173245
2023-12-13 14:27:17,079 - Epoch 6 average train loss: 0.011382294761852416
2023-12-13 14:27:23,473 - 2023-12-13_14-19-29 with 6 epochs: Evaluation Results:
2023-12-13 14:27:23,473 - Training time: 467.0945658683777 seconds
2023-12-13 14:27:23,473 - Inference time: 6.389435768127441 seconds
2023-12-13 14:27:23,473 - Precision: 0.9671389127186136
2023-12-13 14:27:23,473 - Recall: 0.9647553749267705
2023-12-13 14:27:23,473 - F-score: 0.9649631836337111
2023-12-13 14:27:23,473 - Accuracy: 0.9647058823529412
2023-12-13 14:27:23,473 - G-mean: 0.9647306283224726
2023-12-13 14:27:31,992 - distilbert-base-uncased 2023-12-13_14-19-29 with 6 epochs: Evaluation Results (completely new data):
2023-12-13 14:27:31,992 - Training time: 467.0945658683777 seconds
2023-12-13 14:27:31,992 - Inference time: 6.475555658340454 seconds
2023-12-13 14:27:31,992 - Precision: 0.9671389127186136
2023-12-13 14:27:31,992 - Recall: 0.9647553749267705
2023-12-13 14:27:31,992 - F-score: 0.9649631836337111
2023-12-13 14:27:31,992 - Accuracy: 0.9647058823529412
2023-12-13 14:27:31,992 - G-mean: 0.9647306283224726
2023-12-13 14:27:32,022 - Model distilbert-base-uncased 2023-12-13_14-19-29 not saved
2023-12-13 14:27:32,022 - ====================================================
2023-12-13 14:27:32,551 - Model: distilbert-base-uncased 2023-12-13_14-27-32 with 6 epochs
2023-12-13 14:28:50,353 - Epoch 1 average train loss: 0.5906317082135116
2023-12-13 14:30:08,162 - Epoch 2 average train loss: 0.10953498684308108
2023-12-13 14:31:26,018 - Epoch 3 average train loss: 0.05295687604585991
2023-12-13 14:32:43,859 - Epoch 4 average train loss: 0.03457256025936016
2023-12-13 14:34:01,735 - Epoch 5 average train loss: 0.018039503562921548
2023-12-13 14:35:19,900 - Epoch 6 average train loss: 0.009910037212402505
2023-12-13 14:35:26,311 - 2023-12-13_14-27-32 with 6 epochs: Evaluation Results:
2023-12-13 14:35:26,311 - Training time: 467.3137106895447 seconds
2023-12-13 14:35:26,311 - Inference time: 6.406200408935547 seconds
2023-12-13 14:35:26,311 - Precision: 0.9715982341364496
2023-12-13 14:35:26,311 - Recall: 0.9722227411778016
2023-12-13 14:35:26,311 - F-score: 0.9718225560921556
2023-12-13 14:35:26,311 - Accuracy: 0.971764705882353
2023-12-13 14:35:26,311 - G-mean: 0.9719936965499217
2023-12-13 14:35:35,206 - distilbert-base-uncased 2023-12-13_14-27-32 with 6 epochs: Evaluation Results (completely new data):
2023-12-13 14:35:35,206 - Training time: 467.3137106895447 seconds
2023-12-13 14:35:35,206 - Inference time: 6.8171327114105225 seconds
2023-12-13 14:35:35,206 - Precision: 0.9715982341364496
2023-12-13 14:35:35,206 - Recall: 0.9722227411778016
2023-12-13 14:35:35,206 - F-score: 0.9718225560921556
2023-12-13 14:35:35,206 - Accuracy: 0.971764705882353
2023-12-13 14:35:35,207 - G-mean: 0.9719936965499217
2023-12-13 14:35:35,237 - Model distilbert-base-uncased 2023-12-13_14-27-32 not saved
2023-12-13 14:35:35,237 - ====================================================
2023-12-13 14:35:35,843 - Model: distilbert-base-uncased 2023-12-13_14-35-35 with 6 epochs
2023-12-13 14:36:54,022 - Epoch 1 average train loss: 0.5921692870557308
2023-12-13 14:38:11,963 - Epoch 2 average train loss: 0.10871677132871221
2023-12-13 14:39:29,917 - Epoch 3 average train loss: 0.05048620681114056
2023-12-13 14:40:47,877 - Epoch 4 average train loss: 0.031013355701613954
2023-12-13 14:42:05,838 - Epoch 5 average train loss: 0.018385150874417056
2023-12-13 14:43:23,808 - Epoch 6 average train loss: 0.013892335813588407
2023-12-13 14:43:30,228 - 2023-12-13_14-35-35 with 6 epochs: Evaluation Results:
2023-12-13 14:43:30,228 - Training time: 467.93154215812683 seconds
2023-12-13 14:43:30,228 - Inference time: 6.414547920227051 seconds
2023-12-13 14:43:30,228 - Precision: 0.9712490150540992
2023-12-13 14:43:30,228 - Recall: 0.9725376914747079
2023-12-13 14:43:30,228 - F-score: 0.9717080286243908
2023-12-13 14:43:30,228 - Accuracy: 0.971764705882353
2023-12-13 14:43:30,228 - G-mean: 0.9721511218506216
2023-12-13 14:43:38,824 - distilbert-base-uncased 2023-12-13_14-35-35 with 6 epochs: Evaluation Results (completely new data):
2023-12-13 14:43:38,824 - Training time: 467.93154215812683 seconds
2023-12-13 14:43:38,824 - Inference time: 6.535484790802002 seconds
2023-12-13 14:43:38,824 - Precision: 0.9712490150540992
2023-12-13 14:43:38,824 - Recall: 0.9725376914747079
2023-12-13 14:43:38,824 - F-score: 0.9717080286243908
2023-12-13 14:43:38,824 - Accuracy: 0.971764705882353
2023-12-13 14:43:38,824 - G-mean: 0.9721511218506216
2023-12-13 14:43:38,853 - Model distilbert-base-uncased 2023-12-13_14-35-35 not saved
2023-12-13 14:43:38,853 - ====================================================
2023-12-13 14:43:39,439 - Model: distilbert-base-uncased 2023-12-13_14-43-39 with 7 epochs
2023-12-13 14:44:57,294 - Epoch 1 average train loss: 0.5998670712639304
2023-12-13 14:46:15,256 - Epoch 2 average train loss: 0.11522147508447661
2023-12-13 14:47:33,236 - Epoch 3 average train loss: 0.05267810136518058
2023-12-13 14:48:51,224 - Epoch 4 average train loss: 0.031037035677308106
2023-12-13 14:50:09,177 - Epoch 5 average train loss: 0.019342919155845746
2023-12-13 14:51:27,149 - Epoch 6 average train loss: 0.009804547386764385
2023-12-13 14:52:45,134 - Epoch 7 average train loss: 0.005583513956825139
2023-12-13 14:52:51,560 - 2023-12-13_14-43-39 with 7 epochs: Evaluation Results:
2023-12-13 14:52:51,560 - Training time: 545.6560113430023 seconds
2023-12-13 14:52:51,560 - Inference time: 6.420349597930908 seconds
2023-12-13 14:52:51,560 - Precision: 0.9696668186770477
2023-12-13 14:52:51,560 - Recall: 0.9699201630563185
2023-12-13 14:52:51,560 - F-score: 0.9696168554838807
2023-12-13 14:52:51,560 - Accuracy: 0.9694117647058823
2023-12-13 14:52:51,560 - G-mean: 0.9696659305617801
2023-12-13 14:53:00,085 - distilbert-base-uncased 2023-12-13_14-43-39 with 7 epochs: Evaluation Results (completely new data):
2023-12-13 14:53:00,086 - Training time: 545.6560113430023 seconds
2023-12-13 14:53:00,086 - Inference time: 6.452924966812134 seconds
2023-12-13 14:53:00,086 - Precision: 0.9696668186770477
2023-12-13 14:53:00,086 - Recall: 0.9699201630563185
2023-12-13 14:53:00,086 - F-score: 0.9696168554838807
2023-12-13 14:53:00,086 - Accuracy: 0.9694117647058823
2023-12-13 14:53:00,086 - G-mean: 0.9696659305617801
2023-12-13 14:53:00,117 - Model distilbert-base-uncased 2023-12-13_14-43-39 not saved
2023-12-13 14:53:00,118 - ====================================================
2023-12-13 14:53:00,667 - Model: distilbert-base-uncased 2023-12-13_14-53-00 with 7 epochs
2023-12-13 14:54:18,580 - Epoch 1 average train loss: 0.5719818253376905
2023-12-13 14:55:36,532 - Epoch 2 average train loss: 0.10796324445920832
2023-12-13 14:56:54,455 - Epoch 3 average train loss: 0.04883386021151262
2023-12-13 14:58:12,446 - Epoch 4 average train loss: 0.030859003956977497
2023-12-13 14:59:30,391 - Epoch 5 average train loss: 0.018841391065267516
2023-12-13 15:00:49,095 - Epoch 6 average train loss: 0.010682594448752592
2023-12-13 15:02:09,462 - Epoch 7 average train loss: 0.012043428085230784
2023-12-13 15:02:16,028 - 2023-12-13_14-53-00 with 7 epochs: Evaluation Results:
2023-12-13 15:02:16,029 - Training time: 548.7586441040039 seconds
2023-12-13 15:02:16,029 - Inference time: 6.560277700424194 seconds
2023-12-13 15:02:16,029 - Precision: 0.9713327092606727
2023-12-13 15:02:16,029 - Recall: 0.9725086226609673
2023-12-13 15:02:16,029 - F-score: 0.9715767655506635
2023-12-13 15:02:16,029 - Accuracy: 0.971764705882353
2023-12-13 15:02:16,029 - G-mean: 0.9721365931124016
2023-12-13 15:02:24,779 - distilbert-base-uncased 2023-12-13_14-53-00 with 7 epochs: Evaluation Results (completely new data):
2023-12-13 15:02:24,779 - Training time: 548.7586441040039 seconds
2023-12-13 15:02:24,779 - Inference time: 6.569671154022217 seconds
2023-12-13 15:02:24,779 - Precision: 0.9713327092606727
2023-12-13 15:02:24,779 - Recall: 0.9725086226609673
2023-12-13 15:02:24,779 - F-score: 0.9715767655506635
2023-12-13 15:02:24,779 - Accuracy: 0.971764705882353
2023-12-13 15:02:24,779 - G-mean: 0.9721365931124016
2023-12-13 15:02:24,808 - Model distilbert-base-uncased 2023-12-13_14-53-00 not saved
2023-12-13 15:02:24,809 - ====================================================
2023-12-13 15:02:25,365 - Model: distilbert-base-uncased 2023-12-13_15-02-25 with 7 epochs
2023-12-13 15:03:44,986 - Epoch 1 average train loss: 0.6056342421384419
2023-12-13 15:05:05,258 - Epoch 2 average train loss: 0.11794347687021775
2023-12-13 15:06:24,693 - Epoch 3 average train loss: 0.05025387640056365
2023-12-13 15:07:45,825 - Epoch 4 average train loss: 0.030269497894024586
2023-12-13 15:09:10,738 - Epoch 5 average train loss: 0.020273406418752582
2023-12-13 15:10:40,375 - Epoch 6 average train loss: 0.010703457830857266
2023-12-13 15:12:08,463 - Epoch 7 average train loss: 0.007568727034685092
2023-12-13 15:12:15,415 - 2023-12-13_15-02-25 with 7 epochs: Evaluation Results:
2023-12-13 15:12:15,415 - Training time: 583.0626771450043 seconds
2023-12-13 15:12:15,415 - Inference time: 6.945682525634766 seconds
2023-12-13 15:12:15,415 - Precision: 0.9726434940865557
2023-12-13 15:12:15,415 - Recall: 0.9739356031552168
2023-12-13 15:12:15,415 - F-score: 0.9730787812399362
2023-12-13 15:12:15,415 - Accuracy: 0.9729411764705882
2023-12-13 15:12:15,415 - G-mean: 0.9734382628294557
2023-12-13 15:12:24,854 - distilbert-base-uncased 2023-12-13_15-02-25 with 7 epochs: Evaluation Results (completely new data):
2023-12-13 15:12:24,854 - Training time: 583.0626771450043 seconds
2023-12-13 15:12:24,854 - Inference time: 7.10050892829895 seconds
2023-12-13 15:12:24,855 - Precision: 0.9726434940865557
2023-12-13 15:12:24,855 - Recall: 0.9739356031552168
2023-12-13 15:12:24,855 - F-score: 0.9730787812399362
2023-12-13 15:12:24,855 - Accuracy: 0.9729411764705882
2023-12-13 15:12:24,855 - G-mean: 0.9734382628294557
2023-12-13 15:12:24,905 - Model distilbert-base-uncased 2023-12-13_15-02-25 not saved
2023-12-13 15:12:24,905 - ====================================================
2023-12-13 15:12:25,611 - Model: distilbert-base-uncased 2023-12-13_15-12-25 with 7 epochs
2023-12-13 15:13:57,700 - Epoch 1 average train loss: 0.5954052428725888
2023-12-13 15:15:25,218 - Epoch 2 average train loss: 0.11613620188525495
2023-12-13 15:16:49,883 - Epoch 3 average train loss: 0.06279106384471936
2023-12-13 15:18:15,507 - Epoch 4 average train loss: 0.03277742767103893
2023-12-13 15:19:41,139 - Epoch 5 average train loss: 0.014288604991127024
2023-12-13 15:21:05,764 - Epoch 6 average train loss: 0.009803297391695463
2023-12-13 15:22:31,120 - Epoch 7 average train loss: 0.007314923423451974
2023-12-13 15:22:37,983 - 2023-12-13_15-12-25 with 7 epochs: Evaluation Results:
2023-12-13 15:22:37,983 - Training time: 605.4672417640686 seconds
2023-12-13 15:22:37,983 - Inference time: 6.8582258224487305 seconds
2023-12-13 15:22:37,983 - Precision: 0.9630880599528832
2023-12-13 15:22:37,983 - Recall: 0.9638923456954954
2023-12-13 15:22:37,983 - F-score: 0.9631410169507001
2023-12-13 15:22:37,984 - Accuracy: 0.9635294117647059
2023-12-13 15:22:37,984 - G-mean: 0.9637108616449662
2023-12-13 15:22:46,992 - distilbert-base-uncased 2023-12-13_15-12-25 with 7 epochs: Evaluation Results (completely new data):
2023-12-13 15:22:46,992 - Training time: 605.4672417640686 seconds
2023-12-13 15:22:46,992 - Inference time: 6.7252702713012695 seconds
2023-12-13 15:22:46,992 - Precision: 0.9630880599528832
2023-12-13 15:22:46,993 - Recall: 0.9638923456954954
2023-12-13 15:22:46,993 - F-score: 0.9631410169507001
2023-12-13 15:22:46,993 - Accuracy: 0.9635294117647059
2023-12-13 15:22:46,993 - G-mean: 0.9637108616449662
2023-12-13 15:22:47,029 - Model distilbert-base-uncased 2023-12-13_15-12-25 not saved
2023-12-13 15:22:47,029 - ====================================================
2023-12-13 15:22:47,930 - Model: distilbert-base-uncased 2023-12-13_15-22-47 with 7 epochs
2023-12-13 15:24:09,371 - Epoch 1 average train loss: 0.5849091544659699
2023-12-13 15:25:31,136 - Epoch 2 average train loss: 0.11506806546274354
2023-12-13 15:26:53,007 - Epoch 3 average train loss: 0.0565532015587258
2023-12-13 15:28:23,841 - Epoch 4 average train loss: 0.03054110996041666
2023-12-13 15:29:59,861 - Epoch 5 average train loss: 0.02181298287037541
2023-12-13 15:31:39,281 - Epoch 6 average train loss: 0.014027550278149326
2023-12-13 15:33:16,516 - Epoch 7 average train loss: 0.00598255027023911
2023-12-13 15:33:24,526 - 2023-12-13_15-22-47 with 7 epochs: Evaluation Results:
2023-12-13 15:33:24,526 - Training time: 628.5427148342133 seconds
2023-12-13 15:33:24,526 - Inference time: 8.006249904632568 seconds
2023-12-13 15:33:24,526 - Precision: 0.965243204740579
2023-12-13 15:33:24,526 - Recall: 0.9663111990719411
2023-12-13 15:33:24,526 - F-score: 0.9655932815554278
2023-12-13 15:33:24,526 - Accuracy: 0.9658823529411765
2023-12-13 15:33:24,526 - G-mean: 0.9660967522111934
2023-12-13 15:33:35,048 - distilbert-base-uncased 2023-12-13_15-22-47 with 7 epochs: Evaluation Results (completely new data):
2023-12-13 15:33:35,048 - Training time: 628.5427148342133 seconds
2023-12-13 15:33:35,048 - Inference time: 8.16860556602478 seconds
2023-12-13 15:33:35,048 - Precision: 0.965243204740579
2023-12-13 15:33:35,048 - Recall: 0.9663111990719411
2023-12-13 15:33:35,048 - F-score: 0.9655932815554278
2023-12-13 15:33:35,048 - Accuracy: 0.9658823529411765
2023-12-13 15:33:35,048 - G-mean: 0.9660967522111934
2023-12-13 15:33:35,081 - Model distilbert-base-uncased 2023-12-13_15-22-47 not saved
2023-12-13 15:33:35,081 - Total program time: 9086.407794713974 seconds
