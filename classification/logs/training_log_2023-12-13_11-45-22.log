2023-12-13 11:45:39,669 - ====================================================
2023-12-13 11:45:39,857 - Model: distilbert-base-uncased 2023-12-13_11-45-39 with 4 epochs
2023-12-13 11:49:34,060 - Epoch 1 average train loss: 0.5867784160287941
2023-12-13 11:53:51,321 - Epoch 2 average train loss: 0.11038336513454423
2023-12-13 11:58:08,505 - Epoch 3 average train loss: 0.055698281524374206
2023-12-13 12:02:36,208 - Epoch 4 average train loss: 0.028560122792773385
2023-12-13 12:03:02,649 - 2023-12-13_11-45-39 with 4 epochs: Evaluation Results:
2023-12-13 12:03:02,649 - Training time: 1016.285605430603 seconds
2023-12-13 12:03:02,649 - Inference time: 26.431177139282227 seconds
2023-12-13 12:03:02,653 - Precision: 0.9667519277284231
2023-12-13 12:03:02,653 - Recall: 0.9657568111558088
2023-12-13 12:03:02,653 - F-score: 0.9661237966732127
2023-12-13 12:03:02,653 - Accuracy: 0.9658823529411765
2023-12-13 12:03:02,653 - G-mean: 0.9658195800086785
2023-12-13 12:03:32,850 - distilbert-base-uncased 2023-12-13_11-45-39 with 4 epochs: Evaluation Results (completely new data):
2023-12-13 12:03:32,851 - Training time: 1016.285605430603 seconds
2023-12-13 12:03:32,851 - Inference time: 26.2949960231781 seconds
2023-12-13 12:03:32,851 - Precision: 0.9700327189505209
2023-12-13 12:03:32,851 - Recall: 0.9710890192938677
2023-12-13 12:03:32,851 - F-score: 0.9704296557946176
2023-12-13 12:03:32,851 - Accuracy: 0.9705882352941176
2023-12-13 12:03:32,851 - G-mean: 0.9708385950043037
2023-12-13 12:03:34,771 - ====================================================
2023-12-13 12:03:35,060 - Model: distilbert-base-uncased 2023-12-13_12-03-35 with 4 epochs
2023-12-13 12:07:31,465 - Epoch 1 average train loss: 0.5984503516993102
2023-12-13 12:11:26,869 - Epoch 2 average train loss: 0.11276994316236061
2023-12-13 12:15:27,601 - Epoch 3 average train loss: 0.05514017104226
2023-12-13 12:19:24,616 - Epoch 4 average train loss: 0.027566641827716547
2023-12-13 12:19:50,809 - 2023-12-13_12-03-35 with 4 epochs: Evaluation Results:
2023-12-13 12:19:50,809 - Training time: 949.4959228038788 seconds
2023-12-13 12:19:50,809 - Inference time: 26.18301820755005 seconds
2023-12-13 12:19:50,809 - Precision: 0.9656404735973585
2023-12-13 12:19:50,809 - Recall: 0.9663693366994224
2023-12-13 12:19:50,809 - F-score: 0.9659407302504752
2023-12-13 12:19:50,809 - Accuracy: 0.9658823529411765
2023-12-13 12:19:50,809 - G-mean: 0.9661258141367729
2023-12-13 12:20:20,271 - distilbert-base-uncased 2023-12-13_12-03-35 with 4 epochs: Evaluation Results (completely new data):
2023-12-13 12:20:20,271 - Training time: 949.4959228038788 seconds
2023-12-13 12:20:20,271 - Inference time: 25.79097819328308 seconds
2023-12-13 12:20:20,271 - Precision: 0.9656404735973585
2023-12-13 12:20:20,271 - Recall: 0.9663693366994224
2023-12-13 12:20:20,271 - F-score: 0.9659407302504752
2023-12-13 12:20:20,271 - Accuracy: 0.9658823529411765
2023-12-13 12:20:20,271 - G-mean: 0.9661258141367729
2023-12-13 12:20:20,315 - Model distilbert-base-uncased 2023-12-13_12-03-35 not saved
2023-12-13 12:20:20,316 - ====================================================
2023-12-13 12:20:20,580 - Model: distilbert-base-uncased 2023-12-13_12-20-20 with 4 epochs
2023-12-13 12:24:28,127 - Epoch 1 average train loss: 0.5889208204868962
2023-12-13 12:28:28,386 - Epoch 2 average train loss: 0.11466720187488724
2023-12-13 12:32:25,252 - Epoch 3 average train loss: 0.05503214626518242
2023-12-13 12:36:11,621 - Epoch 4 average train loss: 0.029511874150210882
2023-12-13 12:36:36,614 - 2023-12-13_12-20-20 with 4 epochs: Evaluation Results:
2023-12-13 12:36:36,615 - Training time: 950.9660556316376 seconds
2023-12-13 12:36:36,615 - Inference time: 24.984999656677246 seconds
2023-12-13 12:36:36,615 - Precision: 0.9651884296368325
2023-12-13 12:36:36,615 - Recall: 0.9630002783083377
2023-12-13 12:36:36,615 - F-score: 0.9636776793379301
2023-12-13 12:36:36,615 - Accuracy: 0.9635294117647059
2023-12-13 12:36:36,615 - G-mean: 0.963264808704066
2023-12-13 12:37:05,516 - distilbert-base-uncased 2023-12-13_12-20-20 with 4 epochs: Evaluation Results (completely new data):
2023-12-13 12:37:05,516 - Training time: 950.9660556316376 seconds
2023-12-13 12:37:05,516 - Inference time: 25.369637489318848 seconds
2023-12-13 12:37:05,516 - Precision: 0.9651884296368325
2023-12-13 12:37:05,516 - Recall: 0.9630002783083377
2023-12-13 12:37:05,516 - F-score: 0.9636776793379301
2023-12-13 12:37:05,516 - Accuracy: 0.9635294117647059
2023-12-13 12:37:05,516 - G-mean: 0.963264808704066
2023-12-13 12:37:05,566 - Model distilbert-base-uncased 2023-12-13_12-20-20 not saved
2023-12-13 12:37:05,566 - ====================================================
2023-12-13 12:37:05,834 - Model: distilbert-base-uncased 2023-12-13_12-37-05 with 4 epochs
