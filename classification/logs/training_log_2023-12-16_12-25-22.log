2023-12-16 12:25:37,237 - ====================================================
2023-12-16 12:25:37,452 - Model: distilbert-base-uncased 2023-12-16_12-25-37 with 8 epochs
2023-12-16 12:29:31,183 - Epoch 1 average train loss: 0.6101489357212011
2023-12-16 12:33:31,367 - Epoch 2 average train loss: 0.124562125731917
2023-12-16 12:37:19,342 - Epoch 3 average train loss: 0.05714181161869098
2023-12-16 12:41:11,116 - Epoch 4 average train loss: 0.0348675568692167
2023-12-16 12:45:03,526 - Epoch 5 average train loss: 0.016676599291317602
2023-12-16 12:48:56,170 - Epoch 6 average train loss: 0.013114646238494006
2023-12-16 12:52:49,498 - Epoch 7 average train loss: 0.015431420916951644
2023-12-16 12:56:48,111 - Epoch 8 average train loss: 0.005238701502231004
2023-12-16 12:57:16,380 - 2023-12-16_12-25-37 with 8 epochs: Evaluation Results:
2023-12-16 12:57:16,380 - Training time: 1870.589391708374 seconds
2023-12-16 12:57:16,380 - Inference time: 28.26000165939331 seconds
2023-12-16 12:57:16,380 - Precision: 0.9642546795027112
2023-12-16 12:57:16,380 - Recall: 0.9636177737226538
2023-12-16 12:57:16,380 - F-score: 0.9638838544556008
2023-12-16 12:57:16,380 - Accuracy: 0.9635294117647059
2023-12-16 12:57:16,380 - G-mean: 0.963573591730805
2023-12-16 12:57:48,760 - distilbert-base-uncased 2023-12-16_12-25-37 with 8 epochs: Evaluation Results (completely new data):
2023-12-16 12:57:48,760 - Training time: 1870.589391708374 seconds
2023-12-16 12:57:48,760 - Inference time: 28.301969528198242 seconds
2023-12-16 12:57:48,760 - Precision: 0.9738311681438232
2023-12-16 12:57:48,760 - Recall: 0.9748632728700567
2023-12-16 12:57:48,760 - F-score: 0.9742679583152964
2023-12-16 12:57:48,760 - Accuracy: 0.9741176470588235
2023-12-16 12:57:48,760 - G-mean: 0.9744903886505211
2023-12-16 12:57:51,317 - ====================================================
2023-12-16 12:57:51,595 - Model: distilbert-base-uncased 2023-12-16_12-57-51 with 8 epochs
2023-12-16 13:02:53,897 - Epoch 1 average train loss: 0.6217072008111898
2023-12-16 13:07:51,999 - Epoch 2 average train loss: 0.11710456922650338
2023-12-16 13:12:00,188 - Epoch 3 average train loss: 0.05284078432904447
2023-12-16 13:16:19,055 - Epoch 4 average train loss: 0.029196398505831465
2023-12-16 13:20:24,646 - Epoch 5 average train loss: 0.01728319819414002
2023-12-16 13:24:39,887 - Epoch 6 average train loss: 0.012428411899052342
2023-12-16 13:28:33,024 - Epoch 7 average train loss: 0.0073908195775413115
2023-12-16 13:32:26,963 - Epoch 8 average train loss: 0.008453803743862355
2023-12-16 13:32:52,706 - 2023-12-16_12-57-51 with 8 epochs: Evaluation Results:
2023-12-16 13:32:52,706 - Training time: 2075.305240392685 seconds
2023-12-16 13:32:52,706 - Inference time: 25.734999656677246 seconds
2023-12-16 13:32:52,706 - Precision: 0.9674051694955927
2023-12-16 13:32:52,706 - Recall: 0.9670171904709715
2023-12-16 13:32:52,706 - F-score: 0.9669614539466002
2023-12-16 13:32:52,706 - Accuracy: 0.9670588235294117
2023-12-16 13:32:52,706 - G-mean: 0.9670380067761426
2023-12-16 13:33:21,512 - distilbert-base-uncased 2023-12-16_12-57-51 with 8 epochs: Evaluation Results (completely new data):
2023-12-16 13:33:21,513 - Training time: 2075.305240392685 seconds
2023-12-16 13:33:21,513 - Inference time: 25.41300082206726 seconds
2023-12-16 13:33:21,513 - Precision: 0.9658297428068862
2023-12-16 13:33:21,513 - Recall: 0.9662821302582005
2023-12-16 13:33:21,513 - F-score: 0.9657154047470706
2023-12-16 13:33:21,513 - Accuracy: 0.9658823529411765
2023-12-16 13:33:21,513 - G-mean: 0.9660822209205607
2023-12-16 13:33:21,550 - Model distilbert-base-uncased 2023-12-16_12-57-51 not saved
2023-12-16 13:33:21,550 - ====================================================
2023-12-16 13:33:21,813 - Model: distilbert-base-uncased 2023-12-16_13-33-21 with 8 epochs
2023-12-16 13:37:11,302 - Epoch 1 average train loss: 0.6067456438173267
2023-12-16 13:41:00,873 - Epoch 2 average train loss: 0.11530037299894234
2023-12-16 13:44:49,989 - Epoch 3 average train loss: 0.06026258090072695
2023-12-16 13:48:39,307 - Epoch 4 average train loss: 0.026832949765136137
2023-12-16 13:52:28,575 - Epoch 5 average train loss: 0.015564479569164926
2023-12-16 13:56:17,520 - Epoch 6 average train loss: 0.00875155702164835
2023-12-16 14:00:06,605 - Epoch 7 average train loss: 0.008439176343107486
2023-12-16 14:03:55,816 - Epoch 8 average train loss: 0.007369621636239839
2023-12-16 14:04:21,462 - 2023-12-16_13-33-21 with 8 epochs: Evaluation Results:
2023-12-16 14:04:21,462 - Training time: 1833.9385793209076 seconds
2023-12-16 14:04:21,462 - Inference time: 25.638043880462646 seconds
2023-12-16 14:04:21,462 - Precision: 0.9620303522892717
2023-12-16 14:04:21,462 - Recall: 0.960688792814325
2023-12-16 14:04:21,463 - F-score: 0.9612461469797624
2023-12-16 14:04:21,463 - Accuracy: 0.9611764705882353
2023-12-16 14:04:21,463 - G-mean: 0.9609326007639377
2023-12-16 14:04:50,392 - distilbert-base-uncased 2023-12-16_13-33-21 with 8 epochs: Evaluation Results (completely new data):
2023-12-16 14:04:50,392 - Training time: 1833.9385793209076 seconds
2023-12-16 14:04:50,392 - Inference time: 25.54396891593933 seconds
2023-12-16 14:04:50,392 - Precision: 0.9668682065431031
2023-12-16 14:04:50,392 - Recall: 0.9672822547192885
2023-12-16 14:04:50,392 - F-score: 0.9670582769510361
2023-12-16 14:04:50,392 - Accuracy: 0.9670588235294117
2023-12-16 14:04:50,392 - G-mean: 0.9671705326723472
2023-12-16 14:04:50,429 - Model distilbert-base-uncased 2023-12-16_13-33-21 not saved
2023-12-16 14:04:50,430 - ====================================================
2023-12-16 14:04:50,683 - Model: distilbert-base-uncased 2023-12-16_14-04-50 with 8 epochs
2023-12-16 14:08:39,324 - Epoch 1 average train loss: 0.5706351398808115
2023-12-16 14:12:28,154 - Epoch 2 average train loss: 0.11216761128429105
2023-12-16 14:16:16,770 - Epoch 3 average train loss: 0.05597290471963146
2023-12-16 14:20:05,595 - Epoch 4 average train loss: 0.029119683252921438
2023-12-16 14:23:54,240 - Epoch 5 average train loss: 0.014380986077354892
2023-12-16 14:27:42,931 - Epoch 6 average train loss: 0.012144951118663063
2023-12-16 14:31:31,312 - Epoch 7 average train loss: 0.005918621396310353
2023-12-16 14:35:19,899 - Epoch 8 average train loss: 0.0059547133996795095
2023-12-16 14:35:45,445 - 2023-12-16_14-04-50 with 8 epochs: Evaluation Results:
2023-12-16 14:35:45,445 - Training time: 1829.1489007472992 seconds
2023-12-16 14:35:45,445 - Inference time: 25.53799557685852 seconds
2023-12-16 14:35:45,445 - Precision: 0.9671123938485545
2023-12-16 14:35:45,445 - Recall: 0.9673030719541373
2023-12-16 14:35:45,445 - F-score: 0.9669532694110832
2023-12-16 14:35:45,445 - Accuracy: 0.9670588235294117
2023-12-16 14:35:45,445 - G-mean: 0.9671809400315713
2023-12-16 14:36:14,273 - distilbert-base-uncased 2023-12-16_14-04-50 with 8 epochs: Evaluation Results (completely new data):
2023-12-16 14:36:14,273 - Training time: 1829.1489007472992 seconds
2023-12-16 14:36:14,273 - Inference time: 25.42800211906433 seconds
2023-12-16 14:36:14,273 - Precision: 0.9677514386648193
2023-12-16 14:36:14,273 - Recall: 0.9689627687341004
2023-12-16 14:36:14,273 - F-score: 0.9679282886569439
2023-12-16 14:36:14,273 - Accuracy: 0.9682352941176471
2023-12-16 14:36:14,273 - G-mean: 0.9685989631288644
2023-12-16 14:36:14,315 - Model distilbert-base-uncased 2023-12-16_14-04-50 not saved
2023-12-16 14:36:14,316 - ====================================================
2023-12-16 14:36:14,566 - Model: distilbert-base-uncased 2023-12-16_14-36-14 with 8 epochs
2023-12-16 14:40:02,711 - Epoch 1 average train loss: 0.5777185956169577
2023-12-16 14:43:51,179 - Epoch 2 average train loss: 0.11143941611270694
2023-12-16 14:47:39,737 - Epoch 3 average train loss: 0.056433598146061685
2023-12-16 14:51:28,456 - Epoch 4 average train loss: 0.02811005905708846
2023-12-16 14:55:17,245 - Epoch 5 average train loss: 0.021286140385713866
2023-12-16 14:59:05,935 - Epoch 6 average train loss: 0.010465011347140021
2023-12-16 15:02:54,491 - Epoch 7 average train loss: 0.008783543909084984
2023-12-16 15:06:43,117 - Epoch 8 average train loss: 0.008463694446134682
2023-12-16 15:07:08,670 - 2023-12-16_14-36-14 with 8 epochs: Evaluation Results:
2023-12-16 15:07:08,671 - Training time: 1828.4866642951965 seconds
2023-12-16 15:07:08,671 - Inference time: 25.545995473861694 seconds
2023-12-16 15:07:08,671 - Precision: 0.9725157697420714
2023-12-16 15:07:08,671 - Recall: 0.9715065614768246
2023-12-16 15:07:08,671 - F-score: 0.9719271852404443
2023-12-16 15:07:08,671 - Accuracy: 0.971764705882353
2023-12-16 15:07:08,671 - G-mean: 0.9716356251066047
2023-12-16 15:07:37,520 - distilbert-base-uncased 2023-12-16_14-36-14 with 8 epochs: Evaluation Results (completely new data):
2023-12-16 15:07:37,520 - Training time: 1828.4866642951965 seconds
2023-12-16 15:07:37,520 - Inference time: 25.469966173171997 seconds
2023-12-16 15:07:37,520 - Precision: 0.9655135898047277
2023-12-16 15:07:37,520 - Recall: 0.966655218182588
2023-12-16 15:07:37,520 - F-score: 0.9659805146890145
2023-12-16 15:07:37,521 - Accuracy: 0.9658823529411765
2023-12-16 15:07:37,521 - G-mean: 0.9662687082903308
2023-12-16 15:07:37,560 - Model distilbert-base-uncased 2023-12-16_14-36-14 not saved
2023-12-16 15:07:37,561 - ====================================================
2023-12-16 15:07:37,802 - Model: distilbert-base-uncased 2023-12-16_15-07-37 with 10 epochs
2023-12-16 15:11:26,017 - Epoch 1 average train loss: 0.5876397157591932
2023-12-16 15:15:14,739 - Epoch 2 average train loss: 0.10861502421910271
2023-12-16 15:19:03,037 - Epoch 3 average train loss: 0.05168136321336907
2023-12-16 15:22:51,287 - Epoch 4 average train loss: 0.030795476866666886
2023-12-16 15:26:39,758 - Epoch 5 average train loss: 0.016905085250790066
2023-12-16 15:30:28,258 - Epoch 6 average train loss: 0.015016537860638517
2023-12-16 15:34:16,614 - Epoch 7 average train loss: 0.008402721866390066
2023-12-16 15:38:05,215 - Epoch 8 average train loss: 0.012686899422037908
2023-12-16 15:41:54,004 - Epoch 9 average train loss: 0.00210475348864052
2023-12-16 15:45:42,584 - Epoch 10 average train loss: 0.0021535659153425297
2023-12-16 15:46:08,149 - 2023-12-16_15-07-37 with 10 epochs: Evaluation Results:
2023-12-16 15:46:08,149 - Training time: 2284.7286472320557 seconds
2023-12-16 15:46:08,149 - Inference time: 25.555999040603638 seconds
2023-12-16 15:46:08,149 - Precision: 0.9577578692218243
2023-12-16 15:46:08,149 - Recall: 0.9585939849268861
2023-12-16 15:46:08,149 - F-score: 0.9580069494026834
2023-12-16 15:46:08,149 - Accuracy: 0.9576470588235294
2023-12-16 15:46:08,149 - G-mean: 0.9581204048923909
2023-12-16 15:46:37,083 - distilbert-base-uncased 2023-12-16_15-07-37 with 10 epochs: Evaluation Results (completely new data):
2023-12-16 15:46:37,083 - Training time: 2284.7286472320557 seconds
2023-12-16 15:46:37,083 - Inference time: 25.450965404510498 seconds
2023-12-16 15:46:37,083 - Precision: 0.9671360570079492
2023-12-16 15:46:37,083 - Recall: 0.96826415446222
2023-12-16 15:46:37,083 - F-score: 0.9673640414356617
2023-12-16 15:46:37,083 - Accuracy: 0.9670588235294117
2023-12-16 15:46:37,084 - G-mean: 0.9676613013239369
2023-12-16 15:46:39,297 - ====================================================
2023-12-16 15:46:39,566 - Model: distilbert-base-uncased 2023-12-16_15-46-39 with 10 epochs
2023-12-16 15:50:27,909 - Epoch 1 average train loss: 0.6181016380821958
2023-12-16 15:54:16,186 - Epoch 2 average train loss: 0.11665619014378856
2023-12-16 15:58:04,332 - Epoch 3 average train loss: 0.058316308483481405
2023-12-16 16:01:52,414 - Epoch 4 average train loss: 0.03423556160839165
2023-12-16 16:05:40,696 - Epoch 5 average train loss: 0.02257446183631306
2023-12-16 16:09:29,055 - Epoch 6 average train loss: 0.011510974750374717
2023-12-16 16:13:17,207 - Epoch 7 average train loss: 0.006811687479699578
2023-12-16 16:17:05,411 - Epoch 8 average train loss: 0.006694587723827948
2023-12-16 16:20:53,660 - Epoch 9 average train loss: 0.005695697808037307
2023-12-16 16:24:42,087 - Epoch 10 average train loss: 0.004565305337695035
2023-12-16 16:25:07,716 - 2023-12-16_15-46-39 with 10 epochs: Evaluation Results:
2023-12-16 16:25:07,716 - Training time: 2282.465318441391 seconds
2023-12-16 16:25:07,716 - Inference time: 25.619999647140503 seconds
2023-12-16 16:25:07,716 - Precision: 0.9704108206466697
2023-12-16 16:25:07,716 - Recall: 0.9710712599904511
2023-12-16 16:25:07,716 - F-score: 0.9706612497977186
2023-12-16 16:25:07,716 - Accuracy: 0.9705882352941176
2023-12-16 16:25:07,716 - G-mean: 0.9708297176018909
2023-12-16 16:25:36,680 - distilbert-base-uncased 2023-12-16_15-46-39 with 10 epochs: Evaluation Results (completely new data):
2023-12-16 16:25:36,680 - Training time: 2282.465318441391 seconds
2023-12-16 16:25:36,680 - Inference time: 25.552000522613525 seconds
2023-12-16 16:25:36,680 - Precision: 0.9640018947578923
2023-12-16 16:25:36,680 - Recall: 0.9652707491691043
2023-12-16 16:25:36,680 - F-score: 0.9644408157250595
2023-12-16 16:25:36,680 - Accuracy: 0.9647058823529412
2023-12-16 16:25:36,680 - G-mean: 0.964988274429625
2023-12-16 16:25:36,720 - Model distilbert-base-uncased 2023-12-16_15-46-39 not saved
2023-12-16 16:25:36,720 - ====================================================
2023-12-16 16:25:36,970 - Model: distilbert-base-uncased 2023-12-16_16-25-36 with 10 epochs
2023-12-16 16:29:24,981 - Epoch 1 average train loss: 0.6039868744331248
2023-12-16 16:33:13,643 - Epoch 2 average train loss: 0.11117817845633801
2023-12-16 16:37:02,460 - Epoch 3 average train loss: 0.057838391300071686
2023-12-16 16:40:51,122 - Epoch 4 average train loss: 0.03321627520956099
2023-12-16 16:44:39,480 - Epoch 5 average train loss: 0.020382249880143824
2023-12-16 16:48:27,848 - Epoch 6 average train loss: 0.01679531332475188
2023-12-16 16:52:16,271 - Epoch 7 average train loss: 0.009416413846192882
2023-12-16 16:56:04,669 - Epoch 8 average train loss: 0.005762510069967796
2023-12-16 17:00:23,178 - Epoch 9 average train loss: 0.007526281403021558
2023-12-16 17:04:43,963 - Epoch 10 average train loss: 0.002684692871189327
2023-12-16 17:05:13,386 - 2023-12-16_16-25-36 with 10 epochs: Evaluation Results:
2023-12-16 17:05:13,387 - Training time: 2346.9293298721313 seconds
2023-12-16 17:05:13,387 - Inference time: 29.41500973701477 seconds
2023-12-16 17:05:13,387 - Precision: 0.966216591405576
2023-12-16 17:05:13,387 - Recall: 0.9661008302664558
2023-12-16 17:05:13,387 - F-score: 0.966155007376386
2023-12-16 17:05:13,387 - Accuracy: 0.9658823529411765
2023-12-16 17:05:13,387 - G-mean: 0.9659915854272171
2023-12-16 17:05:46,375 - distilbert-base-uncased 2023-12-16_16-25-36 with 10 epochs: Evaluation Results (completely new data):
2023-12-16 17:05:46,375 - Training time: 2346.9293298721313 seconds
2023-12-16 17:05:46,375 - Inference time: 29.333965063095093 seconds
2023-12-16 17:05:46,375 - Precision: 0.9740401868922449
2023-12-16 17:05:46,375 - Recall: 0.9749856136648942
2023-12-16 17:05:46,375 - F-score: 0.9744235366754896
2023-12-16 17:05:46,375 - Accuracy: 0.9741176470588235
2023-12-16 17:05:46,375 - G-mean: 0.974551533732029
2023-12-16 17:05:48,326 - ====================================================
2023-12-16 17:05:48,637 - Model: distilbert-base-uncased 2023-12-16_17-05-48 with 10 epochs
2023-12-16 17:10:29,905 - Epoch 1 average train loss: 0.6023078229672768
2023-12-16 17:14:56,765 - Epoch 2 average train loss: 0.11340343358762124
2023-12-16 17:20:36,401 - Epoch 3 average train loss: 0.056207484497743494
2023-12-16 17:25:48,732 - Epoch 4 average train loss: 0.0301411244366318
2023-12-16 17:32:20,008 - Epoch 5 average train loss: 0.02072049196330173
2023-12-16 17:40:06,843 - Epoch 6 average train loss: 0.011154749548637911
2023-12-16 17:44:19,977 - Epoch 7 average train loss: 0.00939669038836762
2023-12-16 17:48:12,357 - Epoch 8 average train loss: 0.0054224951726877515
2023-12-16 17:52:03,973 - Epoch 9 average train loss: 0.0026929225125487018
2023-12-16 17:55:55,030 - Epoch 10 average train loss: 0.008398448142003925
2023-12-16 17:56:20,851 - 2023-12-16_17-05-48 with 10 epochs: Evaluation Results:
2023-12-16 17:56:20,851 - Training time: 3006.333606004715 seconds
2023-12-16 17:56:20,851 - Inference time: 25.81299877166748 seconds
2023-12-16 17:56:20,851 - Precision: 0.9638545253397444
2023-12-16 17:56:20,851 - Recall: 0.9640251215489151
2023-12-16 17:56:20,851 - F-score: 0.9639194757242617
2023-12-16 17:56:20,851 - Accuracy: 0.9635294117647059
2023-12-16 17:56:20,851 - G-mean: 0.963777234786351
2023-12-16 17:56:49,859 - distilbert-base-uncased 2023-12-16_17-05-48 with 10 epochs: Evaluation Results (completely new data):
2023-12-16 17:56:49,859 - Training time: 3006.333606004715 seconds
2023-12-16 17:56:49,859 - Inference time: 25.60299777984619 seconds
2023-12-16 17:56:49,859 - Precision: 0.9676432593066343
2023-12-16 17:56:49,859 - Recall: 0.968920913046972
2023-12-16 17:56:49,860 - F-score: 0.9681154334542681
2023-12-16 17:56:49,860 - Accuracy: 0.9682352941176471
2023-12-16 17:56:49,860 - G-mean: 0.9685780429169216
2023-12-16 17:56:49,900 - Model distilbert-base-uncased 2023-12-16_17-05-48 not saved
2023-12-16 17:56:49,901 - ====================================================
2023-12-16 17:56:50,149 - Model: distilbert-base-uncased 2023-12-16_17-56-50 with 10 epochs
2023-12-16 18:00:49,514 - Epoch 1 average train loss: 0.5904410448582733
2023-12-16 18:04:46,904 - Epoch 2 average train loss: 0.11698284037411213
2023-12-16 18:08:47,791 - Epoch 3 average train loss: 0.05028095751014702
2023-12-16 18:12:44,957 - Epoch 4 average train loss: 0.032121388954384364
2023-12-16 18:16:43,266 - Epoch 5 average train loss: 0.012824436184566686
2023-12-16 18:20:42,286 - Epoch 6 average train loss: 0.009533795366707423
2023-12-16 18:24:32,615 - Epoch 7 average train loss: 0.008258063807939727
2023-12-16 18:28:31,939 - Epoch 8 average train loss: 0.001519521872011383
2023-12-16 18:32:47,533 - Epoch 9 average train loss: 0.0032956672545183478
2023-12-16 18:37:36,230 - Epoch 10 average train loss: 0.001971137517663438
2023-12-16 18:38:04,221 - 2023-12-16_17-56-50 with 10 epochs: Evaluation Results:
2023-12-16 18:38:04,221 - Training time: 2446.019437789917 seconds
2023-12-16 18:38:04,221 - Inference time: 27.976481676101685 seconds
2023-12-16 18:38:04,221 - Precision: 0.9632337246000888
2023-12-16 18:38:04,222 - Recall: 0.9637795655074985
2023-12-16 18:38:04,222 - F-score: 0.9632764671535613
2023-12-16 18:38:04,222 - Accuracy: 0.9635294117647059
2023-12-16 18:38:04,222 - G-mean: 0.963654480518969
2023-12-16 18:38:43,659 - distilbert-base-uncased 2023-12-16_17-56-50 with 10 epochs: Evaluation Results (completely new data):
2023-12-16 18:38:43,659 - Training time: 2446.019437789917 seconds
2023-12-16 18:38:43,659 - Inference time: 35.034998178482056 seconds
2023-12-16 18:38:43,659 - Precision: 0.9679224961833658
2023-12-16 18:38:43,659 - Recall: 0.9690141850280689
2023-12-16 18:38:43,659 - F-score: 0.9682319507983435
2023-12-16 18:38:43,659 - Accuracy: 0.9682352941176471
2023-12-16 18:38:43,659 - G-mean: 0.9686246612825963
2023-12-16 18:38:43,708 - Model distilbert-base-uncased 2023-12-16_17-56-50 not saved
2023-12-16 18:38:43,709 - ====================================================
2023-12-16 18:38:44,032 - Model: distilbert-base-uncased 2023-12-16_18-38-44 with 11 epochs
2023-12-16 18:42:38,684 - Epoch 1 average train loss: 0.5938809006354389
2023-12-16 18:46:26,384 - Epoch 2 average train loss: 0.11727296177955235
2023-12-16 18:50:14,272 - Epoch 3 average train loss: 0.05752399443593972
2023-12-16 18:53:58,886 - Epoch 4 average train loss: 0.032668662281049525
2023-12-16 18:57:43,919 - Epoch 5 average train loss: 0.01810971722828553
2023-12-16 19:01:30,250 - Epoch 6 average train loss: 0.011352178429677973
2023-12-16 19:05:15,929 - Epoch 7 average train loss: 0.006660235536538119
2023-12-16 19:09:03,074 - Epoch 8 average train loss: 0.003332863385337131
2023-12-16 19:12:51,346 - Epoch 9 average train loss: 0.004266147156749332
2023-12-16 19:16:39,882 - Epoch 10 average train loss: 0.0019518116396262913
2023-12-16 19:20:26,567 - Epoch 11 average train loss: 0.0028077102708180864
2023-12-16 19:20:51,475 - 2023-12-16_18-38-44 with 11 epochs: Evaluation Results:
2023-12-16 19:20:51,476 - Training time: 2502.4784026145935 seconds
2023-12-16 19:20:51,476 - Inference time: 24.901002645492554 seconds
2023-12-16 19:20:51,476 - Precision: 0.9687907063910334
2023-12-16 19:20:51,476 - Recall: 0.9683673995825816
2023-12-16 19:20:51,476 - F-score: 0.9684948340040591
2023-12-16 19:20:51,476 - Accuracy: 0.9682352941176471
2023-12-16 19:20:51,476 - G-mean: 0.9683013445972188
2023-12-16 19:21:19,535 - distilbert-base-uncased 2023-12-16_18-38-44 with 11 epochs: Evaluation Results (completely new data):
2023-12-16 19:21:19,535 - Training time: 2502.4784026145935 seconds
2023-12-16 19:21:19,535 - Inference time: 24.708999395370483 seconds
2023-12-16 19:21:19,535 - Precision: 0.9713085000610325
2023-12-16 19:21:19,535 - Recall: 0.9719676774118602
2023-12-16 19:21:19,536 - F-score: 0.9715991616114922
2023-12-16 19:21:19,536 - Accuracy: 0.971764705882353
2023-12-16 19:21:19,536 - G-mean: 0.9718661863483522
2023-12-16 19:21:21,740 - ====================================================
2023-12-16 19:21:22,006 - Model: distilbert-base-uncased 2023-12-16_19-21-22 with 11 epochs
2023-12-16 19:25:17,235 - Epoch 1 average train loss: 0.5862469169935759
2023-12-16 19:29:18,951 - Epoch 2 average train loss: 0.10823440294931917
2023-12-16 19:33:47,742 - Epoch 3 average train loss: 0.05071199687088237
2023-12-16 19:37:46,328 - Epoch 4 average train loss: 0.03186211511684472
2023-12-16 19:41:47,853 - Epoch 5 average train loss: 0.02028648795833921
2023-12-16 19:45:55,512 - Epoch 6 average train loss: 0.009184324120664422
2023-12-16 19:51:21,855 - Epoch 7 average train loss: 0.00923025999115506
2023-12-16 19:57:22,006 - Epoch 8 average train loss: 0.006469973386984373
2023-12-16 20:03:05,242 - Epoch 9 average train loss: 0.0011102464295896317
2023-12-16 20:09:12,109 - Epoch 10 average train loss: 0.0001714589293110561
2023-12-16 20:15:04,796 - Epoch 11 average train loss: 0.0033098655567621736
2023-12-16 20:15:29,653 - 2023-12-16_19-21-22 with 11 epochs: Evaluation Results:
2023-12-16 20:15:29,653 - Training time: 3222.736129283905 seconds
2023-12-16 20:15:29,653 - Inference time: 24.848999738693237 seconds
2023-12-16 20:15:29,653 - Precision: 0.9674408913835875
2023-12-16 20:15:29,653 - Recall: 0.967204608884907
2023-12-16 20:15:29,653 - F-score: 0.9672360468061948
2023-12-16 20:15:29,653 - Accuracy: 0.9670588235294117
2023-12-16 20:15:29,653 - G-mean: 0.9671317134602003
2023-12-16 20:15:57,818 - distilbert-base-uncased 2023-12-16_19-21-22 with 11 epochs: Evaluation Results (completely new data):
2023-12-16 20:15:57,819 - Training time: 3222.736129283905 seconds
2023-12-16 20:15:57,819 - Inference time: 24.83000087738037 seconds
2023-12-16 20:15:57,819 - Precision: 0.9702722915599121
2023-12-16 20:15:57,819 - Recall: 0.9709623618626388
2023-12-16 20:15:57,819 - F-score: 0.9705368460552364
2023-12-16 20:15:57,819 - Accuracy: 0.9705882352941176
2023-12-16 20:15:57,819 - G-mean: 0.9707752805553235
2023-12-16 20:15:57,965 - Model distilbert-base-uncased 2023-12-16_19-21-22 not saved
2023-12-16 20:15:57,965 - ====================================================
2023-12-16 20:15:58,210 - Model: distilbert-base-uncased 2023-12-16_20-15-58 with 11 epochs
2023-12-16 20:19:48,670 - Epoch 1 average train loss: 0.5856059614086853
2023-12-16 20:23:38,746 - Epoch 2 average train loss: 0.10914931377067286
2023-12-16 20:27:27,645 - Epoch 3 average train loss: 0.050887577770387424
2023-12-16 20:31:18,523 - Epoch 4 average train loss: 0.02575016585918253
2023-12-16 20:35:08,567 - Epoch 5 average train loss: 0.0114199584433535
2023-12-16 20:39:01,754 - Epoch 6 average train loss: 0.006941829633159454
2023-12-16 20:42:53,371 - Epoch 7 average train loss: 0.006202267814728924
2023-12-16 20:46:37,981 - Epoch 8 average train loss: 0.012213345058476347
2023-12-16 20:50:23,387 - Epoch 9 average train loss: 0.003117597996332573
2023-12-16 20:54:07,645 - Epoch 10 average train loss: 0.009698328404778937
2023-12-16 20:57:54,741 - Epoch 11 average train loss: 0.0050179516145234465
2023-12-16 20:58:21,435 - 2023-12-16_20-15-58 with 11 epochs: Evaluation Results:
2023-12-16 20:58:21,435 - Training time: 2516.4664957523346 seconds
2023-12-16 20:58:21,435 - Inference time: 26.68600034713745 seconds
2023-12-16 20:58:21,435 - Precision: 0.9686841818162865
2023-12-16 20:58:21,435 - Recall: 0.9686172722603897
2023-12-16 20:58:21,435 - F-score: 0.9686338270386141
2023-12-16 20:58:21,435 - Accuracy: 0.9682352941176471
2023-12-16 20:58:21,435 - G-mean: 0.9684262643559763
2023-12-16 20:58:50,756 - distilbert-base-uncased 2023-12-16_20-15-58 with 11 epochs: Evaluation Results (completely new data):
2023-12-16 20:58:50,756 - Training time: 2516.4664957523346 seconds
2023-12-16 20:58:50,756 - Inference time: 25.774999618530273 seconds
2023-12-16 20:58:50,757 - Precision: 0.9691678501405878
2023-12-16 20:58:50,757 - Recall: 0.9701769757257435
2023-12-16 20:58:50,757 - F-score: 0.9695762182042577
2023-12-16 20:58:50,757 - Accuracy: 0.9694117647058823
2023-12-16 20:58:50,757 - G-mean: 0.9697942947426061
2023-12-16 20:58:50,798 - Model distilbert-base-uncased 2023-12-16_20-15-58 not saved
2023-12-16 20:58:50,799 - ====================================================
2023-12-16 20:58:51,106 - Model: distilbert-base-uncased 2023-12-16_20-58-51 with 11 epochs
2023-12-16 21:02:38,686 - Epoch 1 average train loss: 0.591441564840429
2023-12-16 21:06:27,727 - Epoch 2 average train loss: 0.1123874917582554
2023-12-16 21:10:14,937 - Epoch 3 average train loss: 0.054952111171887204
2023-12-16 21:14:00,558 - Epoch 4 average train loss: 0.024931068717337707
2023-12-16 21:17:44,731 - Epoch 5 average train loss: 0.017988105891409385
2023-12-16 21:21:28,807 - Epoch 6 average train loss: 0.007035819022190373
2023-12-16 21:25:12,908 - Epoch 7 average train loss: 0.00550314636721262
2023-12-16 21:28:56,723 - Epoch 8 average train loss: 0.005345457844069802
2023-12-16 21:32:40,195 - Epoch 9 average train loss: 0.0033570874188358977
2023-12-16 21:36:23,580 - Epoch 10 average train loss: 0.005359936893640706
2023-12-16 21:40:09,488 - Epoch 11 average train loss: 0.002548370145349883
2023-12-16 21:40:34,460 - 2023-12-16_20-58-51 with 11 epochs: Evaluation Results:
2023-12-16 21:40:34,460 - Training time: 2478.3167695999146 seconds
2023-12-16 21:40:34,460 - Inference time: 24.96516251564026 seconds
2023-12-16 21:40:34,460 - Precision: 0.9612718668017667
2023-12-16 21:40:34,460 - Recall: 0.9612331802480819
2023-12-16 21:40:34,460 - F-score: 0.960931239252685
2023-12-16 21:40:34,460 - Accuracy: 0.9611764705882353
2023-12-16 21:40:34,460 - G-mean: 0.9612048249999354
2023-12-16 21:41:03,173 - distilbert-base-uncased 2023-12-16_20-58-51 with 11 epochs: Evaluation Results (completely new data):
2023-12-16 21:41:03,174 - Training time: 2478.3167695999146 seconds
2023-12-16 21:41:03,174 - Inference time: 25.04322338104248 seconds
2023-12-16 21:41:03,174 - Precision: 0.9691360388336113
2023-12-16 21:41:03,174 - Recall: 0.9698620254288371
2023-12-16 21:41:03,174 - F-score: 0.9694387008773475
2023-12-16 21:41:03,174 - Accuracy: 0.9694117647058823
2023-12-16 21:41:03,174 - G-mean: 0.969636868931968
2023-12-16 21:41:03,219 - Model distilbert-base-uncased 2023-12-16_20-58-51 not saved
2023-12-16 21:41:03,219 - ====================================================
2023-12-16 21:41:03,515 - Model: distilbert-base-uncased 2023-12-16_21-41-03 with 11 epochs
2023-12-16 21:44:53,481 - Epoch 1 average train loss: 0.5821272586373721
2023-12-16 21:48:44,217 - Epoch 2 average train loss: 0.11404720023931826
2023-12-16 21:52:36,640 - Epoch 3 average train loss: 0.05934156782377292
2023-12-16 21:56:26,382 - Epoch 4 average train loss: 0.03679142949007013
2023-12-16 22:00:10,007 - Epoch 5 average train loss: 0.02673280973398291
2023-12-16 22:03:52,694 - Epoch 6 average train loss: 0.013805854011409205
2023-12-16 22:07:35,900 - Epoch 7 average train loss: 0.008868197147796094
2023-12-16 22:11:18,627 - Epoch 8 average train loss: 0.004452054624510792
2023-12-16 22:15:01,051 - Epoch 9 average train loss: 0.0026375521662018453
2023-12-16 22:18:43,246 - Epoch 10 average train loss: 0.00954917296225818
2023-12-16 22:22:25,955 - Epoch 11 average train loss: 0.005660437686697953
2023-12-16 22:22:50,454 - 2023-12-16_21-41-03 with 11 epochs: Evaluation Results:
2023-12-16 22:22:50,454 - Training time: 2482.3718554973602 seconds
2023-12-16 22:22:50,454 - Inference time: 24.49299907684326 seconds
2023-12-16 22:22:50,454 - Precision: 0.960563387410916
2023-12-16 22:22:50,454 - Recall: 0.9585779497431689
2023-12-16 22:22:50,454 - F-score: 0.9593449319458784
2023-12-16 22:22:50,454 - Accuracy: 0.9588235294117647
2023-12-16 22:22:50,455 - G-mean: 0.9587007317140415
2023-12-16 22:23:18,482 - distilbert-base-uncased 2023-12-16_21-41-03 with 11 epochs: Evaluation Results (completely new data):
2023-12-16 22:23:18,482 - Training time: 2482.3718554973602 seconds
2023-12-16 22:23:18,482 - Inference time: 24.368996620178223 seconds
2023-12-16 22:23:18,482 - Precision: 0.9692702034692309
2023-12-16 22:23:18,482 - Recall: 0.9699219119598019
2023-12-16 22:23:18,482 - F-score: 0.969532557808345
2023-12-16 22:23:18,482 - Accuracy: 0.9694117647058823
2023-12-16 22:23:18,482 - G-mean: 0.9696668047839191
2023-12-16 22:23:18,526 - Model distilbert-base-uncased 2023-12-16_21-41-03 not saved
2023-12-16 22:23:18,527 - Total program time: 35875.86635375023 seconds
