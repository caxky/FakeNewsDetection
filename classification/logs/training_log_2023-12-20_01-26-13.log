2023-12-20 01:26:29,202 - ====================================================
2023-12-20 01:26:29,442 - Model: distilbert-base-uncased 2023-12-20_01-26-29 with 6 epochs
2023-12-20 01:30:11,481 - Epoch 1 average train loss: 0.584906
2023-12-20 01:33:55,705 - Epoch 2 average train loss: 0.106846
2023-12-20 01:37:40,858 - Epoch 3 average train loss: 0.054229
2023-12-20 01:41:26,592 - Epoch 4 average train loss: 0.031187
2023-12-20 01:45:12,271 - Epoch 5 average train loss: 0.015703
2023-12-20 01:48:58,244 - Epoch 6 average train loss: 0.008486
2023-12-20 01:49:23,426 - 2023-12-20_01-26-29 with 6 epochs: Evaluation Results:
2023-12-20 01:49:23,426 - Training time: 1348.7360260486603 seconds
2023-12-20 01:49:23,426 - Inference time: 25.173356533050537 seconds
2023-12-20 01:49:23,426 - Precision: 0.9635598195975514
2023-12-20 01:49:23,426 - Recall: 0.9636220903590452
2023-12-20 01:49:23,426 - F-score: 0.9633981699657441
2023-12-20 01:49:23,426 - Accuracy: 0.9635294117647059
2023-12-20 01:49:23,426 - G-mean: 0.9635757499476245
2023-12-20 01:49:51,795 - distilbert-base-uncased 2023-12-20_01-26-29 with 6 epochs: Evaluation Results (completely new data):
2023-12-20 01:49:51,795 - Training time: 1348.7360260486603 seconds
2023-12-20 01:49:51,795 - Inference time: 24.887064456939697 seconds
2023-12-20 01:49:51,795 - Precision: 0.9614848588226834
2023-12-20 01:49:51,795 - Recall: 0.9630136875775032
2023-12-20 01:49:51,795 - F-score: 0.961800663032079
2023-12-20 01:49:51,795 - Accuracy: 0.9623529411764706
2023-12-20 01:49:51,795 - G-mean: 0.9626832576883266
2023-12-20 01:49:53,766 - ====================================================
2023-12-20 01:49:54,012 - Model: distilbert-base-uncased 2023-12-20_01-49-54 with 6 epochs
2023-12-20 01:53:39,518 - Epoch 1 average train loss: 0.576171
2023-12-20 01:57:25,814 - Epoch 2 average train loss: 0.109383
2023-12-20 02:01:12,213 - Epoch 3 average train loss: 0.051392
2023-12-20 02:04:58,231 - Epoch 4 average train loss: 0.031391
2023-12-20 02:08:44,662 - Epoch 5 average train loss: 0.015720
2023-12-20 02:12:31,332 - Epoch 6 average train loss: 0.012913
2023-12-20 02:12:56,579 - 2023-12-20_01-49-54 with 6 epochs: Evaluation Results:
2023-12-20 02:12:56,580 - Training time: 1357.2652904987335 seconds
2023-12-20 02:12:56,580 - Inference time: 25.239195346832275 seconds
2023-12-20 02:12:56,580 - Precision: 0.9582633571274505
2023-12-20 02:12:56,580 - Recall: 0.9576487497829497
2023-12-20 02:12:56,580 - F-score: 0.9579304485385004
2023-12-20 02:12:56,580 - Accuracy: 0.9576470588235294
2023-12-20 02:12:56,580 - G-mean: 0.9576479043028664
2023-12-20 02:13:24,987 - distilbert-base-uncased 2023-12-20_01-49-54 with 6 epochs: Evaluation Results (completely new data):
2023-12-20 02:13:24,987 - Training time: 1357.2652904987335 seconds
2023-12-20 02:13:24,987 - Inference time: 25.00639033317566 seconds
2023-12-20 02:13:24,987 - Precision: 0.96323393340077
2023-12-20 02:13:24,987 - Recall: 0.9640832062940806
2023-12-20 02:13:24,987 - F-score: 0.9632354498351632
2023-12-20 02:13:24,987 - Accuracy: 0.9635294117647059
2023-12-20 02:13:24,987 - G-mean: 0.9638062692537163
2023-12-20 02:13:26,900 - ====================================================
2023-12-20 02:13:27,212 - Model: distilbert-base-uncased 2023-12-20_02-13-27 with 6 epochs
2023-12-20 02:17:12,708 - Epoch 1 average train loss: 0.579058
2023-12-20 02:20:58,808 - Epoch 2 average train loss: 0.113696
2023-12-20 02:24:44,682 - Epoch 3 average train loss: 0.062117
2023-12-20 02:28:30,411 - Epoch 4 average train loss: 0.037118
2023-12-20 02:32:16,729 - Epoch 5 average train loss: 0.019792
2023-12-20 02:36:03,049 - Epoch 6 average train loss: 0.010175
2023-12-20 02:36:28,245 - 2023-12-20_02-13-27 with 6 epochs: Evaluation Results:
2023-12-20 02:36:28,245 - Training time: 1355.7823536396027 seconds
2023-12-20 02:36:28,245 - Inference time: 25.186757802963257 seconds
2023-12-20 02:36:28,245 - Precision: 0.965090798469063
2023-12-20 02:36:28,245 - Recall: 0.9646282803600084
2023-12-20 02:36:28,245 - F-score: 0.9646580430788905
2023-12-20 02:36:28,245 - Accuracy: 0.9647058823529412
2023-12-20 02:36:28,245 - G-mean: 0.9646670805761448
2023-12-20 02:36:56,584 - distilbert-base-uncased 2023-12-20_02-13-27 with 6 epochs: Evaluation Results (completely new data):
2023-12-20 02:36:56,584 - Training time: 1355.7823536396027 seconds
2023-12-20 02:36:56,584 - Inference time: 24.864694118499756 seconds
2023-12-20 02:36:56,584 - Precision: 0.9693959527873304
2023-12-20 02:36:56,584 - Recall: 0.9696420960165113
2023-12-20 02:36:56,584 - F-score: 0.969474484857313
2023-12-20 02:36:56,584 - Accuracy: 0.9694117647058823
2023-12-20 02:36:56,584 - G-mean: 0.969526923521197
2023-12-20 02:36:58,469 - ====================================================
2023-12-20 02:36:58,848 - Model: distilbert-base-uncased 2023-12-20_02-36-58 with 13 epochs
2023-12-20 02:40:44,887 - Epoch 1 average train loss: 0.592174
2023-12-20 02:44:31,164 - Epoch 2 average train loss: 0.111144
2023-12-20 02:48:17,439 - Epoch 3 average train loss: 0.051133
2023-12-20 02:52:03,813 - Epoch 4 average train loss: 0.032752
2023-12-20 02:55:50,404 - Epoch 5 average train loss: 0.020256
2023-12-20 02:59:36,842 - Epoch 6 average train loss: 0.016504
2023-12-20 03:03:23,455 - Epoch 7 average train loss: 0.012755
2023-12-20 03:07:10,106 - Epoch 8 average train loss: 0.012158
2023-12-20 03:10:57,177 - Epoch 9 average train loss: 0.014126
2023-12-20 03:14:44,124 - Epoch 10 average train loss: 0.006707
2023-12-20 03:18:31,065 - Epoch 11 average train loss: 0.008390
2023-12-20 03:22:18,270 - Epoch 12 average train loss: 0.002803
2023-12-20 03:26:04,915 - Epoch 13 average train loss: 0.000244
2023-12-20 03:26:30,138 - 2023-12-20_02-36-58 with 13 epochs: Evaluation Results:
2023-12-20 03:26:30,138 - Training time: 2946.0132415294647 seconds
2023-12-20 03:26:30,138 - Inference time: 25.21403932571411 seconds
2023-12-20 03:26:30,138 - Precision: 0.9710249277540248
2023-12-20 03:26:30,139 - Recall: 0.970913784841998
2023-12-20 03:26:30,139 - F-score: 0.9709333449709436
2023-12-20 03:26:30,139 - Accuracy: 0.9705882352941176
2023-12-20 03:26:30,139 - G-mean: 0.970750996421084
2023-12-20 03:26:58,542 - distilbert-base-uncased 2023-12-20_02-36-58 with 13 epochs: Evaluation Results (completely new data):
2023-12-20 03:26:58,542 - Training time: 2946.0132415294647 seconds
2023-12-20 03:26:58,542 - Inference time: 24.96029019355774 seconds
2023-12-20 03:26:58,542 - Precision: 0.9750434945045287
2023-12-20 03:26:58,542 - Recall: 0.9760551323814717
2023-12-20 03:26:58,542 - F-score: 0.9754426019842853
2023-12-20 03:26:58,542 - Accuracy: 0.9752941176470589
2023-12-20 03:26:58,542 - G-mean: 0.9756745508164445
2023-12-20 03:27:00,439 - ====================================================
2023-12-20 03:27:00,755 - Model: distilbert-base-uncased 2023-12-20_03-27-00 with 13 epochs
2023-12-20 03:30:46,687 - Epoch 1 average train loss: 0.598724
2023-12-20 03:34:33,448 - Epoch 2 average train loss: 0.114462
2023-12-20 03:38:20,576 - Epoch 3 average train loss: 0.052389
2023-12-20 03:42:07,890 - Epoch 4 average train loss: 0.028936
2023-12-20 03:45:54,466 - Epoch 5 average train loss: 0.013965
2023-12-20 03:49:41,373 - Epoch 6 average train loss: 0.006748
2023-12-20 03:53:28,315 - Epoch 7 average train loss: 0.014683
2023-12-20 03:57:15,870 - Epoch 8 average train loss: 0.006352
2023-12-20 04:01:02,867 - Epoch 9 average train loss: 0.002747
2023-12-20 04:04:49,902 - Epoch 10 average train loss: 0.001611
2023-12-20 04:08:36,823 - Epoch 11 average train loss: 0.001777
2023-12-20 04:12:24,358 - Epoch 12 average train loss: 0.012275
2023-12-20 04:16:12,007 - Epoch 13 average train loss: 0.008377
2023-12-20 04:16:37,356 - 2023-12-20_03-27-00 with 13 epochs: Evaluation Results:
2023-12-20 04:16:37,356 - Training time: 2951.194875717163 seconds
2023-12-20 04:16:37,356 - Inference time: 25.339558362960815 seconds
2023-12-20 04:16:37,356 - Precision: 0.9625557623462798
2023-12-20 04:16:37,356 - Recall: 0.9625736100947471
2023-12-20 04:16:37,356 - F-score: 0.9624644659398249
2023-12-20 04:16:37,356 - Accuracy: 0.9623529411764706
2023-12-20 04:16:37,356 - G-mean: 0.9624632693113713
2023-12-20 04:17:05,890 - distilbert-base-uncased 2023-12-20_03-27-00 with 13 epochs: Evaluation Results (completely new data):
2023-12-20 04:17:05,890 - Training time: 2951.194875717163 seconds
2023-12-20 04:17:05,890 - Inference time: 25.042415142059326 seconds
2023-12-20 04:17:05,890 - Precision: 0.9694056888829203
2023-12-20 04:17:05,890 - Recall: 0.9699772103139551
2023-12-20 04:17:05,890 - F-score: 0.9695541653812245
2023-12-20 04:17:05,890 - Accuracy: 0.9694117647058823
2023-12-20 04:17:05,891 - G-mean: 0.96969444629478
2023-12-20 04:17:05,930 - Model distilbert-base-uncased 2023-12-20_03-27-00 not saved
2023-12-20 04:17:05,930 - ====================================================
2023-12-20 04:17:06,171 - Model: distilbert-base-uncased 2023-12-20_04-17-06 with 13 epochs
2023-12-20 04:20:52,985 - Epoch 1 average train loss: 0.585592
2023-12-20 04:24:40,255 - Epoch 2 average train loss: 0.111707
2023-12-20 04:28:27,546 - Epoch 3 average train loss: 0.056488
2023-12-20 04:32:14,842 - Epoch 4 average train loss: 0.030162
2023-12-20 04:36:01,945 - Epoch 5 average train loss: 0.020813
2023-12-20 04:39:49,405 - Epoch 6 average train loss: 0.007380
2023-12-20 04:43:36,749 - Epoch 7 average train loss: 0.008863
2023-12-20 04:47:23,937 - Epoch 8 average train loss: 0.006382
2023-12-20 04:51:11,512 - Epoch 9 average train loss: 0.007731
2023-12-20 04:54:59,005 - Epoch 10 average train loss: 0.002803
2023-12-20 04:58:46,683 - Epoch 11 average train loss: 0.004623
2023-12-20 05:02:34,372 - Epoch 12 average train loss: 0.003741
2023-12-20 05:06:22,061 - Epoch 13 average train loss: 0.007964
2023-12-20 05:06:47,276 - 2023-12-20_04-17-06 with 13 epochs: Evaluation Results:
2023-12-20 05:06:47,276 - Training time: 2955.827986717224 seconds
2023-12-20 05:06:47,276 - Inference time: 25.206039905548096 seconds
2023-12-20 05:06:47,276 - Precision: 0.9638556501773788
2023-12-20 05:06:47,276 - Recall: 0.963808634321239
2023-12-20 05:06:47,276 - F-score: 0.96368808707327
2023-12-20 05:06:47,276 - Accuracy: 0.9635294117647059
2023-12-20 05:06:47,276 - G-mean: 0.9636690129299
2023-12-20 05:07:15,877 - distilbert-base-uncased 2023-12-20_04-17-06 with 13 epochs: Evaluation Results (completely new data):
2023-12-20 05:07:15,877 - Training time: 2955.827986717224 seconds
2023-12-20 05:07:15,877 - Inference time: 25.02640962600708 seconds
2023-12-20 05:07:15,877 - Precision: 0.969172568634634
2023-12-20 05:07:15,877 - Recall: 0.9700195005772903
2023-12-20 05:07:15,877 - F-score: 0.9694771826780082
2023-12-20 05:07:15,877 - Accuracy: 0.9694117647058823
2023-12-20 05:07:15,877 - G-mean: 0.9697155850318946
2023-12-20 05:07:15,921 - Model distilbert-base-uncased 2023-12-20_04-17-06 not saved
2023-12-20 05:07:15,921 - Total program time: 13262.257277965546 seconds
