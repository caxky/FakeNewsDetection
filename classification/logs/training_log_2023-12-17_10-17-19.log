2023-12-17 10:17:37,521 - ====================================================
2023-12-17 10:17:37,900 - Model: distilbert-base-uncased 2023-12-17_10-17-37 with 4 epochs
2023-12-17 10:21:28,753 - Epoch 1 average train loss: 0.606787
2023-12-17 10:25:20,008 - Epoch 2 average train loss: 0.117597
2023-12-17 10:29:12,788 - Epoch 3 average train loss: 0.057082
2023-12-17 10:33:01,933 - Epoch 4 average train loss: 0.030387
2023-12-17 10:33:27,427 - 2023-12-17_10-17-37 with 4 epochs: Evaluation Results:
2023-12-17 10:33:27,427 - Training time: 923.9321584701538 seconds
2023-12-17 10:33:27,427 - Inference time: 25.48599863052368 seconds
2023-12-17 10:33:27,427 - Precision: 0.967773023235695
2023-12-17 10:33:27,433 - Recall: 0.9669562664524782
2023-12-17 10:33:27,433 - F-score: 0.9673138655567903
2023-12-17 10:33:27,433 - Accuracy: 0.9670588235294117
2023-12-17 10:33:27,433 - G-mean: 0.9670075436313442
2023-12-17 10:33:56,237 - distilbert-base-uncased 2023-12-17_10-17-37 with 4 epochs: Evaluation Results (completely new data):
2023-12-17 10:33:56,237 - Training time: 923.9321584701538 seconds
2023-12-17 10:33:56,238 - Inference time: 25.341959714889526 seconds
2023-12-17 10:33:56,238 - Precision: 0.9727429533827265
2023-12-17 10:33:56,238 - Recall: 0.9731946712768907
2023-12-17 10:33:56,238 - F-score: 0.9729242839893042
2023-12-17 10:33:56,238 - Accuracy: 0.9729411764705882
2023-12-17 10:33:56,238 - G-mean: 0.9730679156189692
2023-12-17 10:33:58,122 - ====================================================
2023-12-17 10:33:58,496 - Model: distilbert-base-uncased 2023-12-17_10-33-58 with 4 epochs
2023-12-17 10:37:46,956 - Epoch 1 average train loss: 0.607376
2023-12-17 10:41:35,631 - Epoch 2 average train loss: 0.121436
2023-12-17 10:45:23,879 - Epoch 3 average train loss: 0.056813
2023-12-17 10:49:12,090 - Epoch 4 average train loss: 0.038385
2023-12-17 10:49:37,645 - 2023-12-17_10-33-58 with 4 epochs: Evaluation Results:
2023-12-17 10:49:37,645 - Training time: 913.535514831543 seconds
2023-12-17 10:49:37,645 - Inference time: 25.54799795150757 seconds
2023-12-17 10:49:37,646 - Precision: 0.9655473557240182
2023-12-17 10:49:37,646 - Recall: 0.9641548174271202
2023-12-17 10:49:37,646 - F-score: 0.9647218179050181
2023-12-17 10:49:37,646 - Accuracy: 0.9647058823529412
2023-12-17 10:49:37,646 - G-mean: 0.964430310530973
2023-12-17 10:50:06,508 - distilbert-base-uncased 2023-12-17_10-33-58 with 4 epochs: Evaluation Results (completely new data):
2023-12-17 10:50:06,508 - Training time: 913.535514831543 seconds
2023-12-17 10:50:06,508 - Inference time: 25.468998908996582 seconds
2023-12-17 10:50:06,509 - Precision: 0.9636199289140466
2023-12-17 10:50:06,509 - Recall: 0.9622808442422821
2023-12-17 10:50:06,509 - F-score: 0.9625296114887985
2023-12-17 10:50:06,509 - Accuracy: 0.9623529411764706
2023-12-17 10:50:06,509 - G-mean: 0.9623168920341871
2023-12-17 10:50:06,547 - Model distilbert-base-uncased 2023-12-17_10-33-58 not saved
2023-12-17 10:50:06,547 - ====================================================
2023-12-17 10:50:06,821 - Model: distilbert-base-uncased 2023-12-17_10-50-06 with 4 epochs
2023-12-17 10:53:54,403 - Epoch 1 average train loss: 0.567190
2023-12-17 10:57:42,442 - Epoch 2 average train loss: 0.112614
2023-12-17 11:01:30,232 - Epoch 3 average train loss: 0.058791
2023-12-17 11:05:17,980 - Epoch 4 average train loss: 0.030042
2023-12-17 11:05:43,395 - 2023-12-17_10-50-06 with 4 epochs: Evaluation Results:
2023-12-17 11:05:43,395 - Training time: 911.0932714939117 seconds
2023-12-17 11:05:43,395 - Inference time: 25.4069983959198 seconds
2023-12-17 11:05:43,395 - Precision: 0.9627824120756582
2023-12-17 11:05:43,395 - Recall: 0.9622409004944243
2023-12-17 11:05:43,395 - F-score: 0.9624598826671609
2023-12-17 11:05:43,395 - Accuracy: 0.9623529411764706
2023-12-17 11:05:43,395 - G-mean: 0.9622969192048288
2023-12-17 11:06:12,137 - distilbert-base-uncased 2023-12-17_10-50-06 with 4 epochs: Evaluation Results (completely new data):
2023-12-17 11:06:12,137 - Training time: 911.0932714939117 seconds
2023-12-17 11:06:12,137 - Inference time: 25.333000421524048 seconds
2023-12-17 11:06:12,137 - Precision: 0.9669308030468287
2023-12-17 11:06:12,137 - Recall: 0.9675330018488385
2023-12-17 11:06:12,137 - F-score: 0.9671769713123967
2023-12-17 11:06:12,137 - Accuracy: 0.9670588235294117
2023-12-17 11:06:12,138 - G-mean: 0.9672958836332438
2023-12-17 11:06:12,176 - Model distilbert-base-uncased 2023-12-17_10-50-06 not saved
2023-12-17 11:06:12,177 - ====================================================
2023-12-17 11:06:12,524 - Model: distilbert-base-uncased 2023-12-17_11-06-12 with 4 epochs
2023-12-17 11:10:00,647 - Epoch 1 average train loss: 0.598011
2023-12-17 11:13:49,083 - Epoch 2 average train loss: 0.113436
2023-12-17 11:17:37,628 - Epoch 3 average train loss: 0.052993
2023-12-17 11:21:25,945 - Epoch 4 average train loss: 0.033277
2023-12-17 11:21:51,386 - 2023-12-17_11-06-12 with 4 epochs: Evaluation Results:
2023-12-17 11:21:51,386 - Training time: 913.3549461364746 seconds
2023-12-17 11:21:51,386 - Inference time: 25.433972358703613 seconds
2023-12-17 11:21:51,386 - Precision: 0.9617804011693357
2023-12-17 11:21:51,386 - Recall: 0.9616720015852049
2023-12-17 11:21:51,386 - F-score: 0.9616803890348408
2023-12-17 11:21:51,386 - Accuracy: 0.9611764705882353
2023-12-17 11:21:51,386 - G-mean: 0.961424204161301
2023-12-17 11:22:20,118 - distilbert-base-uncased 2023-12-17_11-06-12 with 4 epochs: Evaluation Results (completely new data):
2023-12-17 11:22:20,118 - Training time: 913.3549461364746 seconds
2023-12-17 11:22:20,118 - Inference time: 25.37999987602234 seconds
2023-12-17 11:22:20,118 - Precision: 0.9660320545950469
2023-12-17 11:22:20,118 - Recall: 0.966398405513163
2023-12-17 11:22:20,118 - F-score: 0.9660849266794476
2023-12-17 11:22:20,118 - Accuracy: 0.9658823529411765
2023-12-17 11:22:20,118 - G-mean: 0.9661403447717393
2023-12-17 11:22:20,156 - Model distilbert-base-uncased 2023-12-17_11-06-12 not saved
2023-12-17 11:22:20,156 - ====================================================
2023-12-17 11:22:20,463 - Model: distilbert-base-uncased 2023-12-17_11-22-20 with 4 epochs
2023-12-17 11:26:08,524 - Epoch 1 average train loss: 0.589224
2023-12-17 11:29:56,992 - Epoch 2 average train loss: 0.107388
2023-12-17 11:33:45,389 - Epoch 3 average train loss: 0.046863
2023-12-17 11:37:33,776 - Epoch 4 average train loss: 0.030125
2023-12-17 11:37:59,203 - 2023-12-17_11-22-20 with 4 epochs: Evaluation Results:
2023-12-17 11:37:59,203 - Training time: 913.2460753917694 seconds
2023-12-17 11:37:59,203 - Inference time: 25.419042825698853 seconds
2023-12-17 11:37:59,203 - Precision: 0.9637169979415596
2023-12-17 11:37:59,203 - Recall: 0.9620381274741933
2023-12-17 11:37:59,203 - F-score: 0.9626829079974334
2023-12-17 11:37:59,203 - Accuracy: 0.9623529411764706
2023-12-17 11:37:59,203 - G-mean: 0.9621955214501334
2023-12-17 11:38:27,964 - distilbert-base-uncased 2023-12-17_11-22-20 with 4 epochs: Evaluation Results (completely new data):
2023-12-17 11:38:27,965 - Training time: 913.2460753917694 seconds
2023-12-17 11:38:27,965 - Inference time: 25.36896824836731 seconds
2023-12-17 11:38:27,965 - Precision: 0.9711472586456547
2023-12-17 11:38:27,965 - Recall: 0.9708929676071494
2023-12-17 11:38:27,965 - F-score: 0.9709061923994705
2023-12-17 11:38:27,965 - Accuracy: 0.9705882352941176
2023-12-17 11:38:27,965 - G-mean: 0.9707405894930385
2023-12-17 11:38:28,004 - Model distilbert-base-uncased 2023-12-17_11-22-20 not saved
2023-12-17 11:38:28,005 - ====================================================
2023-12-17 11:38:28,714 - Model: distilbert-base-uncased 2023-12-17_11-38-28 with 4 epochs
2023-12-17 11:42:16,771 - Epoch 1 average train loss: 0.594265
2023-12-17 11:46:05,112 - Epoch 2 average train loss: 0.115316
2023-12-17 11:49:53,680 - Epoch 3 average train loss: 0.062404
2023-12-17 11:53:42,455 - Epoch 4 average train loss: 0.032216
2023-12-17 11:54:07,900 - 2023-12-17_11-38-28 with 4 epochs: Evaluation Results:
2023-12-17 11:54:07,900 - Training time: 913.6754343509674 seconds
2023-12-17 11:54:07,900 - Inference time: 25.436997890472412 seconds
2023-12-17 11:54:07,900 - Precision: 0.9623655845299746
2023-12-17 11:54:07,900 - Recall: 0.9611344985207475
2023-12-17 11:54:07,900 - F-score: 0.9615089655279139
2023-12-17 11:54:07,901 - Accuracy: 0.9611764705882353
2023-12-17 11:54:07,901 - G-mean: 0.9611554843253851
2023-12-17 11:54:36,830 - distilbert-base-uncased 2023-12-17_11-38-28 with 4 epochs: Evaluation Results (completely new data):
2023-12-17 11:54:36,830 - Training time: 913.6754343509674 seconds
2023-12-17 11:54:36,830 - Inference time: 25.397964000701904 seconds
2023-12-17 11:54:36,830 - Precision: 0.9702350091898622
2023-12-17 11:54:36,830 - Recall: 0.9693501489934707
2023-12-17 11:54:36,830 - F-score: 0.969484289100967
2023-12-17 11:54:36,830 - Accuracy: 0.9694117647058823
2023-12-17 11:54:36,830 - G-mean: 0.9693809563601249
2023-12-17 11:54:36,869 - Model distilbert-base-uncased 2023-12-17_11-38-28 not saved
2023-12-17 11:54:36,869 - ====================================================
2023-12-17 11:54:37,116 - Model: distilbert-base-uncased 2023-12-17_11-54-37 with 4 epochs
2023-12-17 11:58:25,632 - Epoch 1 average train loss: 0.574704
2023-12-17 12:02:14,223 - Epoch 2 average train loss: 0.116849
2023-12-17 12:06:03,003 - Epoch 3 average train loss: 0.061613
2023-12-17 12:09:51,618 - Epoch 4 average train loss: 0.036775
2023-12-17 12:10:17,088 - 2023-12-17_11-54-37 with 4 epochs: Evaluation Results:
2023-12-17 12:10:17,088 - Training time: 914.4357588291168 seconds
2023-12-17 12:10:17,088 - Inference time: 25.46304726600647 seconds
2023-12-17 12:10:17,088 - Precision: 0.9661594688939218
2023-12-17 12:10:17,089 - Recall: 0.9657635324893213
2023-12-17 12:10:17,089 - F-score: 0.9659001661885039
2023-12-17 12:10:17,089 - Accuracy: 0.9658823529411765
2023-12-17 12:10:17,089 - G-mean: 0.9658229408880119
2023-12-17 12:10:45,828 - distilbert-base-uncased 2023-12-17_11-54-37 with 4 epochs: Evaluation Results (completely new data):
2023-12-17 12:10:45,828 - Training time: 914.4357588291168 seconds
2023-12-17 12:10:45,828 - Inference time: 25.37497043609619 seconds
2023-12-17 12:10:45,828 - Precision: 0.9657454341970091
2023-12-17 12:10:45,828 - Recall: 0.966282786051838
2023-12-17 12:10:45,828 - F-score: 0.9659681890859737
2023-12-17 12:10:45,828 - Accuracy: 0.9658823529411765
2023-12-17 12:10:45,828 - G-mean: 0.966082548749487
2023-12-17 12:10:45,874 - Model distilbert-base-uncased 2023-12-17_11-54-37 not saved
2023-12-17 12:10:45,874 - ====================================================
2023-12-17 12:10:46,147 - Model: distilbert-base-uncased 2023-12-17_12-10-46 with 4 epochs
2023-12-17 12:14:34,521 - Epoch 1 average train loss: 0.589698
2023-12-17 12:18:22,888 - Epoch 2 average train loss: 0.115174
2023-12-17 12:22:11,152 - Epoch 3 average train loss: 0.055291
2023-12-17 12:25:59,526 - Epoch 4 average train loss: 0.026501
2023-12-17 12:26:24,997 - 2023-12-17_12-10-46 with 4 epochs: Evaluation Results:
2023-12-17 12:26:24,997 - Training time: 913.3140263557434 seconds
2023-12-17 12:26:24,997 - Inference time: 25.46299934387207 seconds
2023-12-17 12:26:24,997 - Precision: 0.9641856315335653
2023-12-17 12:26:24,997 - Recall: 0.9634269131240686
2023-12-17 12:26:24,997 - F-score: 0.9637609689394756
2023-12-17 12:26:24,997 - Accuracy: 0.9635294117647059
2023-12-17 12:26:24,997 - G-mean: 0.9634781610813605
2023-12-17 12:26:53,987 - distilbert-base-uncased 2023-12-17_12-10-46 with 4 epochs: Evaluation Results (completely new data):
2023-12-17 12:26:53,987 - Training time: 913.3140263557434 seconds
2023-12-17 12:26:53,987 - Inference time: 25.41403102874756 seconds
2023-12-17 12:26:53,987 - Precision: 0.9616395049433877
2023-12-17 12:26:53,987 - Recall: 0.9608597106298034
2023-12-17 12:26:53,987 - F-score: 0.9611125171514416
2023-12-17 12:26:53,987 - Accuracy: 0.9611764705882353
2023-12-17 12:26:53,987 - G-mean: 0.961018077558163
2023-12-17 12:26:54,024 - Model distilbert-base-uncased 2023-12-17_12-10-46 not saved
2023-12-17 12:26:54,025 - ====================================================
2023-12-17 12:26:54,295 - Model: distilbert-base-uncased 2023-12-17_12-26-54 with 4 epochs
2023-12-17 12:30:42,367 - Epoch 1 average train loss: 0.579563
2023-12-17 12:34:30,577 - Epoch 2 average train loss: 0.110689
2023-12-17 12:38:18,899 - Epoch 3 average train loss: 0.054422
2023-12-17 12:42:07,177 - Epoch 4 average train loss: 0.024380
2023-12-17 12:42:32,625 - 2023-12-17_12-26-54 with 4 epochs: Evaluation Results:
2023-12-17 12:42:32,625 - Training time: 912.815319776535 seconds
2023-12-17 12:42:32,625 - Inference time: 25.44000244140625 seconds
2023-12-17 12:42:32,625 - Precision: 0.9583867459538841
2023-12-17 12:42:32,625 - Recall: 0.9556925178031346
2023-12-17 12:42:32,625 - F-score: 0.9566657252385754
2023-12-17 12:42:32,625 - Accuracy: 0.9564705882352941
2023-12-17 12:42:32,625 - G-mean: 0.9560814738688505
2023-12-17 12:43:01,451 - distilbert-base-uncased 2023-12-17_12-26-54 with 4 epochs: Evaluation Results (completely new data):
2023-12-17 12:43:01,451 - Training time: 912.815319776535 seconds
2023-12-17 12:43:01,451 - Inference time: 25.381001710891724 seconds
2023-12-17 12:43:01,451 - Precision: 0.9731549096065224
2023-12-17 12:43:01,451 - Recall: 0.971804136723532
2023-12-17 12:43:01,451 - F-score: 0.9722288716128814
2023-12-17 12:43:01,451 - Accuracy: 0.971764705882353
2023-12-17 12:43:01,451 - G-mean: 0.9717844211029507
2023-12-17 12:43:03,314 - ====================================================
2023-12-17 12:43:03,585 - Model: distilbert-base-uncased 2023-12-17_12-43-03 with 4 epochs
2023-12-17 12:46:52,017 - Epoch 1 average train loss: 0.578858
2023-12-17 12:50:40,794 - Epoch 2 average train loss: 0.112510
2023-12-17 12:54:29,386 - Epoch 3 average train loss: 0.052787
2023-12-17 12:58:17,969 - Epoch 4 average train loss: 0.032995
2023-12-17 12:58:43,362 - 2023-12-17_12-43-03 with 4 epochs: Evaluation Results:
2023-12-17 12:58:43,362 - Training time: 914.3257932662964 seconds
2023-12-17 12:58:43,362 - Inference time: 25.38505530357361 seconds
2023-12-17 12:58:43,362 - Precision: 0.9666221906001148
2023-12-17 12:58:43,362 - Recall: 0.9659433551180026
2023-12-17 12:58:43,362 - F-score: 0.9662468121534508
2023-12-17 12:58:43,362 - Accuracy: 0.9658823529411765
2023-12-17 12:58:43,362 - G-mean: 0.9659128535480158
2023-12-17 12:59:12,042 - distilbert-base-uncased 2023-12-17_12-43-03 with 4 epochs: Evaluation Results (completely new data):
2023-12-17 12:59:12,042 - Training time: 914.3257932662964 seconds
2023-12-17 12:59:12,042 - Inference time: 25.2979998588562 seconds
2023-12-17 12:59:12,042 - Precision: 0.9746528327834859
2023-12-17 12:59:12,043 - Recall: 0.9744155996020464
2023-12-17 12:59:12,043 - F-score: 0.9744279663124373
2023-12-17 12:59:12,043 - Accuracy: 0.9741176470588235
2023-12-17 12:59:12,043 - G-mean: 0.9742666119403651
2023-12-17 12:59:13,919 - ====================================================
2023-12-17 12:59:14,194 - Model: distilbert-base-uncased 2023-12-17_12-59-14 with 5 epochs
2023-12-17 13:03:02,416 - Epoch 1 average train loss: 0.581563
2023-12-17 13:06:50,477 - Epoch 2 average train loss: 0.111718
2023-12-17 13:10:38,576 - Epoch 3 average train loss: 0.055177
2023-12-17 13:14:26,822 - Epoch 4 average train loss: 0.032985
2023-12-17 13:18:15,353 - Epoch 5 average train loss: 0.020158
2023-12-17 13:18:40,757 - 2023-12-17_12-59-14 with 5 epochs: Evaluation Results:
2023-12-17 13:18:40,758 - Training time: 1141.1022622585297 seconds
2023-12-17 13:18:40,758 - Inference time: 25.39699912071228 seconds
2023-12-17 13:18:40,758 - Precision: 0.9641884637243695
2023-12-17 13:18:40,758 - Recall: 0.9624146575832306
2023-12-17 13:18:40,758 - F-score: 0.9630047245469064
2023-12-17 13:18:40,758 - Accuracy: 0.9623529411764706
2023-12-17 13:18:40,758 - G-mean: 0.9623837988851266
2023-12-17 13:19:09,469 - distilbert-base-uncased 2023-12-17_12-59-14 with 5 epochs: Evaluation Results (completely new data):
2023-12-17 13:19:09,469 - Training time: 1141.1022622585297 seconds
2023-12-17 13:19:09,469 - Inference time: 25.328006744384766 seconds
2023-12-17 13:19:09,469 - Precision: 0.9668885501973493
2023-12-17 13:19:09,469 - Recall: 0.96517206744177
2023-12-17 13:19:09,469 - F-score: 0.9654274774212823
2023-12-17 13:19:09,470 - Accuracy: 0.9647058823529412
2023-12-17 13:19:09,470 - G-mean: 0.9649389467442099
2023-12-17 13:19:11,345 - ====================================================
2023-12-17 13:19:11,586 - Model: distilbert-base-uncased 2023-12-17_13-19-11 with 5 epochs
2023-12-17 13:22:59,830 - Epoch 1 average train loss: 0.601183
2023-12-17 13:26:48,307 - Epoch 2 average train loss: 0.114024
2023-12-17 13:30:36,848 - Epoch 3 average train loss: 0.053716
2023-12-17 13:34:25,186 - Epoch 4 average train loss: 0.028740
2023-12-17 13:38:13,344 - Epoch 5 average train loss: 0.022324
2023-12-17 13:38:38,850 - 2023-12-17_13-19-11 with 5 epochs: Evaluation Results:
2023-12-17 13:38:38,850 - Training time: 1141.699138879776 seconds
2023-12-17 13:38:38,850 - Inference time: 25.498030185699463 seconds
2023-12-17 13:38:38,850 - Precision: 0.9678696839578175
2023-12-17 13:38:38,850 - Recall: 0.9673978741806135
2023-12-17 13:38:38,850 - F-score: 0.9676168044341283
2023-12-17 13:38:38,850 - Accuracy: 0.9670588235294117
2023-12-17 13:38:38,851 - G-mean: 0.9672283339987295
2023-12-17 13:39:07,719 - distilbert-base-uncased 2023-12-17_13-19-11 with 5 epochs: Evaluation Results (completely new data):
2023-12-17 13:39:07,719 - Training time: 1141.699138879776 seconds
2023-12-17 13:39:07,719 - Inference time: 25.452998876571655 seconds
2023-12-17 13:39:07,719 - Precision: 0.9673448545989529
2023-12-17 13:39:07,719 - Recall: 0.9675388487306092
2023-12-17 13:39:07,719 - F-score: 0.9673702874676031
2023-12-17 13:39:07,719 - Accuracy: 0.9670588235294117
2023-12-17 13:39:07,719 - G-mean: 0.9672988063532512
2023-12-17 13:39:09,614 - ====================================================
2023-12-17 13:39:09,860 - Model: distilbert-base-uncased 2023-12-17_13-39-09 with 5 epochs
2023-12-17 13:42:58,243 - Epoch 1 average train loss: 0.612545
2023-12-17 13:46:46,925 - Epoch 2 average train loss: 0.111572
2023-12-17 13:50:35,619 - Epoch 3 average train loss: 0.058986
2023-12-17 13:54:24,055 - Epoch 4 average train loss: 0.033531
2023-12-17 13:58:12,598 - Epoch 5 average train loss: 0.019343
2023-12-17 13:58:37,970 - 2023-12-17_13-39-09 with 5 epochs: Evaluation Results:
2023-12-17 13:58:37,971 - Training time: 1142.680583000183 seconds
2023-12-17 13:58:37,971 - Inference time: 25.365034580230713 seconds
2023-12-17 13:58:37,971 - Precision: 0.969688357193035
2023-12-17 13:58:37,971 - Recall: 0.9696919820651007
2023-12-17 13:58:37,971 - F-score: 0.9695022720249244
2023-12-17 13:58:37,971 - Accuracy: 0.9694117647058823
2023-12-17 13:58:37,971 - G-mean: 0.9695518632620299
2023-12-17 13:59:06,705 - distilbert-base-uncased 2023-12-17_13-39-09 with 5 epochs: Evaluation Results (completely new data):
2023-12-17 13:59:06,705 - Training time: 1142.680583000183 seconds
2023-12-17 13:59:06,705 - Inference time: 25.274967193603516 seconds
2023-12-17 13:59:06,705 - Precision: 0.967643272429752
2023-12-17 13:59:06,705 - Recall: 0.9689851162143283
2023-12-17 13:59:06,705 - F-score: 0.9680217707744092
2023-12-17 13:59:06,705 - Accuracy: 0.9682352941176471
2023-12-17 13:59:06,706 - G-mean: 0.9686101326092984
2023-12-17 13:59:08,588 - ====================================================
2023-12-17 13:59:08,884 - Model: distilbert-base-uncased 2023-12-17_13-59-08 with 5 epochs
2023-12-17 14:02:56,960 - Epoch 1 average train loss: 0.589355
2023-12-17 14:06:45,427 - Epoch 2 average train loss: 0.111170
2023-12-17 14:12:17,143 - Epoch 3 average train loss: 0.054987
2023-12-17 14:17:55,076 - Epoch 4 average train loss: 0.034304
2023-12-17 14:23:31,690 - Epoch 5 average train loss: 0.020177
2023-12-17 14:24:08,886 - 2023-12-17_13-59-08 with 5 epochs: Evaluation Results:
2023-12-17 14:24:08,886 - Training time: 1462.7501318454742 seconds
2023-12-17 14:24:08,886 - Inference time: 37.18804454803467 seconds
2023-12-17 14:24:08,886 - Precision: 0.9657754822290103
2023-12-17 14:24:08,886 - Recall: 0.9642114248092222
2023-12-17 14:24:08,886 - F-score: 0.9648789102355625
2023-12-17 14:24:08,887 - Accuracy: 0.9647058823529412
2023-12-17 14:24:08,887 - G-mean: 0.9644586218938411
2023-12-17 14:24:49,437 - distilbert-base-uncased 2023-12-17_13-59-08 with 5 epochs: Evaluation Results (completely new data):
2023-12-17 14:24:49,437 - Training time: 1462.7501318454742 seconds
2023-12-17 14:24:49,437 - Inference time: 37.08896493911743 seconds
2023-12-17 14:24:49,437 - Precision: 0.9659114211537855
2023-12-17 14:24:49,437 - Recall: 0.9664060012984172
2023-12-17 14:24:49,437 - F-score: 0.9660560791041691
2023-12-17 14:24:49,437 - Accuracy: 0.9658823529411765
2023-12-17 14:24:49,437 - G-mean: 0.9661441416427411
2023-12-17 14:24:49,480 - Model distilbert-base-uncased 2023-12-17_13-59-08 not saved
2023-12-17 14:24:49,481 - ====================================================
2023-12-17 14:24:49,820 - Model: distilbert-base-uncased 2023-12-17_14-24-49 with 5 epochs
2023-12-17 14:29:13,271 - Epoch 1 average train loss: 0.569175
2023-12-17 14:33:36,757 - Epoch 2 average train loss: 0.106350
2023-12-17 14:38:00,683 - Epoch 3 average train loss: 0.054488
2023-12-17 14:42:24,547 - Epoch 4 average train loss: 0.029403
2023-12-17 14:46:50,972 - Epoch 5 average train loss: 0.014032
2023-12-17 14:47:20,590 - 2023-12-17_14-24-49 with 5 epochs: Evaluation Results:
2023-12-17 14:47:20,590 - Training time: 1321.091054201126 seconds
2023-12-17 14:47:20,590 - Inference time: 29.60503339767456 seconds
2023-12-17 14:47:20,590 - Precision: 0.9628825573138995
2023-12-17 14:47:20,590 - Recall: 0.9622684390627855
2023-12-17 14:47:20,590 - F-score: 0.9624011340362599
2023-12-17 14:47:20,590 - Accuracy: 0.9623529411764706
2023-12-17 14:47:20,590 - G-mean: 0.9623106891920941
2023-12-17 14:47:53,801 - distilbert-base-uncased 2023-12-17_14-24-49 with 5 epochs: Evaluation Results (completely new data):
2023-12-17 14:47:53,801 - Training time: 1321.091054201126 seconds
2023-12-17 14:47:53,801 - Inference time: 29.447962045669556 seconds
2023-12-17 14:47:53,801 - Precision: 0.9702889978294191
2023-12-17 14:47:53,802 - Recall: 0.9710265650299951
2023-12-17 14:47:53,802 - F-score: 0.9705482367429887
2023-12-17 14:47:53,802 - Accuracy: 0.9705882352941176
2023-12-17 14:47:53,802 - G-mean: 0.9708073754232462