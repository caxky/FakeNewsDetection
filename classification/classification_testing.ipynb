{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, DistilBertTokenizer, DistilBertForSequenceClassification, AlbertTokenizer, AlbertForSequenceClassification, RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_filename = f'testing_logs/testing_log_{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}.log'\n",
    "logging.basicConfig(filename=log_filename, filemode='w', format='%(asctime)s - %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_category_data(file_path: str, category: str):\n",
    "    df = pd.read_feather(file_path)\n",
    "    # add a column for the category\n",
    "    df['category'] = category\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               text  label  metadata  title\n",
      "category                                   \n",
      "crime           315    315       315      0\n",
      "health         2814   2821      2821   2821\n",
      "politics      41913  41952     41952      0\n",
      "science         907    907       907      0\n",
      "social_media  44898  44898     44898      0\n"
     ]
    }
   ],
   "source": [
    "# load the testing datasets\n",
    "testing_datasets = {\n",
    "  'crime': ['snope'],\n",
    "  'health': ['covid_claims'],\n",
    "  'politics': ['pheme', 'liar_dataset', ],\n",
    "  'science': ['climate_dataset'],\n",
    "  'social_media': ['gossipcop']\n",
    "}\n",
    "\n",
    "data = pd.concat([load_category_data(os.path.join(os.path.realpath('.'), f'..\\data\\{category}\\{dataset}.feather'), category) for category, datasets in testing_datasets.items() for dataset in datasets])\n",
    "print(data.groupby('category').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               text\n",
      "category           \n",
      "crime           315\n",
      "health         2814\n",
      "politics      41913\n",
      "science         907\n",
      "social_media  44898\n"
     ]
    }
   ],
   "source": [
    "# keep only the text and category columns\n",
    "data = data[['text', 'category']]\n",
    "data.dropna(inplace=True)\n",
    "print(data.groupby('category').count())\n",
    "logging.info(f'Number of samples: {len(data)}')\n",
    "logging.info(data.groupby('category').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>encoded_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Was an Italian Economist Removed from a Plane ...</td>\n",
       "      <td>crime</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8524</th>\n",
       "      <td>Shelby Township Meijer Human Trafficking Warning</td>\n",
       "      <td>crime</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8523</th>\n",
       "      <td>Shelby Township Meijer Human Trafficking Warning</td>\n",
       "      <td>crime</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>Shelby Township Meijer Human Trafficking Warning</td>\n",
       "      <td>crime</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8521</th>\n",
       "      <td>Shelby Township Meijer Human Trafficking Warning</td>\n",
       "      <td>crime</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text category  \\\n",
       "174   Was an Italian Economist Removed from a Plane ...    crime   \n",
       "8524   Shelby Township Meijer Human Trafficking Warning    crime   \n",
       "8523   Shelby Township Meijer Human Trafficking Warning    crime   \n",
       "8522   Shelby Township Meijer Human Trafficking Warning    crime   \n",
       "8521   Shelby Township Meijer Human Trafficking Warning    crime   \n",
       "\n",
       "      encoded_category  \n",
       "174                  0  \n",
       "8524                 0  \n",
       "8523                 0  \n",
       "8522                 0  \n",
       "8521                 0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['encoded_category'] = data['category'].astype('category').cat.codes\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model_state_dir = 'models/distilbert-base-uncased-2023-12-13_17-42-42.pt'\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(testing_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the test data\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "data_texts = data['text'].tolist()\n",
    "data_labels = data['encoded_category'].tolist()\n",
    "\n",
    "test_encodings = tokenizer(list(data_texts), truncation=True, padding=True)\n",
    "\n",
    "test_inputs = torch.tensor(test_encodings['input_ids'])\n",
    "test_masks = torch.tensor(test_encodings['attention_mask'])\n",
    "test_labels = torch.tensor(data_labels)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "model.load_state_dict(torch.load(model_state_dir, map_location=device))\n",
    "model.to(device)\n",
    "test_inputs = test_inputs.to(device)\n",
    "test_masks = test_masks.to(device)\n",
    "test_labels = test_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# track variables\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "# predict\n",
    "eval_start_time = time.time()\n",
    "for batch in test_dataloader:\n",
    "    inputs = {'input_ids': batch[0].to(device), 'attention_mask': batch[1].to(device), 'labels': None}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions.extend(logits.argmax(dim=1).cpu().tolist())\n",
    "    label_ids = batch[2].cpu().tolist()\n",
    "    true_labels.append(label_ids)\n",
    "eval_end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the results across all batches\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate additional metrics\n",
    "precision = precision_score(true_labels, predictions, average='weighted')\n",
    "recall = recall_score(true_labels, predictions, average='weighted')\n",
    "f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "g_mean = (recall*accuracy)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/distilbert-base-uncased-2023-12-13_17-42-42.pt: Evaluation Results:\n",
      "Inference time: 8960.384637355804 seconds\n",
      "Precision: 0.9597576979234526\n",
      "Recall: 0.9554195515537112\n",
      "F-score: 0.9563099380122453\n",
      "Accuracy: 0.9554195515537112\n",
      "G-mean: 0.9554195515537112\n"
     ]
    }
   ],
   "source": [
    "# Log the results\n",
    "logging.info(f\"{model_state_dir}: Evaluation Results:\")\n",
    "logging.info(f\"Inference time: {eval_end_time - eval_start_time} seconds\")\n",
    "logging.info(f\"Precision: {precision}\")\n",
    "logging.info(f\"Recall: {recall}\")\n",
    "logging.info(f\"F-score: {f1}\")\n",
    "logging.info(f\"Accuracy: {accuracy}\")\n",
    "logging.info(f\"G-mean: {g_mean}\")\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"{model_state_dir}: Evaluation Results:\")\n",
    "print(f\"Inference time: {eval_end_time - eval_start_time} seconds\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F-score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"G-mean: {g_mean}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
